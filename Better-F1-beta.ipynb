{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, re\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from datetime import datetime as dt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, classification_report\n",
    "# models\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# design network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('gcTrianingSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['CUMSUM_cputime'] = train['cpuTimeTaken'].cumsum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new = train[train['gcRun'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initialUsedMemory</th>\n",
       "      <th>initialFreeMemory</th>\n",
       "      <th>query token</th>\n",
       "      <th>gcRun</th>\n",
       "      <th>gcInitialMemory</th>\n",
       "      <th>gcFinalMemory</th>\n",
       "      <th>gcTotalMemory</th>\n",
       "      <th>userTime</th>\n",
       "      <th>sysTime</th>\n",
       "      <th>realTime</th>\n",
       "      <th>cpuTimeTaken</th>\n",
       "      <th>finalUsedMemory</th>\n",
       "      <th>finalFreeMemory</th>\n",
       "      <th>CUMSUM_cputime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730</td>\n",
       "      <td>2730</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>token_41</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>2559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.775503</td>\n",
       "      <td>1.921919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.415684</td>\n",
       "      <td>0.291495</td>\n",
       "      <td>0.479192</td>\n",
       "      <td>0.018359</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.186569</td>\n",
       "      <td>5.775588</td>\n",
       "      <td>1.921990</td>\n",
       "      <td>255.461629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.801402</td>\n",
       "      <td>0.726219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.619302</td>\n",
       "      <td>1.132280</td>\n",
       "      <td>1.855206</td>\n",
       "      <td>0.111837</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.016707</td>\n",
       "      <td>0.128994</td>\n",
       "      <td>0.802645</td>\n",
       "      <td>0.728086</td>\n",
       "      <td>147.136479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.129662</td>\n",
       "      <td>0.330214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>4.117682</td>\n",
       "      <td>0.330214</td>\n",
       "      <td>0.371230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.143413</td>\n",
       "      <td>1.338731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112348</td>\n",
       "      <td>5.137244</td>\n",
       "      <td>1.337994</td>\n",
       "      <td>128.070885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.758096</td>\n",
       "      <td>1.961032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141588</td>\n",
       "      <td>5.758960</td>\n",
       "      <td>1.959821</td>\n",
       "      <td>255.542042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.418293</td>\n",
       "      <td>2.484630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230622</td>\n",
       "      <td>6.419282</td>\n",
       "      <td>2.484630</td>\n",
       "      <td>383.730196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.520346</td>\n",
       "      <td>3.728506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.583425</td>\n",
       "      <td>5.281528</td>\n",
       "      <td>8.037598</td>\n",
       "      <td>2.410000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.906536</td>\n",
       "      <td>7.520346</td>\n",
       "      <td>3.749075</td>\n",
       "      <td>509.334226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        initialUsedMemory  initialFreeMemory query token  gcRun  \\\n",
       "count         2730.000000        2730.000000        2730   2730   \n",
       "unique                NaN                NaN          91      2   \n",
       "top                   NaN                NaN    token_41  False   \n",
       "freq                  NaN                NaN          30   2559   \n",
       "mean             5.775503           1.921919         NaN    NaN   \n",
       "std              0.801402           0.726219         NaN    NaN   \n",
       "min              4.129662           0.330214         NaN    NaN   \n",
       "25%              5.143413           1.338731         NaN    NaN   \n",
       "50%              5.758096           1.961032         NaN    NaN   \n",
       "75%              6.418293           2.484630         NaN    NaN   \n",
       "max              7.520346           3.728506         NaN    NaN   \n",
       "\n",
       "        gcInitialMemory  gcFinalMemory  gcTotalMemory     userTime  \\\n",
       "count       2730.000000    2730.000000    2730.000000  2730.000000   \n",
       "unique              NaN            NaN            NaN          NaN   \n",
       "top                 NaN            NaN            NaN          NaN   \n",
       "freq                NaN            NaN            NaN          NaN   \n",
       "mean           0.415684       0.291495       0.479192     0.018359   \n",
       "std            1.619302       1.132280       1.855206     0.111837   \n",
       "min            0.000000       0.000000       0.000000     0.000000   \n",
       "25%            0.000000       0.000000       0.000000     0.000000   \n",
       "50%            0.000000       0.000000       0.000000     0.000000   \n",
       "75%            0.000000       0.000000       0.000000     0.000000   \n",
       "max            7.583425       5.281528       8.037598     2.410000   \n",
       "\n",
       "            sysTime     realTime  cpuTimeTaken  finalUsedMemory  \\\n",
       "count   2730.000000  2730.000000   2730.000000      2730.000000   \n",
       "unique          NaN          NaN           NaN              NaN   \n",
       "top             NaN          NaN           NaN              NaN   \n",
       "freq            NaN          NaN           NaN              NaN   \n",
       "mean       0.000535     0.002755      0.186569         5.775588   \n",
       "std        0.007700     0.016707      0.128994         0.802645   \n",
       "min        0.000000     0.000000      0.001052         4.117682   \n",
       "25%        0.000000     0.000000      0.112348         5.137244   \n",
       "50%        0.000000     0.000000      0.141588         5.758960   \n",
       "75%        0.000000     0.000000      0.230622         6.419282   \n",
       "max        0.260000     0.350000      0.906536         7.520346   \n",
       "\n",
       "        finalFreeMemory  CUMSUM_cputime  \n",
       "count       2730.000000     2730.000000  \n",
       "unique              NaN             NaN  \n",
       "top                 NaN             NaN  \n",
       "freq                NaN             NaN  \n",
       "mean           1.921990      255.461629  \n",
       "std            0.728086      147.136479  \n",
       "min            0.330214        0.371230  \n",
       "25%            1.337994      128.070885  \n",
       "50%            1.959821      255.542042  \n",
       "75%            2.484630      383.730196  \n",
       "max            3.749075      509.334226  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['diff'] = train['finalUsedMemory'].values - train['initialUsedMemory'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['freq'] = train['diff'].values / train['cpuTimeTaken'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initialUsedMemory</th>\n",
       "      <th>initialFreeMemory</th>\n",
       "      <th>query token</th>\n",
       "      <th>gcRun</th>\n",
       "      <th>gcInitialMemory</th>\n",
       "      <th>gcFinalMemory</th>\n",
       "      <th>gcTotalMemory</th>\n",
       "      <th>userTime</th>\n",
       "      <th>sysTime</th>\n",
       "      <th>realTime</th>\n",
       "      <th>cpuTimeTaken</th>\n",
       "      <th>finalUsedMemory</th>\n",
       "      <th>finalFreeMemory</th>\n",
       "      <th>diff</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730</td>\n",
       "      <td>2730</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>token_80</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>2559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.775503</td>\n",
       "      <td>1.921919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.415684</td>\n",
       "      <td>0.291495</td>\n",
       "      <td>0.479192</td>\n",
       "      <td>0.018359</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.186569</td>\n",
       "      <td>5.775588</td>\n",
       "      <td>1.921990</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>-0.019479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.801402</td>\n",
       "      <td>0.726219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.619302</td>\n",
       "      <td>1.132280</td>\n",
       "      <td>1.855206</td>\n",
       "      <td>0.111837</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.016707</td>\n",
       "      <td>0.128994</td>\n",
       "      <td>0.802645</td>\n",
       "      <td>0.728086</td>\n",
       "      <td>0.482923</td>\n",
       "      <td>2.876326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.129662</td>\n",
       "      <td>0.330214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>4.117682</td>\n",
       "      <td>0.330214</td>\n",
       "      <td>-2.575007</td>\n",
       "      <td>-24.433835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.143413</td>\n",
       "      <td>1.338731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112348</td>\n",
       "      <td>5.137244</td>\n",
       "      <td>1.337994</td>\n",
       "      <td>0.054697</td>\n",
       "      <td>0.494437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.758096</td>\n",
       "      <td>1.961032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141588</td>\n",
       "      <td>5.758960</td>\n",
       "      <td>1.959821</td>\n",
       "      <td>0.076620</td>\n",
       "      <td>0.560554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.418293</td>\n",
       "      <td>2.484630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230622</td>\n",
       "      <td>6.419282</td>\n",
       "      <td>2.484630</td>\n",
       "      <td>0.133900</td>\n",
       "      <td>0.654622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.520346</td>\n",
       "      <td>3.728506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.583425</td>\n",
       "      <td>5.281528</td>\n",
       "      <td>8.037598</td>\n",
       "      <td>2.410000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.906536</td>\n",
       "      <td>7.520346</td>\n",
       "      <td>3.749075</td>\n",
       "      <td>0.962846</td>\n",
       "      <td>12.985695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        initialUsedMemory  initialFreeMemory query token  gcRun  \\\n",
       "count         2730.000000        2730.000000        2730   2730   \n",
       "unique                NaN                NaN          91      2   \n",
       "top                   NaN                NaN    token_80  False   \n",
       "freq                  NaN                NaN          30   2559   \n",
       "mean             5.775503           1.921919         NaN    NaN   \n",
       "std              0.801402           0.726219         NaN    NaN   \n",
       "min              4.129662           0.330214         NaN    NaN   \n",
       "25%              5.143413           1.338731         NaN    NaN   \n",
       "50%              5.758096           1.961032         NaN    NaN   \n",
       "75%              6.418293           2.484630         NaN    NaN   \n",
       "max              7.520346           3.728506         NaN    NaN   \n",
       "\n",
       "        gcInitialMemory  gcFinalMemory  gcTotalMemory     userTime  \\\n",
       "count       2730.000000    2730.000000    2730.000000  2730.000000   \n",
       "unique              NaN            NaN            NaN          NaN   \n",
       "top                 NaN            NaN            NaN          NaN   \n",
       "freq                NaN            NaN            NaN          NaN   \n",
       "mean           0.415684       0.291495       0.479192     0.018359   \n",
       "std            1.619302       1.132280       1.855206     0.111837   \n",
       "min            0.000000       0.000000       0.000000     0.000000   \n",
       "25%            0.000000       0.000000       0.000000     0.000000   \n",
       "50%            0.000000       0.000000       0.000000     0.000000   \n",
       "75%            0.000000       0.000000       0.000000     0.000000   \n",
       "max            7.583425       5.281528       8.037598     2.410000   \n",
       "\n",
       "            sysTime     realTime  cpuTimeTaken  finalUsedMemory  \\\n",
       "count   2730.000000  2730.000000   2730.000000      2730.000000   \n",
       "unique          NaN          NaN           NaN              NaN   \n",
       "top             NaN          NaN           NaN              NaN   \n",
       "freq            NaN          NaN           NaN              NaN   \n",
       "mean       0.000535     0.002755      0.186569         5.775588   \n",
       "std        0.007700     0.016707      0.128994         0.802645   \n",
       "min        0.000000     0.000000      0.001052         4.117682   \n",
       "25%        0.000000     0.000000      0.112348         5.137244   \n",
       "50%        0.000000     0.000000      0.141588         5.758960   \n",
       "75%        0.000000     0.000000      0.230622         6.419282   \n",
       "max        0.260000     0.350000      0.906536         7.520346   \n",
       "\n",
       "        finalFreeMemory         diff         freq  \n",
       "count       2730.000000  2730.000000  2730.000000  \n",
       "unique              NaN          NaN          NaN  \n",
       "top                 NaN          NaN          NaN  \n",
       "freq                NaN          NaN          NaN  \n",
       "mean           1.921990     0.000085    -0.019479  \n",
       "std            0.728086     0.482923     2.876326  \n",
       "min            0.330214    -2.575007   -24.433835  \n",
       "25%            1.337994     0.054697     0.494437  \n",
       "50%            1.959821     0.076620     0.560554  \n",
       "75%            2.484630     0.133900     0.654622  \n",
       "max            3.749075     0.962846    12.985695  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['initialUsedMemory', 'initialFreeMemory', 'query token', 'gcRun',\n",
       "       'gcInitialMemory', 'gcFinalMemory', 'gcTotalMemory', 'userTime',\n",
       "       'sysTime', 'realTime', 'cpuTimeTaken', 'finalUsedMemory',\n",
       "       'finalFreeMemory', 'diff', 'freq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = train.drop(['gcInitialMemory', 'gcFinalMemory', 'gcTotalMemory', 'userTime', 'sysTime', 'realTime'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initialUsedMemory</th>\n",
       "      <th>initialFreeMemory</th>\n",
       "      <th>query token</th>\n",
       "      <th>gcRun</th>\n",
       "      <th>cpuTimeTaken</th>\n",
       "      <th>finalUsedMemory</th>\n",
       "      <th>finalFreeMemory</th>\n",
       "      <th>diff</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.249634</td>\n",
       "      <td>2.999878</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.371230</td>\n",
       "      <td>4.409714</td>\n",
       "      <td>2.839798</td>\n",
       "      <td>0.160080</td>\n",
       "      <td>0.431215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.409720</td>\n",
       "      <td>2.839792</td>\n",
       "      <td>token_2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.220883</td>\n",
       "      <td>4.482361</td>\n",
       "      <td>2.767151</td>\n",
       "      <td>0.072641</td>\n",
       "      <td>0.328867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.482361</td>\n",
       "      <td>2.767151</td>\n",
       "      <td>token_3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.141776</td>\n",
       "      <td>4.542626</td>\n",
       "      <td>2.706886</td>\n",
       "      <td>0.060265</td>\n",
       "      <td>0.425069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.542626</td>\n",
       "      <td>2.706886</td>\n",
       "      <td>token_4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.156459</td>\n",
       "      <td>4.616293</td>\n",
       "      <td>2.633218</td>\n",
       "      <td>0.073668</td>\n",
       "      <td>0.470844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.616296</td>\n",
       "      <td>2.633216</td>\n",
       "      <td>token_5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.285218</td>\n",
       "      <td>4.787172</td>\n",
       "      <td>2.462339</td>\n",
       "      <td>0.170877</td>\n",
       "      <td>0.599111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initialUsedMemory  initialFreeMemory query token  gcRun  cpuTimeTaken  \\\n",
       "0           4.249634           2.999878     token_1  False      0.371230   \n",
       "1           4.409720           2.839792     token_2  False      0.220883   \n",
       "2           4.482361           2.767151     token_3  False      0.141776   \n",
       "3           4.542626           2.706886     token_4  False      0.156459   \n",
       "4           4.616296           2.633216     token_5  False      0.285218   \n",
       "\n",
       "   finalUsedMemory  finalFreeMemory      diff      freq  \n",
       "0         4.409714         2.839798  0.160080  0.431215  \n",
       "1         4.482361         2.767151  0.072641  0.328867  \n",
       "2         4.542626         2.706886  0.060265  0.425069  \n",
       "3         4.616293         2.633218  0.073668  0.470844  \n",
       "4         4.787172         2.462339  0.170877  0.599111  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "newdata = data[data['gcRun'] == False]\n",
    "\n",
    "small = newdata.groupby('query token', as_index=False)['freq'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = data.merge(small, on='query token', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initialUsedMemory</th>\n",
       "      <th>initialFreeMemory</th>\n",
       "      <th>query token</th>\n",
       "      <th>gcRun</th>\n",
       "      <th>cpuTimeTaken</th>\n",
       "      <th>finalUsedMemory</th>\n",
       "      <th>finalFreeMemory</th>\n",
       "      <th>diff</th>\n",
       "      <th>freq_x</th>\n",
       "      <th>freq_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.249634</td>\n",
       "      <td>2.999878</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.371230</td>\n",
       "      <td>4.409714</td>\n",
       "      <td>2.839798</td>\n",
       "      <td>0.160080</td>\n",
       "      <td>0.431215</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>4.873217</td>\n",
       "      <td>2.376295</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.193802</td>\n",
       "      <td>5.010445</td>\n",
       "      <td>2.239067</td>\n",
       "      <td>0.137228</td>\n",
       "      <td>0.708081</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>5.490317</td>\n",
       "      <td>2.017495</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.196103</td>\n",
       "      <td>5.621264</td>\n",
       "      <td>1.886548</td>\n",
       "      <td>0.130947</td>\n",
       "      <td>0.667747</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>4.509700</td>\n",
       "      <td>3.048405</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191939</td>\n",
       "      <td>4.647537</td>\n",
       "      <td>2.910569</td>\n",
       "      <td>0.137836</td>\n",
       "      <td>0.718124</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>5.181700</td>\n",
       "      <td>2.515077</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191070</td>\n",
       "      <td>5.319710</td>\n",
       "      <td>2.377067</td>\n",
       "      <td>0.138010</td>\n",
       "      <td>0.722304</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>4.353560</td>\n",
       "      <td>3.448198</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191412</td>\n",
       "      <td>4.488307</td>\n",
       "      <td>3.313451</td>\n",
       "      <td>0.134747</td>\n",
       "      <td>0.703965</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>6.607853</td>\n",
       "      <td>1.294491</td>\n",
       "      <td>token_1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.188288</td>\n",
       "      <td>4.220680</td>\n",
       "      <td>3.693871</td>\n",
       "      <td>-2.387173</td>\n",
       "      <td>-12.678319</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>4.516493</td>\n",
       "      <td>3.289659</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191804</td>\n",
       "      <td>4.645598</td>\n",
       "      <td>3.160554</td>\n",
       "      <td>0.129105</td>\n",
       "      <td>0.673110</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>5.027514</td>\n",
       "      <td>2.114088</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191983</td>\n",
       "      <td>5.170535</td>\n",
       "      <td>1.971066</td>\n",
       "      <td>0.143021</td>\n",
       "      <td>0.744970</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>6.408616</td>\n",
       "      <td>1.163650</td>\n",
       "      <td>token_1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.195108</td>\n",
       "      <td>4.449746</td>\n",
       "      <td>3.117637</td>\n",
       "      <td>-1.958870</td>\n",
       "      <td>-10.039939</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>6.213867</td>\n",
       "      <td>1.446778</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.195159</td>\n",
       "      <td>6.352690</td>\n",
       "      <td>1.307955</td>\n",
       "      <td>0.138823</td>\n",
       "      <td>0.711333</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>5.264453</td>\n",
       "      <td>2.441114</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.194490</td>\n",
       "      <td>5.401629</td>\n",
       "      <td>2.303937</td>\n",
       "      <td>0.137177</td>\n",
       "      <td>0.705316</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>5.318928</td>\n",
       "      <td>2.414959</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.192652</td>\n",
       "      <td>5.452772</td>\n",
       "      <td>2.281115</td>\n",
       "      <td>0.133844</td>\n",
       "      <td>0.694746</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>6.564707</td>\n",
       "      <td>1.210683</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.192135</td>\n",
       "      <td>6.692626</td>\n",
       "      <td>1.082764</td>\n",
       "      <td>0.127919</td>\n",
       "      <td>0.665778</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>5.698932</td>\n",
       "      <td>2.128705</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191148</td>\n",
       "      <td>5.840147</td>\n",
       "      <td>1.987490</td>\n",
       "      <td>0.141215</td>\n",
       "      <td>0.738777</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>6.566484</td>\n",
       "      <td>1.386153</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191952</td>\n",
       "      <td>6.696381</td>\n",
       "      <td>1.256255</td>\n",
       "      <td>0.129898</td>\n",
       "      <td>0.676719</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>7.080305</td>\n",
       "      <td>0.911394</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.192364</td>\n",
       "      <td>7.216078</td>\n",
       "      <td>0.775621</td>\n",
       "      <td>0.135773</td>\n",
       "      <td>0.705810</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>5.378027</td>\n",
       "      <td>2.384180</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191456</td>\n",
       "      <td>5.518215</td>\n",
       "      <td>2.243992</td>\n",
       "      <td>0.140188</td>\n",
       "      <td>0.732221</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>5.319840</td>\n",
       "      <td>2.365707</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.192137</td>\n",
       "      <td>5.446558</td>\n",
       "      <td>2.238989</td>\n",
       "      <td>0.126718</td>\n",
       "      <td>0.659520</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>6.146654</td>\n",
       "      <td>1.640944</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191702</td>\n",
       "      <td>6.283191</td>\n",
       "      <td>1.504406</td>\n",
       "      <td>0.136537</td>\n",
       "      <td>0.712238</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>5.794411</td>\n",
       "      <td>2.131371</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.193828</td>\n",
       "      <td>5.932693</td>\n",
       "      <td>1.993088</td>\n",
       "      <td>0.138282</td>\n",
       "      <td>0.713426</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>7.191572</td>\n",
       "      <td>0.601397</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.192882</td>\n",
       "      <td>7.329497</td>\n",
       "      <td>0.463472</td>\n",
       "      <td>0.137925</td>\n",
       "      <td>0.715076</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>5.774768</td>\n",
       "      <td>2.113904</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191996</td>\n",
       "      <td>5.910139</td>\n",
       "      <td>1.978533</td>\n",
       "      <td>0.135371</td>\n",
       "      <td>0.705075</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>5.471675</td>\n",
       "      <td>2.397466</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191359</td>\n",
       "      <td>5.618208</td>\n",
       "      <td>2.250933</td>\n",
       "      <td>0.146533</td>\n",
       "      <td>0.765750</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>5.479445</td>\n",
       "      <td>2.415574</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.190656</td>\n",
       "      <td>5.610015</td>\n",
       "      <td>2.285005</td>\n",
       "      <td>0.130569</td>\n",
       "      <td>0.684842</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>6.102859</td>\n",
       "      <td>1.695480</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.188536</td>\n",
       "      <td>6.237671</td>\n",
       "      <td>1.560669</td>\n",
       "      <td>0.134812</td>\n",
       "      <td>0.715044</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>5.252359</td>\n",
       "      <td>2.559653</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.192773</td>\n",
       "      <td>5.385803</td>\n",
       "      <td>2.426209</td>\n",
       "      <td>0.133443</td>\n",
       "      <td>0.692232</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>7.187666</td>\n",
       "      <td>0.682940</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.194064</td>\n",
       "      <td>7.316381</td>\n",
       "      <td>0.554225</td>\n",
       "      <td>0.128715</td>\n",
       "      <td>0.663261</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>6.149848</td>\n",
       "      <td>1.777398</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191263</td>\n",
       "      <td>6.295106</td>\n",
       "      <td>1.632140</td>\n",
       "      <td>0.145258</td>\n",
       "      <td>0.759466</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>5.459074</td>\n",
       "      <td>2.062410</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.196097</td>\n",
       "      <td>5.600423</td>\n",
       "      <td>1.921062</td>\n",
       "      <td>0.141349</td>\n",
       "      <td>0.720809</td>\n",
       "      <td>0.696677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.008159</td>\n",
       "      <td>2.241353</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>5.008159</td>\n",
       "      <td>2.241353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>4.976454</td>\n",
       "      <td>2.253527</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006520</td>\n",
       "      <td>4.976454</td>\n",
       "      <td>2.253527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.767373</td>\n",
       "      <td>1.782431</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>5.770162</td>\n",
       "      <td>1.779643</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.436735</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>4.424427</td>\n",
       "      <td>3.249401</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006955</td>\n",
       "      <td>4.424427</td>\n",
       "      <td>3.249401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>4.502425</td>\n",
       "      <td>3.267106</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>4.502425</td>\n",
       "      <td>3.267106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>4.154043</td>\n",
       "      <td>3.647715</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>4.154043</td>\n",
       "      <td>3.647715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>4.970368</td>\n",
       "      <td>2.580901</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006437</td>\n",
       "      <td>4.970368</td>\n",
       "      <td>2.580901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>5.029567</td>\n",
       "      <td>2.776585</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006343</td>\n",
       "      <td>5.029567</td>\n",
       "      <td>2.776585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>5.281313</td>\n",
       "      <td>2.090757</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>5.281380</td>\n",
       "      <td>2.090691</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.010405</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>5.921972</td>\n",
       "      <td>1.580958</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>5.931446</td>\n",
       "      <td>1.571484</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>1.505261</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>5.758782</td>\n",
       "      <td>1.887214</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>5.771609</td>\n",
       "      <td>1.874388</td>\n",
       "      <td>0.012826</td>\n",
       "      <td>1.946196</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>5.880260</td>\n",
       "      <td>1.799916</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>5.880260</td>\n",
       "      <td>1.799916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>6.310435</td>\n",
       "      <td>1.423451</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006498</td>\n",
       "      <td>6.323142</td>\n",
       "      <td>1.410745</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>1.955407</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>6.126018</td>\n",
       "      <td>1.645955</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>6.126018</td>\n",
       "      <td>1.645955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>5.866839</td>\n",
       "      <td>1.973493</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>5.869628</td>\n",
       "      <td>1.970704</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.430965</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>5.661955</td>\n",
       "      <td>2.262850</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>5.661955</td>\n",
       "      <td>2.262850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>5.670188</td>\n",
       "      <td>2.340066</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006486</td>\n",
       "      <td>5.690282</td>\n",
       "      <td>2.319972</td>\n",
       "      <td>0.020094</td>\n",
       "      <td>3.098183</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>6.537628</td>\n",
       "      <td>1.485810</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006657</td>\n",
       "      <td>6.537628</td>\n",
       "      <td>1.485810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>5.120050</td>\n",
       "      <td>2.472236</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>5.122838</td>\n",
       "      <td>2.469447</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.439400</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>5.637750</td>\n",
       "      <td>2.160101</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>5.640633</td>\n",
       "      <td>2.157219</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.447362</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>6.768463</td>\n",
       "      <td>1.157318</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>6.768463</td>\n",
       "      <td>1.157318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>7.098492</td>\n",
       "      <td>0.778461</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>7.115049</td>\n",
       "      <td>0.761904</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>2.547258</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>5.149529</td>\n",
       "      <td>2.700568</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>5.163086</td>\n",
       "      <td>2.687012</td>\n",
       "      <td>0.013556</td>\n",
       "      <td>2.096965</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>6.042073</td>\n",
       "      <td>1.794841</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>6.044862</td>\n",
       "      <td>1.792052</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>5.040448</td>\n",
       "      <td>2.401446</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>5.040448</td>\n",
       "      <td>2.401446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>6.469457</td>\n",
       "      <td>1.234645</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>6.469457</td>\n",
       "      <td>1.234645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>5.380671</td>\n",
       "      <td>2.187688</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005672</td>\n",
       "      <td>5.380671</td>\n",
       "      <td>2.187688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>6.564678</td>\n",
       "      <td>1.316182</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>6.564678</td>\n",
       "      <td>1.316182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>5.743222</td>\n",
       "      <td>2.183536</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>5.759533</td>\n",
       "      <td>2.167224</td>\n",
       "      <td>0.016312</td>\n",
       "      <td>2.575895</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>6.730493</td>\n",
       "      <td>0.742163</td>\n",
       "      <td>token_91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006415</td>\n",
       "      <td>6.730493</td>\n",
       "      <td>0.742163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2730 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      initialUsedMemory  initialFreeMemory query token  gcRun  cpuTimeTaken  \\\n",
       "0              4.249634           2.999878     token_1  False      0.371230   \n",
       "102            4.873217           2.376295     token_1  False      0.193802   \n",
       "259            5.490317           2.017495     token_1  False      0.196103   \n",
       "274            4.509700           3.048405     token_1  False      0.191939   \n",
       "394            5.181700           2.515077     token_1  False      0.191070   \n",
       "457            4.353560           3.448198     token_1  False      0.191412   \n",
       "564            6.607853           1.294491     token_1   True      0.188288   \n",
       "637            4.516493           3.289659     token_1  False      0.191804   \n",
       "766            5.027514           2.114088     token_1  False      0.191983   \n",
       "886            6.408616           1.163650     token_1   True      0.195108   \n",
       "975            6.213867           1.446778     token_1  False      0.195159   \n",
       "1062           5.264453           2.441114     token_1  False      0.194490   \n",
       "1108           5.318928           2.414959     token_1  False      0.192652   \n",
       "1256           6.564707           1.210683     token_1  False      0.192135   \n",
       "1307           5.698932           2.128705     token_1  False      0.191148   \n",
       "1440           6.566484           1.386153     token_1  False      0.191952   \n",
       "1484           7.080305           0.911394     token_1  False      0.192364   \n",
       "1613           5.378027           2.384180     token_1  False      0.191456   \n",
       "1666           5.319840           2.365707     token_1  False      0.192137   \n",
       "1755           6.146654           1.640944     token_1  False      0.191702   \n",
       "1845           5.794411           2.131371     token_1  False      0.193828   \n",
       "1965           7.191572           0.601397     token_1  False      0.192882   \n",
       "2017           5.774768           2.113904     token_1  False      0.191996   \n",
       "2172           5.471675           2.397466     token_1  False      0.191359   \n",
       "2209           5.479445           2.415574     token_1  False      0.190656   \n",
       "2324           6.102859           1.695480     token_1  False      0.188536   \n",
       "2406           5.252359           2.559653     token_1  False      0.192773   \n",
       "2508           7.187666           0.682940     token_1  False      0.194064   \n",
       "2613           6.149848           1.777398     token_1  False      0.191263   \n",
       "2683           5.459074           2.062410     token_1  False      0.196097   \n",
       "...                 ...                ...         ...    ...           ...   \n",
       "90             5.008159           2.241353    token_91  False      0.006620   \n",
       "180            4.976454           2.253527    token_91  False      0.006520   \n",
       "270            5.767373           1.782431    token_91  False      0.006385   \n",
       "343            4.424427           3.249401    token_91  False      0.006955   \n",
       "424            4.502425           3.267106    token_91  False      0.006450   \n",
       "455            4.154043           3.647715    token_91  False      0.006373   \n",
       "624            4.970368           2.580901    token_91  False      0.006437   \n",
       "644            5.029567           2.776585    token_91  False      0.006343   \n",
       "806            5.281313           2.090757    token_91  False      0.006361   \n",
       "867            5.921972           1.580958    token_91  False      0.006294   \n",
       "955            5.758782           1.887214    token_91  False      0.006591   \n",
       "1049           5.880260           1.799916    token_91  False      0.006390   \n",
       "1116           6.310435           1.423451    token_91  False      0.006498   \n",
       "1224           6.126018           1.645955    token_91  False      0.006386   \n",
       "1287           5.866839           1.973493    token_91  False      0.006471   \n",
       "1399           5.661955           2.262850    token_91  False      0.006580   \n",
       "1508           5.670188           2.340066    token_91  False      0.006486   \n",
       "1564           6.537628           1.485810    token_91  False      0.006657   \n",
       "1648           5.120050           2.472236    token_91  False      0.006346   \n",
       "1775           5.637750           2.160101    token_91  False      0.006444   \n",
       "1856           6.768463           1.157318    token_91  False      0.006350   \n",
       "1918           7.098492           0.778461    token_91  False      0.006500   \n",
       "2064           5.149529           2.700568    token_91  False      0.006465   \n",
       "2110           6.042073           1.794841    token_91  False      0.006422   \n",
       "2244           5.040448           2.401446    token_91  False      0.006363   \n",
       "2300           6.469457           1.234645    token_91  False      0.006327   \n",
       "2446           5.380671           2.187688    token_91  False      0.005672   \n",
       "2543           6.564678           1.316182    token_91  False      0.006366   \n",
       "2589           5.743222           2.183536    token_91  False      0.006332   \n",
       "2674           6.730493           0.742163    token_91  False      0.006415   \n",
       "\n",
       "      finalUsedMemory  finalFreeMemory      diff     freq_x    freq_y  \n",
       "0            4.409714         2.839798  0.160080   0.431215  0.696677  \n",
       "102          5.010445         2.239067  0.137228   0.708081  0.696677  \n",
       "259          5.621264         1.886548  0.130947   0.667747  0.696677  \n",
       "274          4.647537         2.910569  0.137836   0.718124  0.696677  \n",
       "394          5.319710         2.377067  0.138010   0.722304  0.696677  \n",
       "457          4.488307         3.313451  0.134747   0.703965  0.696677  \n",
       "564          4.220680         3.693871 -2.387173 -12.678319  0.696677  \n",
       "637          4.645598         3.160554  0.129105   0.673110  0.696677  \n",
       "766          5.170535         1.971066  0.143021   0.744970  0.696677  \n",
       "886          4.449746         3.117637 -1.958870 -10.039939  0.696677  \n",
       "975          6.352690         1.307955  0.138823   0.711333  0.696677  \n",
       "1062         5.401629         2.303937  0.137177   0.705316  0.696677  \n",
       "1108         5.452772         2.281115  0.133844   0.694746  0.696677  \n",
       "1256         6.692626         1.082764  0.127919   0.665778  0.696677  \n",
       "1307         5.840147         1.987490  0.141215   0.738777  0.696677  \n",
       "1440         6.696381         1.256255  0.129898   0.676719  0.696677  \n",
       "1484         7.216078         0.775621  0.135773   0.705810  0.696677  \n",
       "1613         5.518215         2.243992  0.140188   0.732221  0.696677  \n",
       "1666         5.446558         2.238989  0.126718   0.659520  0.696677  \n",
       "1755         6.283191         1.504406  0.136537   0.712238  0.696677  \n",
       "1845         5.932693         1.993088  0.138282   0.713426  0.696677  \n",
       "1965         7.329497         0.463472  0.137925   0.715076  0.696677  \n",
       "2017         5.910139         1.978533  0.135371   0.705075  0.696677  \n",
       "2172         5.618208         2.250933  0.146533   0.765750  0.696677  \n",
       "2209         5.610015         2.285005  0.130569   0.684842  0.696677  \n",
       "2324         6.237671         1.560669  0.134812   0.715044  0.696677  \n",
       "2406         5.385803         2.426209  0.133443   0.692232  0.696677  \n",
       "2508         7.316381         0.554225  0.128715   0.663261  0.696677  \n",
       "2613         6.295106         1.632140  0.145258   0.759466  0.696677  \n",
       "2683         5.600423         1.921062  0.141349   0.720809  0.696677  \n",
       "...               ...              ...       ...        ...       ...  \n",
       "90           5.008159         2.241353  0.000000   0.000000  0.597475  \n",
       "180          4.976454         2.253527  0.000000   0.000000  0.597475  \n",
       "270          5.770162         1.779643  0.002789   0.436735  0.597475  \n",
       "343          4.424427         3.249401  0.000000   0.000000  0.597475  \n",
       "424          4.502425         3.267106  0.000000   0.000000  0.597475  \n",
       "455          4.154043         3.647715  0.000000   0.000000  0.597475  \n",
       "624          4.970368         2.580901  0.000000   0.000000  0.597475  \n",
       "644          5.029567         2.776585  0.000000   0.000000  0.597475  \n",
       "806          5.281380         2.090691  0.000066   0.010405  0.597475  \n",
       "867          5.931446         1.571484  0.009474   1.505261  0.597475  \n",
       "955          5.771609         1.874388  0.012826   1.946196  0.597475  \n",
       "1049         5.880260         1.799916  0.000000   0.000000  0.597475  \n",
       "1116         6.323142         1.410745  0.012706   1.955407  0.597475  \n",
       "1224         6.126018         1.645955  0.000000   0.000000  0.597475  \n",
       "1287         5.869628         1.970704  0.002789   0.430965  0.597475  \n",
       "1399         5.661955         2.262850  0.000000   0.000000  0.597475  \n",
       "1508         5.690282         2.319972  0.020094   3.098183  0.597475  \n",
       "1564         6.537628         1.485810  0.000000   0.000000  0.597475  \n",
       "1648         5.122838         2.469447  0.002789   0.439400  0.597475  \n",
       "1775         5.640633         2.157219  0.002883   0.447362  0.597475  \n",
       "1856         6.768463         1.157318  0.000000   0.000000  0.597475  \n",
       "1918         7.115049         0.761904  0.016556   2.547258  0.597475  \n",
       "2064         5.163086         2.687012  0.013556   2.096965  0.597475  \n",
       "2110         6.044862         1.792052  0.002789   0.434211  0.597475  \n",
       "2244         5.040448         2.401446  0.000000   0.000000  0.597475  \n",
       "2300         6.469457         1.234645  0.000000   0.000000  0.597475  \n",
       "2446         5.380671         2.187688  0.000000   0.000000  0.597475  \n",
       "2543         6.564678         1.316182  0.000000   0.000000  0.597475  \n",
       "2589         5.759533         2.167224  0.016312   2.575895  0.597475  \n",
       "2674         6.730493         0.742163  0.000000   0.000000  0.597475  \n",
       "\n",
       "[2730 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.sort_index(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ll = newdata.groupby('query token', as_index=False)['diff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.merge(ll, on='query token', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initialUsedMemory</th>\n",
       "      <th>initialFreeMemory</th>\n",
       "      <th>query token</th>\n",
       "      <th>gcRun</th>\n",
       "      <th>cpuTimeTaken</th>\n",
       "      <th>finalUsedMemory</th>\n",
       "      <th>finalFreeMemory</th>\n",
       "      <th>diff_x</th>\n",
       "      <th>freq_x</th>\n",
       "      <th>freq_y</th>\n",
       "      <th>diff_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.249634</td>\n",
       "      <td>2.999878</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.371230</td>\n",
       "      <td>4.409714</td>\n",
       "      <td>2.839798</td>\n",
       "      <td>0.160080</td>\n",
       "      <td>0.431215</td>\n",
       "      <td>0.696677</td>\n",
       "      <td>0.136833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.409720</td>\n",
       "      <td>2.839792</td>\n",
       "      <td>token_2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.220883</td>\n",
       "      <td>4.482361</td>\n",
       "      <td>2.767151</td>\n",
       "      <td>0.072641</td>\n",
       "      <td>0.328867</td>\n",
       "      <td>0.527402</td>\n",
       "      <td>0.062817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.482361</td>\n",
       "      <td>2.767151</td>\n",
       "      <td>token_3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.141776</td>\n",
       "      <td>4.542626</td>\n",
       "      <td>2.706886</td>\n",
       "      <td>0.060265</td>\n",
       "      <td>0.425069</td>\n",
       "      <td>0.477051</td>\n",
       "      <td>0.055497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.542626</td>\n",
       "      <td>2.706886</td>\n",
       "      <td>token_4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.156459</td>\n",
       "      <td>4.616293</td>\n",
       "      <td>2.633218</td>\n",
       "      <td>0.073668</td>\n",
       "      <td>0.470844</td>\n",
       "      <td>0.513401</td>\n",
       "      <td>0.066184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.616296</td>\n",
       "      <td>2.633216</td>\n",
       "      <td>token_5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.285218</td>\n",
       "      <td>4.787172</td>\n",
       "      <td>2.462339</td>\n",
       "      <td>0.170877</td>\n",
       "      <td>0.599111</td>\n",
       "      <td>0.638627</td>\n",
       "      <td>0.158079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.787174</td>\n",
       "      <td>2.462337</td>\n",
       "      <td>token_6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.170063</td>\n",
       "      <td>4.902623</td>\n",
       "      <td>2.346889</td>\n",
       "      <td>0.115449</td>\n",
       "      <td>0.678856</td>\n",
       "      <td>0.725251</td>\n",
       "      <td>0.106769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.902623</td>\n",
       "      <td>2.346889</td>\n",
       "      <td>token_7</td>\n",
       "      <td>False</td>\n",
       "      <td>0.164785</td>\n",
       "      <td>4.977153</td>\n",
       "      <td>2.272359</td>\n",
       "      <td>0.074530</td>\n",
       "      <td>0.452285</td>\n",
       "      <td>0.486677</td>\n",
       "      <td>0.066470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.977155</td>\n",
       "      <td>2.272357</td>\n",
       "      <td>token_8</td>\n",
       "      <td>True</td>\n",
       "      <td>0.154474</td>\n",
       "      <td>4.168083</td>\n",
       "      <td>3.081428</td>\n",
       "      <td>-0.809071</td>\n",
       "      <td>-5.237581</td>\n",
       "      <td>0.755169</td>\n",
       "      <td>0.098450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.171586</td>\n",
       "      <td>3.077926</td>\n",
       "      <td>token_9</td>\n",
       "      <td>False</td>\n",
       "      <td>0.457611</td>\n",
       "      <td>4.520573</td>\n",
       "      <td>2.728938</td>\n",
       "      <td>0.348987</td>\n",
       "      <td>0.762630</td>\n",
       "      <td>0.744114</td>\n",
       "      <td>0.347700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.523625</td>\n",
       "      <td>2.725887</td>\n",
       "      <td>token_10</td>\n",
       "      <td>False</td>\n",
       "      <td>0.182251</td>\n",
       "      <td>4.621179</td>\n",
       "      <td>2.628333</td>\n",
       "      <td>0.097554</td>\n",
       "      <td>0.535273</td>\n",
       "      <td>0.530135</td>\n",
       "      <td>0.096914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.621179</td>\n",
       "      <td>2.628333</td>\n",
       "      <td>token_11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.190840</td>\n",
       "      <td>4.720848</td>\n",
       "      <td>2.528664</td>\n",
       "      <td>0.099669</td>\n",
       "      <td>0.522265</td>\n",
       "      <td>0.520126</td>\n",
       "      <td>0.098823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.720848</td>\n",
       "      <td>2.528664</td>\n",
       "      <td>token_12</td>\n",
       "      <td>False</td>\n",
       "      <td>0.207480</td>\n",
       "      <td>4.861294</td>\n",
       "      <td>2.388217</td>\n",
       "      <td>0.140446</td>\n",
       "      <td>0.676915</td>\n",
       "      <td>0.663138</td>\n",
       "      <td>0.139480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.861294</td>\n",
       "      <td>2.388217</td>\n",
       "      <td>token_13</td>\n",
       "      <td>False</td>\n",
       "      <td>0.121614</td>\n",
       "      <td>4.919907</td>\n",
       "      <td>2.329605</td>\n",
       "      <td>0.058613</td>\n",
       "      <td>0.481955</td>\n",
       "      <td>0.459128</td>\n",
       "      <td>0.056279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.919907</td>\n",
       "      <td>2.329605</td>\n",
       "      <td>token_14</td>\n",
       "      <td>False</td>\n",
       "      <td>0.227620</td>\n",
       "      <td>5.050119</td>\n",
       "      <td>2.199393</td>\n",
       "      <td>0.130212</td>\n",
       "      <td>0.572059</td>\n",
       "      <td>0.548274</td>\n",
       "      <td>0.128292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.050119</td>\n",
       "      <td>2.199393</td>\n",
       "      <td>token_15</td>\n",
       "      <td>True</td>\n",
       "      <td>0.275411</td>\n",
       "      <td>4.239779</td>\n",
       "      <td>3.009732</td>\n",
       "      <td>-0.810340</td>\n",
       "      <td>-2.942291</td>\n",
       "      <td>0.628202</td>\n",
       "      <td>0.171790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.243753</td>\n",
       "      <td>3.005758</td>\n",
       "      <td>token_16</td>\n",
       "      <td>False</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>4.277324</td>\n",
       "      <td>2.972188</td>\n",
       "      <td>0.033571</td>\n",
       "      <td>0.478212</td>\n",
       "      <td>0.455951</td>\n",
       "      <td>0.032086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.280944</td>\n",
       "      <td>2.968567</td>\n",
       "      <td>token_17</td>\n",
       "      <td>False</td>\n",
       "      <td>0.239481</td>\n",
       "      <td>4.462195</td>\n",
       "      <td>2.787316</td>\n",
       "      <td>0.181251</td>\n",
       "      <td>0.756849</td>\n",
       "      <td>0.742067</td>\n",
       "      <td>0.182763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.462195</td>\n",
       "      <td>2.787316</td>\n",
       "      <td>token_18</td>\n",
       "      <td>False</td>\n",
       "      <td>0.173965</td>\n",
       "      <td>4.582409</td>\n",
       "      <td>2.667103</td>\n",
       "      <td>0.120213</td>\n",
       "      <td>0.691018</td>\n",
       "      <td>0.668248</td>\n",
       "      <td>0.117840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.582409</td>\n",
       "      <td>2.667103</td>\n",
       "      <td>token_19</td>\n",
       "      <td>False</td>\n",
       "      <td>0.252222</td>\n",
       "      <td>4.750459</td>\n",
       "      <td>2.499053</td>\n",
       "      <td>0.168050</td>\n",
       "      <td>0.666280</td>\n",
       "      <td>0.649543</td>\n",
       "      <td>0.166037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.750459</td>\n",
       "      <td>2.499053</td>\n",
       "      <td>token_20</td>\n",
       "      <td>False</td>\n",
       "      <td>0.197709</td>\n",
       "      <td>4.907353</td>\n",
       "      <td>2.342159</td>\n",
       "      <td>0.156894</td>\n",
       "      <td>0.793558</td>\n",
       "      <td>0.780502</td>\n",
       "      <td>0.155978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.907353</td>\n",
       "      <td>2.342159</td>\n",
       "      <td>token_21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.206092</td>\n",
       "      <td>4.995290</td>\n",
       "      <td>2.254222</td>\n",
       "      <td>0.087937</td>\n",
       "      <td>0.426687</td>\n",
       "      <td>0.553914</td>\n",
       "      <td>0.085025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.995290</td>\n",
       "      <td>2.254222</td>\n",
       "      <td>token_22</td>\n",
       "      <td>False</td>\n",
       "      <td>0.096779</td>\n",
       "      <td>5.045302</td>\n",
       "      <td>2.204210</td>\n",
       "      <td>0.050012</td>\n",
       "      <td>0.516769</td>\n",
       "      <td>0.512298</td>\n",
       "      <td>0.049750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.045302</td>\n",
       "      <td>2.204210</td>\n",
       "      <td>token_23</td>\n",
       "      <td>True</td>\n",
       "      <td>0.592555</td>\n",
       "      <td>4.656779</td>\n",
       "      <td>2.592733</td>\n",
       "      <td>-0.388523</td>\n",
       "      <td>-0.655674</td>\n",
       "      <td>0.997292</td>\n",
       "      <td>0.593216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.662953</td>\n",
       "      <td>2.586559</td>\n",
       "      <td>token_24</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216461</td>\n",
       "      <td>4.789210</td>\n",
       "      <td>2.460302</td>\n",
       "      <td>0.126257</td>\n",
       "      <td>0.583279</td>\n",
       "      <td>0.586324</td>\n",
       "      <td>0.129217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.792982</td>\n",
       "      <td>2.456530</td>\n",
       "      <td>token_25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.086305</td>\n",
       "      <td>4.842613</td>\n",
       "      <td>2.406899</td>\n",
       "      <td>0.049631</td>\n",
       "      <td>0.575070</td>\n",
       "      <td>0.596526</td>\n",
       "      <td>0.052575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.842718</td>\n",
       "      <td>2.406794</td>\n",
       "      <td>token_26</td>\n",
       "      <td>False</td>\n",
       "      <td>0.026951</td>\n",
       "      <td>4.858456</td>\n",
       "      <td>2.391055</td>\n",
       "      <td>0.015738</td>\n",
       "      <td>0.583965</td>\n",
       "      <td>0.497912</td>\n",
       "      <td>0.013522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.858725</td>\n",
       "      <td>2.390786</td>\n",
       "      <td>token_27</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100673</td>\n",
       "      <td>4.911962</td>\n",
       "      <td>2.337550</td>\n",
       "      <td>0.053236</td>\n",
       "      <td>0.528805</td>\n",
       "      <td>0.527014</td>\n",
       "      <td>0.053245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.911962</td>\n",
       "      <td>2.337550</td>\n",
       "      <td>token_28</td>\n",
       "      <td>False</td>\n",
       "      <td>0.171593</td>\n",
       "      <td>5.001542</td>\n",
       "      <td>2.247970</td>\n",
       "      <td>0.089580</td>\n",
       "      <td>0.522051</td>\n",
       "      <td>0.513006</td>\n",
       "      <td>0.087936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.001671</td>\n",
       "      <td>2.247841</td>\n",
       "      <td>token_29</td>\n",
       "      <td>False</td>\n",
       "      <td>0.123160</td>\n",
       "      <td>5.065997</td>\n",
       "      <td>2.183514</td>\n",
       "      <td>0.064326</td>\n",
       "      <td>0.522299</td>\n",
       "      <td>0.496095</td>\n",
       "      <td>0.061535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.065997</td>\n",
       "      <td>2.183514</td>\n",
       "      <td>token_30</td>\n",
       "      <td>True</td>\n",
       "      <td>0.119891</td>\n",
       "      <td>4.149363</td>\n",
       "      <td>3.100148</td>\n",
       "      <td>-0.916634</td>\n",
       "      <td>-7.645565</td>\n",
       "      <td>0.637671</td>\n",
       "      <td>0.076020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>5.371504</td>\n",
       "      <td>2.235430</td>\n",
       "      <td>token_57</td>\n",
       "      <td>False</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>5.409899</td>\n",
       "      <td>2.197035</td>\n",
       "      <td>0.038395</td>\n",
       "      <td>0.474001</td>\n",
       "      <td>0.521422</td>\n",
       "      <td>0.042307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>5.409899</td>\n",
       "      <td>2.197035</td>\n",
       "      <td>token_87</td>\n",
       "      <td>False</td>\n",
       "      <td>0.119174</td>\n",
       "      <td>5.471979</td>\n",
       "      <td>2.134955</td>\n",
       "      <td>0.062080</td>\n",
       "      <td>0.520918</td>\n",
       "      <td>0.475054</td>\n",
       "      <td>0.057267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>5.471979</td>\n",
       "      <td>2.134955</td>\n",
       "      <td>token_10</td>\n",
       "      <td>False</td>\n",
       "      <td>0.181636</td>\n",
       "      <td>5.567664</td>\n",
       "      <td>2.039270</td>\n",
       "      <td>0.095685</td>\n",
       "      <td>0.526797</td>\n",
       "      <td>0.530135</td>\n",
       "      <td>0.096914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>5.567664</td>\n",
       "      <td>2.039270</td>\n",
       "      <td>token_71</td>\n",
       "      <td>False</td>\n",
       "      <td>0.144991</td>\n",
       "      <td>5.644413</td>\n",
       "      <td>1.962521</td>\n",
       "      <td>0.076749</td>\n",
       "      <td>0.529336</td>\n",
       "      <td>0.546155</td>\n",
       "      <td>0.080537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>5.644413</td>\n",
       "      <td>1.962521</td>\n",
       "      <td>token_82</td>\n",
       "      <td>False</td>\n",
       "      <td>0.139357</td>\n",
       "      <td>5.721961</td>\n",
       "      <td>1.884973</td>\n",
       "      <td>0.077548</td>\n",
       "      <td>0.556469</td>\n",
       "      <td>0.629907</td>\n",
       "      <td>0.087853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>5.721961</td>\n",
       "      <td>1.884973</td>\n",
       "      <td>token_5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.242884</td>\n",
       "      <td>5.875133</td>\n",
       "      <td>1.731801</td>\n",
       "      <td>0.153172</td>\n",
       "      <td>0.630638</td>\n",
       "      <td>0.638627</td>\n",
       "      <td>0.158079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>5.875133</td>\n",
       "      <td>1.731801</td>\n",
       "      <td>token_23</td>\n",
       "      <td>False</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>6.475813</td>\n",
       "      <td>1.131120</td>\n",
       "      <td>0.600681</td>\n",
       "      <td>1.020983</td>\n",
       "      <td>0.997292</td>\n",
       "      <td>0.593216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>6.475813</td>\n",
       "      <td>1.131120</td>\n",
       "      <td>token_18</td>\n",
       "      <td>False</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>6.601231</td>\n",
       "      <td>1.005703</td>\n",
       "      <td>0.125417</td>\n",
       "      <td>0.708272</td>\n",
       "      <td>0.668248</td>\n",
       "      <td>0.117840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>6.601231</td>\n",
       "      <td>1.005703</td>\n",
       "      <td>token_41</td>\n",
       "      <td>False</td>\n",
       "      <td>0.106106</td>\n",
       "      <td>6.658725</td>\n",
       "      <td>0.948209</td>\n",
       "      <td>0.057494</td>\n",
       "      <td>0.541859</td>\n",
       "      <td>0.518767</td>\n",
       "      <td>0.055362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>6.658725</td>\n",
       "      <td>0.948209</td>\n",
       "      <td>token_7</td>\n",
       "      <td>False</td>\n",
       "      <td>0.135733</td>\n",
       "      <td>6.722698</td>\n",
       "      <td>0.884236</td>\n",
       "      <td>0.063973</td>\n",
       "      <td>0.471312</td>\n",
       "      <td>0.486677</td>\n",
       "      <td>0.066470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>6.722698</td>\n",
       "      <td>0.884236</td>\n",
       "      <td>token_48</td>\n",
       "      <td>False</td>\n",
       "      <td>0.127899</td>\n",
       "      <td>6.784749</td>\n",
       "      <td>0.822184</td>\n",
       "      <td>0.062052</td>\n",
       "      <td>0.485159</td>\n",
       "      <td>0.520411</td>\n",
       "      <td>0.066828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>6.784749</td>\n",
       "      <td>0.822184</td>\n",
       "      <td>token_15</td>\n",
       "      <td>False</td>\n",
       "      <td>0.273149</td>\n",
       "      <td>6.962422</td>\n",
       "      <td>0.644512</td>\n",
       "      <td>0.177673</td>\n",
       "      <td>0.650461</td>\n",
       "      <td>0.628202</td>\n",
       "      <td>0.171790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>6.962422</td>\n",
       "      <td>0.644512</td>\n",
       "      <td>token_56</td>\n",
       "      <td>False</td>\n",
       "      <td>0.195532</td>\n",
       "      <td>7.080855</td>\n",
       "      <td>0.526078</td>\n",
       "      <td>0.118433</td>\n",
       "      <td>0.605699</td>\n",
       "      <td>0.609855</td>\n",
       "      <td>0.121039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>7.080857</td>\n",
       "      <td>0.526076</td>\n",
       "      <td>token_60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.111754</td>\n",
       "      <td>7.145726</td>\n",
       "      <td>0.461208</td>\n",
       "      <td>0.064868</td>\n",
       "      <td>0.580458</td>\n",
       "      <td>0.579365</td>\n",
       "      <td>0.065764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>7.145726</td>\n",
       "      <td>0.461208</td>\n",
       "      <td>token_65</td>\n",
       "      <td>False</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>7.200549</td>\n",
       "      <td>0.406384</td>\n",
       "      <td>0.054823</td>\n",
       "      <td>0.464902</td>\n",
       "      <td>0.459287</td>\n",
       "      <td>0.055122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>7.200549</td>\n",
       "      <td>0.406384</td>\n",
       "      <td>token_19</td>\n",
       "      <td>True</td>\n",
       "      <td>0.259157</td>\n",
       "      <td>5.148405</td>\n",
       "      <td>2.546419</td>\n",
       "      <td>-2.052144</td>\n",
       "      <td>-7.918545</td>\n",
       "      <td>0.649543</td>\n",
       "      <td>0.166037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>5.162250</td>\n",
       "      <td>2.532574</td>\n",
       "      <td>token_49</td>\n",
       "      <td>False</td>\n",
       "      <td>0.225001</td>\n",
       "      <td>5.300746</td>\n",
       "      <td>2.394079</td>\n",
       "      <td>0.138496</td>\n",
       "      <td>0.615533</td>\n",
       "      <td>0.660618</td>\n",
       "      <td>0.150208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>5.314320</td>\n",
       "      <td>2.380504</td>\n",
       "      <td>token_80</td>\n",
       "      <td>False</td>\n",
       "      <td>0.125304</td>\n",
       "      <td>5.395838</td>\n",
       "      <td>2.298986</td>\n",
       "      <td>0.081518</td>\n",
       "      <td>0.650561</td>\n",
       "      <td>0.655804</td>\n",
       "      <td>0.083546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>5.395867</td>\n",
       "      <td>2.298957</td>\n",
       "      <td>token_75</td>\n",
       "      <td>False</td>\n",
       "      <td>0.146119</td>\n",
       "      <td>5.475984</td>\n",
       "      <td>2.218840</td>\n",
       "      <td>0.080118</td>\n",
       "      <td>0.548303</td>\n",
       "      <td>0.526436</td>\n",
       "      <td>0.077532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>5.475984</td>\n",
       "      <td>2.218840</td>\n",
       "      <td>token_67</td>\n",
       "      <td>False</td>\n",
       "      <td>0.476469</td>\n",
       "      <td>5.891383</td>\n",
       "      <td>1.803442</td>\n",
       "      <td>0.415398</td>\n",
       "      <td>0.871826</td>\n",
       "      <td>0.860604</td>\n",
       "      <td>0.413457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>5.891383</td>\n",
       "      <td>1.803442</td>\n",
       "      <td>token_63</td>\n",
       "      <td>False</td>\n",
       "      <td>0.245653</td>\n",
       "      <td>6.085278</td>\n",
       "      <td>1.609547</td>\n",
       "      <td>0.193895</td>\n",
       "      <td>0.789305</td>\n",
       "      <td>0.739731</td>\n",
       "      <td>0.183607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>6.085278</td>\n",
       "      <td>1.609547</td>\n",
       "      <td>token_89</td>\n",
       "      <td>False</td>\n",
       "      <td>0.270267</td>\n",
       "      <td>6.275798</td>\n",
       "      <td>1.419027</td>\n",
       "      <td>0.190520</td>\n",
       "      <td>0.704932</td>\n",
       "      <td>0.704352</td>\n",
       "      <td>0.191045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>6.275798</td>\n",
       "      <td>1.419027</td>\n",
       "      <td>token_47</td>\n",
       "      <td>False</td>\n",
       "      <td>0.130559</td>\n",
       "      <td>6.339934</td>\n",
       "      <td>1.354890</td>\n",
       "      <td>0.064136</td>\n",
       "      <td>0.491244</td>\n",
       "      <td>0.508217</td>\n",
       "      <td>0.065990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>6.339934</td>\n",
       "      <td>1.354890</td>\n",
       "      <td>token_59</td>\n",
       "      <td>False</td>\n",
       "      <td>0.144823</td>\n",
       "      <td>6.409213</td>\n",
       "      <td>1.285612</td>\n",
       "      <td>0.069279</td>\n",
       "      <td>0.478367</td>\n",
       "      <td>0.514850</td>\n",
       "      <td>0.073842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>6.409213</td>\n",
       "      <td>1.285612</td>\n",
       "      <td>token_83</td>\n",
       "      <td>False</td>\n",
       "      <td>0.111179</td>\n",
       "      <td>6.463606</td>\n",
       "      <td>1.231218</td>\n",
       "      <td>0.054394</td>\n",
       "      <td>0.489242</td>\n",
       "      <td>0.449874</td>\n",
       "      <td>0.050758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>6.463606</td>\n",
       "      <td>1.231218</td>\n",
       "      <td>token_38</td>\n",
       "      <td>False</td>\n",
       "      <td>0.239648</td>\n",
       "      <td>6.594545</td>\n",
       "      <td>1.100279</td>\n",
       "      <td>0.130939</td>\n",
       "      <td>0.546380</td>\n",
       "      <td>0.590622</td>\n",
       "      <td>0.139106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>6.594548</td>\n",
       "      <td>1.100277</td>\n",
       "      <td>token_2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.117739</td>\n",
       "      <td>6.663855</td>\n",
       "      <td>1.030969</td>\n",
       "      <td>0.069308</td>\n",
       "      <td>0.588656</td>\n",
       "      <td>0.527402</td>\n",
       "      <td>0.062817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>6.663855</td>\n",
       "      <td>1.030969</td>\n",
       "      <td>token_64</td>\n",
       "      <td>False</td>\n",
       "      <td>0.109347</td>\n",
       "      <td>6.727963</td>\n",
       "      <td>0.966862</td>\n",
       "      <td>0.064107</td>\n",
       "      <td>0.586276</td>\n",
       "      <td>0.549358</td>\n",
       "      <td>0.060051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>6.727963</td>\n",
       "      <td>0.966862</td>\n",
       "      <td>token_42</td>\n",
       "      <td>False</td>\n",
       "      <td>0.371938</td>\n",
       "      <td>7.036368</td>\n",
       "      <td>0.658456</td>\n",
       "      <td>0.308405</td>\n",
       "      <td>0.829185</td>\n",
       "      <td>0.836047</td>\n",
       "      <td>0.309898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>7.036368</td>\n",
       "      <td>0.658456</td>\n",
       "      <td>token_68</td>\n",
       "      <td>False</td>\n",
       "      <td>0.115548</td>\n",
       "      <td>7.104307</td>\n",
       "      <td>0.590517</td>\n",
       "      <td>0.067939</td>\n",
       "      <td>0.587976</td>\n",
       "      <td>0.627657</td>\n",
       "      <td>0.069538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2730 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      initialUsedMemory  initialFreeMemory query token  gcRun  cpuTimeTaken  \\\n",
       "0              4.249634           2.999878     token_1  False      0.371230   \n",
       "1              4.409720           2.839792     token_2  False      0.220883   \n",
       "2              4.482361           2.767151     token_3  False      0.141776   \n",
       "3              4.542626           2.706886     token_4  False      0.156459   \n",
       "4              4.616296           2.633216     token_5  False      0.285218   \n",
       "5              4.787174           2.462337     token_6  False      0.170063   \n",
       "6              4.902623           2.346889     token_7  False      0.164785   \n",
       "7              4.977155           2.272357     token_8   True      0.154474   \n",
       "8              4.171586           3.077926     token_9  False      0.457611   \n",
       "9              4.523625           2.725887    token_10  False      0.182251   \n",
       "10             4.621179           2.628333    token_11  False      0.190840   \n",
       "11             4.720848           2.528664    token_12  False      0.207480   \n",
       "12             4.861294           2.388217    token_13  False      0.121614   \n",
       "13             4.919907           2.329605    token_14  False      0.227620   \n",
       "14             5.050119           2.199393    token_15   True      0.275411   \n",
       "15             4.243753           3.005758    token_16  False      0.070200   \n",
       "16             4.280944           2.968567    token_17  False      0.239481   \n",
       "17             4.462195           2.787316    token_18  False      0.173965   \n",
       "18             4.582409           2.667103    token_19  False      0.252222   \n",
       "19             4.750459           2.499053    token_20  False      0.197709   \n",
       "20             4.907353           2.342159    token_21  False      0.206092   \n",
       "21             4.995290           2.254222    token_22  False      0.096779   \n",
       "22             5.045302           2.204210    token_23   True      0.592555   \n",
       "23             4.662953           2.586559    token_24  False      0.216461   \n",
       "24             4.792982           2.456530    token_25  False      0.086305   \n",
       "25             4.842718           2.406794    token_26  False      0.026951   \n",
       "26             4.858725           2.390786    token_27  False      0.100673   \n",
       "27             4.911962           2.337550    token_28  False      0.171593   \n",
       "28             5.001671           2.247841    token_29  False      0.123160   \n",
       "29             5.065997           2.183514    token_30   True      0.119891   \n",
       "...                 ...                ...         ...    ...           ...   \n",
       "2700           5.371504           2.235430    token_57  False      0.081003   \n",
       "2701           5.409899           2.197035    token_87  False      0.119174   \n",
       "2702           5.471979           2.134955    token_10  False      0.181636   \n",
       "2703           5.567664           2.039270    token_71  False      0.144991   \n",
       "2704           5.644413           1.962521    token_82  False      0.139357   \n",
       "2705           5.721961           1.884973     token_5  False      0.242884   \n",
       "2706           5.875133           1.731801    token_23  False      0.588336   \n",
       "2707           6.475813           1.131120    token_18  False      0.177075   \n",
       "2708           6.601231           1.005703    token_41  False      0.106106   \n",
       "2709           6.658725           0.948209     token_7  False      0.135733   \n",
       "2710           6.722698           0.884236    token_48  False      0.127899   \n",
       "2711           6.784749           0.822184    token_15  False      0.273149   \n",
       "2712           6.962422           0.644512    token_56  False      0.195532   \n",
       "2713           7.080857           0.526076    token_60  False      0.111754   \n",
       "2714           7.145726           0.461208    token_65  False      0.117925   \n",
       "2715           7.200549           0.406384    token_19   True      0.259157   \n",
       "2716           5.162250           2.532574    token_49  False      0.225001   \n",
       "2717           5.314320           2.380504    token_80  False      0.125304   \n",
       "2718           5.395867           2.298957    token_75  False      0.146119   \n",
       "2719           5.475984           2.218840    token_67  False      0.476469   \n",
       "2720           5.891383           1.803442    token_63  False      0.245653   \n",
       "2721           6.085278           1.609547    token_89  False      0.270267   \n",
       "2722           6.275798           1.419027    token_47  False      0.130559   \n",
       "2723           6.339934           1.354890    token_59  False      0.144823   \n",
       "2724           6.409213           1.285612    token_83  False      0.111179   \n",
       "2725           6.463606           1.231218    token_38  False      0.239648   \n",
       "2726           6.594548           1.100277     token_2  False      0.117739   \n",
       "2727           6.663855           1.030969    token_64  False      0.109347   \n",
       "2728           6.727963           0.966862    token_42  False      0.371938   \n",
       "2729           7.036368           0.658456    token_68  False      0.115548   \n",
       "\n",
       "      finalUsedMemory  finalFreeMemory    diff_x    freq_x    freq_y    diff_y  \n",
       "0            4.409714         2.839798  0.160080  0.431215  0.696677  0.136833  \n",
       "1            4.482361         2.767151  0.072641  0.328867  0.527402  0.062817  \n",
       "2            4.542626         2.706886  0.060265  0.425069  0.477051  0.055497  \n",
       "3            4.616293         2.633218  0.073668  0.470844  0.513401  0.066184  \n",
       "4            4.787172         2.462339  0.170877  0.599111  0.638627  0.158079  \n",
       "5            4.902623         2.346889  0.115449  0.678856  0.725251  0.106769  \n",
       "6            4.977153         2.272359  0.074530  0.452285  0.486677  0.066470  \n",
       "7            4.168083         3.081428 -0.809071 -5.237581  0.755169  0.098450  \n",
       "8            4.520573         2.728938  0.348987  0.762630  0.744114  0.347700  \n",
       "9            4.621179         2.628333  0.097554  0.535273  0.530135  0.096914  \n",
       "10           4.720848         2.528664  0.099669  0.522265  0.520126  0.098823  \n",
       "11           4.861294         2.388217  0.140446  0.676915  0.663138  0.139480  \n",
       "12           4.919907         2.329605  0.058613  0.481955  0.459128  0.056279  \n",
       "13           5.050119         2.199393  0.130212  0.572059  0.548274  0.128292  \n",
       "14           4.239779         3.009732 -0.810340 -2.942291  0.628202  0.171790  \n",
       "15           4.277324         2.972188  0.033571  0.478212  0.455951  0.032086  \n",
       "16           4.462195         2.787316  0.181251  0.756849  0.742067  0.182763  \n",
       "17           4.582409         2.667103  0.120213  0.691018  0.668248  0.117840  \n",
       "18           4.750459         2.499053  0.168050  0.666280  0.649543  0.166037  \n",
       "19           4.907353         2.342159  0.156894  0.793558  0.780502  0.155978  \n",
       "20           4.995290         2.254222  0.087937  0.426687  0.553914  0.085025  \n",
       "21           5.045302         2.204210  0.050012  0.516769  0.512298  0.049750  \n",
       "22           4.656779         2.592733 -0.388523 -0.655674  0.997292  0.593216  \n",
       "23           4.789210         2.460302  0.126257  0.583279  0.586324  0.129217  \n",
       "24           4.842613         2.406899  0.049631  0.575070  0.596526  0.052575  \n",
       "25           4.858456         2.391055  0.015738  0.583965  0.497912  0.013522  \n",
       "26           4.911962         2.337550  0.053236  0.528805  0.527014  0.053245  \n",
       "27           5.001542         2.247970  0.089580  0.522051  0.513006  0.087936  \n",
       "28           5.065997         2.183514  0.064326  0.522299  0.496095  0.061535  \n",
       "29           4.149363         3.100148 -0.916634 -7.645565  0.637671  0.076020  \n",
       "...               ...              ...       ...       ...       ...       ...  \n",
       "2700         5.409899         2.197035  0.038395  0.474001  0.521422  0.042307  \n",
       "2701         5.471979         2.134955  0.062080  0.520918  0.475054  0.057267  \n",
       "2702         5.567664         2.039270  0.095685  0.526797  0.530135  0.096914  \n",
       "2703         5.644413         1.962521  0.076749  0.529336  0.546155  0.080537  \n",
       "2704         5.721961         1.884973  0.077548  0.556469  0.629907  0.087853  \n",
       "2705         5.875133         1.731801  0.153172  0.630638  0.638627  0.158079  \n",
       "2706         6.475813         1.131120  0.600681  1.020983  0.997292  0.593216  \n",
       "2707         6.601231         1.005703  0.125417  0.708272  0.668248  0.117840  \n",
       "2708         6.658725         0.948209  0.057494  0.541859  0.518767  0.055362  \n",
       "2709         6.722698         0.884236  0.063973  0.471312  0.486677  0.066470  \n",
       "2710         6.784749         0.822184  0.062052  0.485159  0.520411  0.066828  \n",
       "2711         6.962422         0.644512  0.177673  0.650461  0.628202  0.171790  \n",
       "2712         7.080855         0.526078  0.118433  0.605699  0.609855  0.121039  \n",
       "2713         7.145726         0.461208  0.064868  0.580458  0.579365  0.065764  \n",
       "2714         7.200549         0.406384  0.054823  0.464902  0.459287  0.055122  \n",
       "2715         5.148405         2.546419 -2.052144 -7.918545  0.649543  0.166037  \n",
       "2716         5.300746         2.394079  0.138496  0.615533  0.660618  0.150208  \n",
       "2717         5.395838         2.298986  0.081518  0.650561  0.655804  0.083546  \n",
       "2718         5.475984         2.218840  0.080118  0.548303  0.526436  0.077532  \n",
       "2719         5.891383         1.803442  0.415398  0.871826  0.860604  0.413457  \n",
       "2720         6.085278         1.609547  0.193895  0.789305  0.739731  0.183607  \n",
       "2721         6.275798         1.419027  0.190520  0.704932  0.704352  0.191045  \n",
       "2722         6.339934         1.354890  0.064136  0.491244  0.508217  0.065990  \n",
       "2723         6.409213         1.285612  0.069279  0.478367  0.514850  0.073842  \n",
       "2724         6.463606         1.231218  0.054394  0.489242  0.449874  0.050758  \n",
       "2725         6.594545         1.100279  0.130939  0.546380  0.590622  0.139106  \n",
       "2726         6.663855         1.030969  0.069308  0.588656  0.527402  0.062817  \n",
       "2727         6.727963         0.966862  0.064107  0.586276  0.549358  0.060051  \n",
       "2728         7.036368         0.658456  0.308405  0.829185  0.836047  0.309898  \n",
       "2729         7.104307         0.590517  0.067939  0.587976  0.627657  0.069538  \n",
       "\n",
       "[2730 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_index(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = result.drop(['freq_x', 'diff_x'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freeusedmemory = train_data['finalUsedMemory']\n",
    "finalfreememory = train_data['finalFreeMemory']\n",
    "traindata = train_data.drop(['finalUsedMemory', 'finalFreeMemory'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "traindata['query token'] = encoder.fit_transform(traindata['query token'].astype('str'))\n",
    "traindata['gcRun'] = encoder.fit_transform(traindata['gcRun'].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traindata = traindata.sort_index(axis=0)\n",
    "cols = traindata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindata = traindata.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.24963384e+00,   2.99987788e+00,   0.00000000e+00, ...,\n",
       "          3.71230016e-01,   6.96677061e-01,   1.36833050e-01],\n",
       "       [  4.40971984e+00,   2.83979188e+00,   1.10000000e+01, ...,\n",
       "          2.20883048e-01,   5.27401691e-01,   6.28169937e-02],\n",
       "       [  4.48236098e+00,   2.76715074e+00,   2.20000000e+01, ...,\n",
       "          1.41776299e-01,   4.77051433e-01,   5.54966052e-02],\n",
       "       ..., \n",
       "       [  6.66385527e+00,   1.03096895e+00,   6.00000000e+01, ...,\n",
       "          1.09346554e-01,   5.49357766e-01,   6.00511422e-02],\n",
       "       [  6.72796255e+00,   9.66861673e-01,   3.60000000e+01, ...,\n",
       "          3.71937577e-01,   8.36047402e-01,   3.09897915e-01],\n",
       "       [  7.03636777e+00,   6.58456445e-01,   6.40000000e+01, ...,\n",
       "          1.15547996e-01,   6.27657014e-01,   6.95381181e-02]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   4.249634   2.999878        0.0        0.0   0.371230   0.696677   \n",
      "2   4.409720   2.839792       11.0        0.0   0.220883   0.527402   \n",
      "3   4.482361   2.767151       22.0        0.0   0.141776   0.477051   \n",
      "4   4.542626   2.706886       33.0        0.0   0.156459   0.513401   \n",
      "5   4.616296   2.633216       44.0        0.0   0.285218   0.638627   \n",
      "\n",
      "   var7(t-1)   var1(t)  \n",
      "1   0.136833  4.409720  \n",
      "2   0.062817  4.482361  \n",
      "3   0.055497  4.542626  \n",
      "4   0.066184  4.616296  \n",
      "5   0.158079  4.787174  \n"
     ]
    }
   ],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from pandas import DataFrame, concat\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#scaled = scaler.fit_transform(traindata)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(traindata, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed1 = reframed.drop(reframed.columns[[8,9,10,11,12,13]], axis=1)\n",
    "print(reframed1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1, 7) (2000,) (729, 1, 7) (729,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed1.values\n",
    "n_train_hours = 2000\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 729 samples\n",
      "Epoch 1/300\n",
      "0s - loss: 5.2217 - val_loss: 5.3735\n",
      "Epoch 2/300\n",
      "0s - loss: 4.4091 - val_loss: 4.6809\n",
      "Epoch 3/300\n",
      "0s - loss: 3.7215 - val_loss: 3.5583\n",
      "Epoch 4/300\n",
      "0s - loss: 2.1868 - val_loss: 1.9337\n",
      "Epoch 5/300\n",
      "0s - loss: 1.0497 - val_loss: 1.0535\n",
      "Epoch 6/300\n",
      "0s - loss: 0.9319 - val_loss: 0.8765\n",
      "Epoch 7/300\n",
      "0s - loss: 0.9265 - val_loss: 0.8325\n",
      "Epoch 8/300\n",
      "0s - loss: 0.9472 - val_loss: 0.8292\n",
      "Epoch 9/300\n",
      "0s - loss: 0.9191 - val_loss: 0.8056\n",
      "Epoch 10/300\n",
      "0s - loss: 0.8926 - val_loss: 0.7713\n",
      "Epoch 11/300\n",
      "0s - loss: 0.9172 - val_loss: 0.7387\n",
      "Epoch 12/300\n",
      "0s - loss: 0.8819 - val_loss: 0.7332\n",
      "Epoch 13/300\n",
      "0s - loss: 0.9121 - val_loss: 0.7298\n",
      "Epoch 14/300\n",
      "0s - loss: 0.8439 - val_loss: 0.6789\n",
      "Epoch 15/300\n",
      "0s - loss: 0.8385 - val_loss: 0.6264\n",
      "Epoch 16/300\n",
      "0s - loss: 0.8466 - val_loss: 0.6194\n",
      "Epoch 17/300\n",
      "0s - loss: 0.8197 - val_loss: 0.5795\n",
      "Epoch 18/300\n",
      "0s - loss: 0.7866 - val_loss: 0.5405\n",
      "Epoch 19/300\n",
      "0s - loss: 0.7954 - val_loss: 0.5217\n",
      "Epoch 20/300\n",
      "0s - loss: 0.7652 - val_loss: 0.4955\n",
      "Epoch 21/300\n",
      "0s - loss: 0.7853 - val_loss: 0.4774\n",
      "Epoch 22/300\n",
      "0s - loss: 0.7421 - val_loss: 0.4536\n",
      "Epoch 23/300\n",
      "0s - loss: 0.7301 - val_loss: 0.4548\n",
      "Epoch 24/300\n",
      "0s - loss: 0.7395 - val_loss: 0.4301\n",
      "Epoch 25/300\n",
      "0s - loss: 0.7287 - val_loss: 0.4154\n",
      "Epoch 26/300\n",
      "0s - loss: 0.6863 - val_loss: 0.4169\n",
      "Epoch 27/300\n",
      "0s - loss: 0.6724 - val_loss: 0.4143\n",
      "Epoch 28/300\n",
      "0s - loss: 0.7195 - val_loss: 0.3978\n",
      "Epoch 29/300\n",
      "0s - loss: 0.7141 - val_loss: 0.3744\n",
      "Epoch 30/300\n",
      "0s - loss: 0.6911 - val_loss: 0.3718\n",
      "Epoch 31/300\n",
      "0s - loss: 0.6820 - val_loss: 0.3690\n",
      "Epoch 32/300\n",
      "0s - loss: 0.6754 - val_loss: 0.3557\n",
      "Epoch 33/300\n",
      "0s - loss: 0.6788 - val_loss: 0.3314\n",
      "Epoch 34/300\n",
      "0s - loss: 0.6563 - val_loss: 0.3431\n",
      "Epoch 35/300\n",
      "0s - loss: 0.6302 - val_loss: 0.3383\n",
      "Epoch 36/300\n",
      "0s - loss: 0.6387 - val_loss: 0.3225\n",
      "Epoch 37/300\n",
      "0s - loss: 0.6383 - val_loss: 0.3720\n",
      "Epoch 38/300\n",
      "0s - loss: 0.6170 - val_loss: 0.3096\n",
      "Epoch 39/300\n",
      "0s - loss: 0.6196 - val_loss: 0.3990\n",
      "Epoch 40/300\n",
      "0s - loss: 0.6248 - val_loss: 0.2993\n",
      "Epoch 41/300\n",
      "0s - loss: 0.6301 - val_loss: 0.2906\n",
      "Epoch 42/300\n",
      "0s - loss: 0.6116 - val_loss: 0.2995\n",
      "Epoch 43/300\n",
      "0s - loss: 0.6136 - val_loss: 0.2730\n",
      "Epoch 44/300\n",
      "0s - loss: 0.6107 - val_loss: 0.2912\n",
      "Epoch 45/300\n",
      "0s - loss: 0.6092 - val_loss: 0.3150\n",
      "Epoch 46/300\n",
      "0s - loss: 0.5991 - val_loss: 0.2539\n",
      "Epoch 47/300\n",
      "0s - loss: 0.6256 - val_loss: 0.3337\n",
      "Epoch 48/300\n",
      "0s - loss: 0.5878 - val_loss: 0.2807\n",
      "Epoch 49/300\n",
      "0s - loss: 0.6017 - val_loss: 0.2932\n",
      "Epoch 50/300\n",
      "0s - loss: 0.5879 - val_loss: 0.2508\n",
      "Epoch 51/300\n",
      "0s - loss: 0.5943 - val_loss: 0.2757\n",
      "Epoch 52/300\n",
      "0s - loss: 0.6079 - val_loss: 0.2782\n",
      "Epoch 53/300\n",
      "0s - loss: 0.5922 - val_loss: 0.2602\n",
      "Epoch 54/300\n",
      "0s - loss: 0.5922 - val_loss: 0.2509\n",
      "Epoch 55/300\n",
      "0s - loss: 0.5736 - val_loss: 0.2428\n",
      "Epoch 56/300\n",
      "0s - loss: 0.5832 - val_loss: 0.2196\n",
      "Epoch 57/300\n",
      "0s - loss: 0.6028 - val_loss: 0.2272\n",
      "Epoch 58/300\n",
      "0s - loss: 0.6127 - val_loss: 0.2499\n",
      "Epoch 59/300\n",
      "0s - loss: 0.5887 - val_loss: 0.2447\n",
      "Epoch 60/300\n",
      "0s - loss: 0.5831 - val_loss: 0.2535\n",
      "Epoch 61/300\n",
      "0s - loss: 0.5738 - val_loss: 0.2843\n",
      "Epoch 62/300\n",
      "0s - loss: 0.5748 - val_loss: 0.2432\n",
      "Epoch 63/300\n",
      "0s - loss: 0.5802 - val_loss: 0.2570\n",
      "Epoch 64/300\n",
      "0s - loss: 0.6069 - val_loss: 0.2363\n",
      "Epoch 65/300\n",
      "0s - loss: 0.5939 - val_loss: 0.2457\n",
      "Epoch 66/300\n",
      "0s - loss: 0.5871 - val_loss: 0.2493\n",
      "Epoch 67/300\n",
      "0s - loss: 0.5717 - val_loss: 0.2594\n",
      "Epoch 68/300\n",
      "0s - loss: 0.5770 - val_loss: 0.2221\n",
      "Epoch 69/300\n",
      "0s - loss: 0.5558 - val_loss: 0.2137\n",
      "Epoch 70/300\n",
      "0s - loss: 0.5753 - val_loss: 0.2505\n",
      "Epoch 71/300\n",
      "0s - loss: 0.5595 - val_loss: 0.2372\n",
      "Epoch 72/300\n",
      "0s - loss: 0.5750 - val_loss: 0.2223\n",
      "Epoch 73/300\n",
      "0s - loss: 0.5624 - val_loss: 0.2503\n",
      "Epoch 74/300\n",
      "0s - loss: 0.5834 - val_loss: 0.2298\n",
      "Epoch 75/300\n",
      "0s - loss: 0.5604 - val_loss: 0.2642\n",
      "Epoch 76/300\n",
      "0s - loss: 0.5572 - val_loss: 0.2250\n",
      "Epoch 77/300\n",
      "0s - loss: 0.5782 - val_loss: 0.2388\n",
      "Epoch 78/300\n",
      "0s - loss: 0.5688 - val_loss: 0.2138\n",
      "Epoch 79/300\n",
      "0s - loss: 0.5553 - val_loss: 0.2244\n",
      "Epoch 80/300\n",
      "0s - loss: 0.5743 - val_loss: 0.2220\n",
      "Epoch 81/300\n",
      "0s - loss: 0.5719 - val_loss: 0.2226\n",
      "Epoch 82/300\n",
      "0s - loss: 0.5687 - val_loss: 0.1894\n",
      "Epoch 83/300\n",
      "0s - loss: 0.5406 - val_loss: 0.2065\n",
      "Epoch 84/300\n",
      "0s - loss: 0.5547 - val_loss: 0.2072\n",
      "Epoch 85/300\n",
      "0s - loss: 0.5522 - val_loss: 0.2149\n",
      "Epoch 86/300\n",
      "0s - loss: 0.5438 - val_loss: 0.2585\n",
      "Epoch 87/300\n",
      "0s - loss: 0.5530 - val_loss: 0.2023\n",
      "Epoch 88/300\n",
      "0s - loss: 0.5457 - val_loss: 0.2434\n",
      "Epoch 89/300\n",
      "0s - loss: 0.5242 - val_loss: 0.2373\n",
      "Epoch 90/300\n",
      "0s - loss: 0.5471 - val_loss: 0.2005\n",
      "Epoch 91/300\n",
      "0s - loss: 0.5405 - val_loss: 0.1936\n",
      "Epoch 92/300\n",
      "0s - loss: 0.5473 - val_loss: 0.2030\n",
      "Epoch 93/300\n",
      "0s - loss: 0.5387 - val_loss: 0.2014\n",
      "Epoch 94/300\n",
      "0s - loss: 0.5456 - val_loss: 0.2013\n",
      "Epoch 95/300\n",
      "0s - loss: 0.5223 - val_loss: 0.2051\n",
      "Epoch 96/300\n",
      "0s - loss: 0.5476 - val_loss: 0.2172\n",
      "Epoch 97/300\n",
      "0s - loss: 0.5377 - val_loss: 0.2108\n",
      "Epoch 98/300\n",
      "0s - loss: 0.5377 - val_loss: 0.2287\n",
      "Epoch 99/300\n",
      "0s - loss: 0.5320 - val_loss: 0.1961\n",
      "Epoch 100/300\n",
      "0s - loss: 0.5278 - val_loss: 0.2008\n",
      "Epoch 101/300\n",
      "0s - loss: 0.5328 - val_loss: 0.2321\n",
      "Epoch 102/300\n",
      "0s - loss: 0.5161 - val_loss: 0.2024\n",
      "Epoch 103/300\n",
      "0s - loss: 0.5414 - val_loss: 0.1899\n",
      "Epoch 104/300\n",
      "0s - loss: 0.5064 - val_loss: 0.1845\n",
      "Epoch 105/300\n",
      "0s - loss: 0.5197 - val_loss: 0.1953\n",
      "Epoch 106/300\n",
      "0s - loss: 0.5248 - val_loss: 0.1887\n",
      "Epoch 107/300\n",
      "0s - loss: 0.5064 - val_loss: 0.1984\n",
      "Epoch 108/300\n",
      "0s - loss: 0.5118 - val_loss: 0.1679\n",
      "Epoch 109/300\n",
      "0s - loss: 0.5066 - val_loss: 0.1729\n",
      "Epoch 110/300\n",
      "0s - loss: 0.5193 - val_loss: 0.1698\n",
      "Epoch 111/300\n",
      "0s - loss: 0.5108 - val_loss: 0.1707\n",
      "Epoch 112/300\n",
      "0s - loss: 0.5176 - val_loss: 0.1790\n",
      "Epoch 113/300\n",
      "0s - loss: 0.5010 - val_loss: 0.1763\n",
      "Epoch 114/300\n",
      "0s - loss: 0.5005 - val_loss: 0.1669\n",
      "Epoch 115/300\n",
      "0s - loss: 0.5010 - val_loss: 0.2391\n",
      "Epoch 116/300\n",
      "0s - loss: 0.4948 - val_loss: 0.1801\n",
      "Epoch 117/300\n",
      "0s - loss: 0.5133 - val_loss: 0.1801\n",
      "Epoch 118/300\n",
      "0s - loss: 0.5072 - val_loss: 0.1645\n",
      "Epoch 119/300\n",
      "0s - loss: 0.5101 - val_loss: 0.1631\n",
      "Epoch 120/300\n",
      "0s - loss: 0.5040 - val_loss: 0.1529\n",
      "Epoch 121/300\n",
      "0s - loss: 0.4879 - val_loss: 0.1455\n",
      "Epoch 122/300\n",
      "0s - loss: 0.4818 - val_loss: 0.1953\n",
      "Epoch 123/300\n",
      "0s - loss: 0.4992 - val_loss: 0.1590\n",
      "Epoch 124/300\n",
      "0s - loss: 0.5200 - val_loss: 0.1453\n",
      "Epoch 125/300\n",
      "0s - loss: 0.4824 - val_loss: 0.2199\n",
      "Epoch 126/300\n",
      "0s - loss: 0.4895 - val_loss: 0.1503\n",
      "Epoch 127/300\n",
      "0s - loss: 0.4992 - val_loss: 0.1319\n",
      "Epoch 128/300\n",
      "0s - loss: 0.4973 - val_loss: 0.1263\n",
      "Epoch 129/300\n",
      "0s - loss: 0.5051 - val_loss: 0.1405\n",
      "Epoch 130/300\n",
      "0s - loss: 0.4924 - val_loss: 0.1356\n",
      "Epoch 131/300\n",
      "0s - loss: 0.4675 - val_loss: 0.1342\n",
      "Epoch 132/300\n",
      "0s - loss: 0.4842 - val_loss: 0.1218\n",
      "Epoch 133/300\n",
      "0s - loss: 0.4802 - val_loss: 0.1413\n",
      "Epoch 134/300\n",
      "0s - loss: 0.4738 - val_loss: 0.1477\n",
      "Epoch 135/300\n",
      "0s - loss: 0.4913 - val_loss: 0.1481\n",
      "Epoch 136/300\n",
      "0s - loss: 0.4737 - val_loss: 0.1475\n",
      "Epoch 137/300\n",
      "0s - loss: 0.4762 - val_loss: 0.1628\n",
      "Epoch 138/300\n",
      "0s - loss: 0.4591 - val_loss: 0.1861\n",
      "Epoch 139/300\n",
      "0s - loss: 0.4751 - val_loss: 0.1294\n",
      "Epoch 140/300\n",
      "0s - loss: 0.4713 - val_loss: 0.1556\n",
      "Epoch 141/300\n",
      "0s - loss: 0.4674 - val_loss: 0.1350\n",
      "Epoch 142/300\n",
      "0s - loss: 0.4726 - val_loss: 0.1748\n",
      "Epoch 143/300\n",
      "0s - loss: 0.4773 - val_loss: 0.1595\n",
      "Epoch 144/300\n",
      "0s - loss: 0.4649 - val_loss: 0.1507\n",
      "Epoch 145/300\n",
      "0s - loss: 0.4631 - val_loss: 0.1296\n",
      "Epoch 146/300\n",
      "0s - loss: 0.4572 - val_loss: 0.1232\n",
      "Epoch 147/300\n",
      "0s - loss: 0.4723 - val_loss: 0.1291\n",
      "Epoch 148/300\n",
      "0s - loss: 0.4587 - val_loss: 0.1319\n",
      "Epoch 149/300\n",
      "0s - loss: 0.4524 - val_loss: 0.1065\n",
      "Epoch 150/300\n",
      "0s - loss: 0.4635 - val_loss: 0.2248\n",
      "Epoch 151/300\n",
      "0s - loss: 0.4476 - val_loss: 0.1190\n",
      "Epoch 152/300\n",
      "0s - loss: 0.4590 - val_loss: 0.1293\n",
      "Epoch 153/300\n",
      "0s - loss: 0.4649 - val_loss: 0.1117\n",
      "Epoch 154/300\n",
      "0s - loss: 0.4489 - val_loss: 0.1505\n",
      "Epoch 155/300\n",
      "0s - loss: 0.4302 - val_loss: 0.1560\n",
      "Epoch 156/300\n",
      "0s - loss: 0.4458 - val_loss: 0.1193\n",
      "Epoch 157/300\n",
      "0s - loss: 0.4519 - val_loss: 0.1632\n",
      "Epoch 158/300\n",
      "0s - loss: 0.4413 - val_loss: 0.1646\n",
      "Epoch 159/300\n",
      "0s - loss: 0.4420 - val_loss: 0.1467\n",
      "Epoch 160/300\n",
      "0s - loss: 0.4641 - val_loss: 0.1173\n",
      "Epoch 161/300\n",
      "0s - loss: 0.4538 - val_loss: 0.1143\n",
      "Epoch 162/300\n",
      "0s - loss: 0.4555 - val_loss: 0.1739\n",
      "Epoch 163/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.4298 - val_loss: 0.1125\n",
      "Epoch 164/300\n",
      "0s - loss: 0.4480 - val_loss: 0.1427\n",
      "Epoch 165/300\n",
      "0s - loss: 0.4286 - val_loss: 0.1060\n",
      "Epoch 166/300\n",
      "0s - loss: 0.4495 - val_loss: 0.1670\n",
      "Epoch 167/300\n",
      "0s - loss: 0.4457 - val_loss: 0.1087\n",
      "Epoch 168/300\n",
      "0s - loss: 0.4518 - val_loss: 0.1470\n",
      "Epoch 169/300\n",
      "0s - loss: 0.4511 - val_loss: 0.1252\n",
      "Epoch 170/300\n",
      "0s - loss: 0.4455 - val_loss: 0.1522\n",
      "Epoch 171/300\n",
      "0s - loss: 0.4503 - val_loss: 0.1119\n",
      "Epoch 172/300\n",
      "0s - loss: 0.4325 - val_loss: 0.1159\n",
      "Epoch 173/300\n",
      "0s - loss: 0.4466 - val_loss: 0.1822\n",
      "Epoch 174/300\n",
      "0s - loss: 0.4462 - val_loss: 0.1284\n",
      "Epoch 175/300\n",
      "0s - loss: 0.4251 - val_loss: 0.1492\n",
      "Epoch 176/300\n",
      "0s - loss: 0.4296 - val_loss: 0.1410\n",
      "Epoch 177/300\n",
      "0s - loss: 0.4307 - val_loss: 0.1102\n",
      "Epoch 178/300\n",
      "0s - loss: 0.4393 - val_loss: 0.1255\n",
      "Epoch 179/300\n",
      "0s - loss: 0.4416 - val_loss: 0.1187\n",
      "Epoch 180/300\n",
      "0s - loss: 0.4361 - val_loss: 0.1037\n",
      "Epoch 181/300\n",
      "0s - loss: 0.4191 - val_loss: 0.1113\n",
      "Epoch 182/300\n",
      "0s - loss: 0.4280 - val_loss: 0.1037\n",
      "Epoch 183/300\n",
      "0s - loss: 0.4408 - val_loss: 0.1090\n",
      "Epoch 184/300\n",
      "0s - loss: 0.4333 - val_loss: 0.1071\n",
      "Epoch 185/300\n",
      "0s - loss: 0.4323 - val_loss: 0.1487\n",
      "Epoch 186/300\n",
      "0s - loss: 0.4212 - val_loss: 0.1051\n",
      "Epoch 187/300\n",
      "0s - loss: 0.4187 - val_loss: 0.1100\n",
      "Epoch 188/300\n",
      "0s - loss: 0.4100 - val_loss: 0.1637\n",
      "Epoch 189/300\n",
      "0s - loss: 0.4327 - val_loss: 0.1054\n",
      "Epoch 190/300\n",
      "0s - loss: 0.4191 - val_loss: 0.1132\n",
      "Epoch 191/300\n",
      "0s - loss: 0.4218 - val_loss: 0.1146\n",
      "Epoch 192/300\n",
      "0s - loss: 0.4093 - val_loss: 0.1119\n",
      "Epoch 193/300\n",
      "0s - loss: 0.4157 - val_loss: 0.1242\n",
      "Epoch 194/300\n",
      "0s - loss: 0.4223 - val_loss: 0.1152\n",
      "Epoch 195/300\n",
      "0s - loss: 0.4039 - val_loss: 0.1002\n",
      "Epoch 196/300\n",
      "0s - loss: 0.4196 - val_loss: 0.1256\n",
      "Epoch 197/300\n",
      "0s - loss: 0.4076 - val_loss: 0.1212\n",
      "Epoch 198/300\n",
      "0s - loss: 0.4149 - val_loss: 0.1213\n",
      "Epoch 199/300\n",
      "0s - loss: 0.4290 - val_loss: 0.0977\n",
      "Epoch 200/300\n",
      "0s - loss: 0.4183 - val_loss: 0.1350\n",
      "Epoch 201/300\n",
      "0s - loss: 0.4073 - val_loss: 0.1256\n",
      "Epoch 202/300\n",
      "0s - loss: 0.4080 - val_loss: 0.1398\n",
      "Epoch 203/300\n",
      "0s - loss: 0.4233 - val_loss: 0.1097\n",
      "Epoch 204/300\n",
      "0s - loss: 0.4103 - val_loss: 0.1268\n",
      "Epoch 205/300\n",
      "0s - loss: 0.4001 - val_loss: 0.1085\n",
      "Epoch 206/300\n",
      "0s - loss: 0.4105 - val_loss: 0.1136\n",
      "Epoch 207/300\n",
      "0s - loss: 0.4132 - val_loss: 0.1031\n",
      "Epoch 208/300\n",
      "0s - loss: 0.3986 - val_loss: 0.1052\n",
      "Epoch 209/300\n",
      "0s - loss: 0.3913 - val_loss: 0.1100\n",
      "Epoch 210/300\n",
      "0s - loss: 0.4012 - val_loss: 0.1056\n",
      "Epoch 211/300\n",
      "0s - loss: 0.3992 - val_loss: 0.1102\n",
      "Epoch 212/300\n",
      "0s - loss: 0.3922 - val_loss: 0.0959\n",
      "Epoch 213/300\n",
      "0s - loss: 0.4014 - val_loss: 0.0949\n",
      "Epoch 214/300\n",
      "0s - loss: 0.3868 - val_loss: 0.1342\n",
      "Epoch 215/300\n",
      "0s - loss: 0.3899 - val_loss: 0.1129\n",
      "Epoch 216/300\n",
      "0s - loss: 0.3879 - val_loss: 0.1183\n",
      "Epoch 217/300\n",
      "0s - loss: 0.3878 - val_loss: 0.1057\n",
      "Epoch 218/300\n",
      "0s - loss: 0.3790 - val_loss: 0.1145\n",
      "Epoch 219/300\n",
      "0s - loss: 0.4004 - val_loss: 0.1042\n",
      "Epoch 220/300\n",
      "0s - loss: 0.3980 - val_loss: 0.1013\n",
      "Epoch 221/300\n",
      "0s - loss: 0.3925 - val_loss: 0.1174\n",
      "Epoch 222/300\n",
      "0s - loss: 0.3964 - val_loss: 0.1166\n",
      "Epoch 223/300\n",
      "0s - loss: 0.4037 - val_loss: 0.1051\n",
      "Epoch 224/300\n",
      "0s - loss: 0.3869 - val_loss: 0.0894\n",
      "Epoch 225/300\n",
      "0s - loss: 0.3823 - val_loss: 0.0909\n",
      "Epoch 226/300\n",
      "0s - loss: 0.3945 - val_loss: 0.1099\n",
      "Epoch 227/300\n",
      "0s - loss: 0.3885 - val_loss: 0.1122\n",
      "Epoch 228/300\n",
      "0s - loss: 0.3656 - val_loss: 0.1008\n",
      "Epoch 229/300\n",
      "0s - loss: 0.3847 - val_loss: 0.1317\n",
      "Epoch 230/300\n",
      "0s - loss: 0.3963 - val_loss: 0.1230\n",
      "Epoch 231/300\n",
      "0s - loss: 0.3894 - val_loss: 0.1101\n",
      "Epoch 232/300\n",
      "0s - loss: 0.3896 - val_loss: 0.1099\n",
      "Epoch 233/300\n",
      "0s - loss: 0.3814 - val_loss: 0.1075\n",
      "Epoch 234/300\n",
      "0s - loss: 0.4038 - val_loss: 0.1071\n",
      "Epoch 235/300\n",
      "0s - loss: 0.3809 - val_loss: 0.1013\n",
      "Epoch 236/300\n",
      "0s - loss: 0.3825 - val_loss: 0.0995\n",
      "Epoch 237/300\n",
      "0s - loss: 0.3746 - val_loss: 0.1057\n",
      "Epoch 238/300\n",
      "0s - loss: 0.3781 - val_loss: 0.0968\n",
      "Epoch 239/300\n",
      "0s - loss: 0.3774 - val_loss: 0.1188\n",
      "Epoch 240/300\n",
      "0s - loss: 0.3551 - val_loss: 0.1035\n",
      "Epoch 241/300\n",
      "0s - loss: 0.3675 - val_loss: 0.1232\n",
      "Epoch 242/300\n",
      "0s - loss: 0.3642 - val_loss: 0.0967\n",
      "Epoch 243/300\n",
      "0s - loss: 0.3619 - val_loss: 0.1049\n",
      "Epoch 244/300\n",
      "0s - loss: 0.3747 - val_loss: 0.1156\n",
      "Epoch 245/300\n",
      "0s - loss: 0.3630 - val_loss: 0.1154\n",
      "Epoch 246/300\n",
      "0s - loss: 0.3650 - val_loss: 0.1016\n",
      "Epoch 247/300\n",
      "0s - loss: 0.3732 - val_loss: 0.0985\n",
      "Epoch 248/300\n",
      "0s - loss: 0.3728 - val_loss: 0.1061\n",
      "Epoch 249/300\n",
      "0s - loss: 0.3819 - val_loss: 0.1013\n",
      "Epoch 250/300\n",
      "0s - loss: 0.3707 - val_loss: 0.1046\n",
      "Epoch 251/300\n",
      "0s - loss: 0.3624 - val_loss: 0.1115\n",
      "Epoch 252/300\n",
      "0s - loss: 0.3621 - val_loss: 0.1098\n",
      "Epoch 253/300\n",
      "0s - loss: 0.3615 - val_loss: 0.0927\n",
      "Epoch 254/300\n",
      "0s - loss: 0.3730 - val_loss: 0.0925\n",
      "Epoch 255/300\n",
      "0s - loss: 0.3597 - val_loss: 0.0925\n",
      "Epoch 256/300\n",
      "0s - loss: 0.3602 - val_loss: 0.0965\n",
      "Epoch 257/300\n",
      "0s - loss: 0.3497 - val_loss: 0.0925\n",
      "Epoch 258/300\n",
      "0s - loss: 0.3521 - val_loss: 0.1138\n",
      "Epoch 259/300\n",
      "0s - loss: 0.3598 - val_loss: 0.0952\n",
      "Epoch 260/300\n",
      "0s - loss: 0.3630 - val_loss: 0.0943\n",
      "Epoch 261/300\n",
      "0s - loss: 0.3604 - val_loss: 0.0919\n",
      "Epoch 262/300\n",
      "0s - loss: 0.3739 - val_loss: 0.1185\n",
      "Epoch 263/300\n",
      "0s - loss: 0.3786 - val_loss: 0.0960\n",
      "Epoch 264/300\n",
      "0s - loss: 0.3506 - val_loss: 0.0965\n",
      "Epoch 265/300\n",
      "0s - loss: 0.3552 - val_loss: 0.1006\n",
      "Epoch 266/300\n",
      "0s - loss: 0.3720 - val_loss: 0.1046\n",
      "Epoch 267/300\n",
      "0s - loss: 0.3633 - val_loss: 0.0962\n",
      "Epoch 268/300\n",
      "0s - loss: 0.3578 - val_loss: 0.1004\n",
      "Epoch 269/300\n",
      "0s - loss: 0.3825 - val_loss: 0.1073\n",
      "Epoch 270/300\n",
      "0s - loss: 0.3607 - val_loss: 0.1009\n",
      "Epoch 271/300\n",
      "0s - loss: 0.3539 - val_loss: 0.0941\n",
      "Epoch 272/300\n",
      "0s - loss: 0.3489 - val_loss: 0.1030\n",
      "Epoch 273/300\n",
      "0s - loss: 0.3444 - val_loss: 0.0948\n",
      "Epoch 274/300\n",
      "0s - loss: 0.3545 - val_loss: 0.0979\n",
      "Epoch 275/300\n",
      "0s - loss: 0.3491 - val_loss: 0.1012\n",
      "Epoch 276/300\n",
      "0s - loss: 0.3555 - val_loss: 0.1047\n",
      "Epoch 277/300\n",
      "0s - loss: 0.3678 - val_loss: 0.1397\n",
      "Epoch 278/300\n",
      "0s - loss: 0.3668 - val_loss: 0.1071\n",
      "Epoch 279/300\n",
      "0s - loss: 0.3476 - val_loss: 0.1058\n",
      "Epoch 280/300\n",
      "0s - loss: 0.3549 - val_loss: 0.1010\n",
      "Epoch 281/300\n",
      "0s - loss: 0.3487 - val_loss: 0.0953\n",
      "Epoch 282/300\n",
      "0s - loss: 0.3455 - val_loss: 0.0965\n",
      "Epoch 283/300\n",
      "0s - loss: 0.3432 - val_loss: 0.1040\n",
      "Epoch 284/300\n",
      "0s - loss: 0.3589 - val_loss: 0.1115\n",
      "Epoch 285/300\n",
      "0s - loss: 0.3558 - val_loss: 0.1110\n",
      "Epoch 286/300\n",
      "0s - loss: 0.3535 - val_loss: 0.1015\n",
      "Epoch 287/300\n",
      "0s - loss: 0.3455 - val_loss: 0.1094\n",
      "Epoch 288/300\n",
      "0s - loss: 0.3508 - val_loss: 0.0955\n",
      "Epoch 289/300\n",
      "0s - loss: 0.3498 - val_loss: 0.0951\n",
      "Epoch 290/300\n",
      "0s - loss: 0.3365 - val_loss: 0.0950\n",
      "Epoch 291/300\n",
      "0s - loss: 0.3419 - val_loss: 0.0933\n",
      "Epoch 292/300\n",
      "0s - loss: 0.3415 - val_loss: 0.0930\n",
      "Epoch 293/300\n",
      "0s - loss: 0.3262 - val_loss: 0.0881\n",
      "Epoch 294/300\n",
      "0s - loss: 0.3358 - val_loss: 0.1081\n",
      "Epoch 295/300\n",
      "0s - loss: 0.3422 - val_loss: 0.0916\n",
      "Epoch 296/300\n",
      "0s - loss: 0.3328 - val_loss: 0.0931\n",
      "Epoch 297/300\n",
      "0s - loss: 0.3411 - val_loss: 0.0903\n",
      "Epoch 298/300\n",
      "0s - loss: 0.3344 - val_loss: 0.0991\n",
      "Epoch 299/300\n",
      "0s - loss: 0.3305 - val_loss: 0.1025\n",
      "Epoch 300/300\n",
      "0s - loss: 0.3484 - val_loss: 0.0969\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f30d64de588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(15, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(1))\n",
    "model1.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model1.fit(train_X, train_y, epochs=300, batch_size=64, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.122\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model1.predict(test_X)\n",
    "rmse = sqrt(mean_squared_error(test_y, yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   4.249634   2.999878        0.0        0.0   0.371230   0.696677   \n",
      "2   4.409720   2.839792       11.0        0.0   0.220883   0.527402   \n",
      "3   4.482361   2.767151       22.0        0.0   0.141776   0.477051   \n",
      "4   4.542626   2.706886       33.0        0.0   0.156459   0.513401   \n",
      "5   4.616296   2.633216       44.0        0.0   0.285218   0.638627   \n",
      "\n",
      "   var7(t-1)   var1(t)   var2(t)  \n",
      "1   0.136833  4.409720  2.839792  \n",
      "2   0.062817  4.482361  2.767151  \n",
      "3   0.055497  4.542626  2.706886  \n",
      "4   0.066184  4.616296  2.633216  \n",
      "5   0.158079  4.787174  2.462337  \n"
     ]
    }
   ],
   "source": [
    "reframed2 = reframed.drop(reframed.columns[[9,10,11,12,13]], axis=1)\n",
    "print(reframed2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1, 8) (2000,) (729, 1, 8) (729,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed2.values\n",
    "n_train_hours = 2000\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 729 samples\n",
      "Epoch 1/300\n",
      "0s - loss: 1.0200 - val_loss: 0.6365\n",
      "Epoch 2/300\n",
      "0s - loss: 0.8440 - val_loss: 0.6137\n",
      "Epoch 3/300\n",
      "0s - loss: 0.7297 - val_loss: 0.6360\n",
      "Epoch 4/300\n",
      "0s - loss: 0.6766 - val_loss: 0.6242\n",
      "Epoch 5/300\n",
      "0s - loss: 0.6612 - val_loss: 0.6203\n",
      "Epoch 6/300\n",
      "0s - loss: 0.6495 - val_loss: 0.6123\n",
      "Epoch 7/300\n",
      "0s - loss: 0.6313 - val_loss: 0.6052\n",
      "Epoch 8/300\n",
      "0s - loss: 0.6248 - val_loss: 0.5889\n",
      "Epoch 9/300\n",
      "0s - loss: 0.5894 - val_loss: 0.4770\n",
      "Epoch 10/300\n",
      "0s - loss: 0.5182 - val_loss: 0.3672\n",
      "Epoch 11/300\n",
      "0s - loss: 0.4831 - val_loss: 0.3427\n",
      "Epoch 12/300\n",
      "0s - loss: 0.4521 - val_loss: 0.3121\n",
      "Epoch 13/300\n",
      "0s - loss: 0.4170 - val_loss: 0.2803\n",
      "Epoch 14/300\n",
      "0s - loss: 0.3826 - val_loss: 0.2633\n",
      "Epoch 15/300\n",
      "0s - loss: 0.3627 - val_loss: 0.2333\n",
      "Epoch 16/300\n",
      "0s - loss: 0.3459 - val_loss: 0.2134\n",
      "Epoch 17/300\n",
      "0s - loss: 0.3428 - val_loss: 0.2127\n",
      "Epoch 18/300\n",
      "0s - loss: 0.3298 - val_loss: 0.1916\n",
      "Epoch 19/300\n",
      "0s - loss: 0.3295 - val_loss: 0.1711\n",
      "Epoch 20/300\n",
      "0s - loss: 0.3124 - val_loss: 0.1560\n",
      "Epoch 21/300\n",
      "0s - loss: 0.3152 - val_loss: 0.1453\n",
      "Epoch 22/300\n",
      "0s - loss: 0.3045 - val_loss: 0.1419\n",
      "Epoch 23/300\n",
      "0s - loss: 0.3056 - val_loss: 0.1284\n",
      "Epoch 24/300\n",
      "0s - loss: 0.2959 - val_loss: 0.1285\n",
      "Epoch 25/300\n",
      "0s - loss: 0.2947 - val_loss: 0.1094\n",
      "Epoch 26/300\n",
      "0s - loss: 0.2975 - val_loss: 0.1152\n",
      "Epoch 27/300\n",
      "0s - loss: 0.2772 - val_loss: 0.0997\n",
      "Epoch 28/300\n",
      "0s - loss: 0.2863 - val_loss: 0.1020\n",
      "Epoch 29/300\n",
      "0s - loss: 0.3024 - val_loss: 0.0886\n",
      "Epoch 30/300\n",
      "0s - loss: 0.2850 - val_loss: 0.1040\n",
      "Epoch 31/300\n",
      "0s - loss: 0.2875 - val_loss: 0.1065\n",
      "Epoch 32/300\n",
      "0s - loss: 0.2728 - val_loss: 0.0876\n",
      "Epoch 33/300\n",
      "0s - loss: 0.2711 - val_loss: 0.1087\n",
      "Epoch 34/300\n",
      "0s - loss: 0.2700 - val_loss: 0.0856\n",
      "Epoch 35/300\n",
      "0s - loss: 0.2661 - val_loss: 0.0845\n",
      "Epoch 36/300\n",
      "0s - loss: 0.2588 - val_loss: 0.0817\n",
      "Epoch 37/300\n",
      "0s - loss: 0.2642 - val_loss: 0.1027\n",
      "Epoch 38/300\n",
      "0s - loss: 0.2577 - val_loss: 0.0981\n",
      "Epoch 39/300\n",
      "0s - loss: 0.2575 - val_loss: 0.0872\n",
      "Epoch 40/300\n",
      "0s - loss: 0.2638 - val_loss: 0.0726\n",
      "Epoch 41/300\n",
      "0s - loss: 0.2577 - val_loss: 0.0999\n",
      "Epoch 42/300\n",
      "0s - loss: 0.2453 - val_loss: 0.0836\n",
      "Epoch 43/300\n",
      "0s - loss: 0.2512 - val_loss: 0.0685\n",
      "Epoch 44/300\n",
      "0s - loss: 0.2511 - val_loss: 0.0855\n",
      "Epoch 45/300\n",
      "0s - loss: 0.2478 - val_loss: 0.0814\n",
      "Epoch 46/300\n",
      "0s - loss: 0.2450 - val_loss: 0.0878\n",
      "Epoch 47/300\n",
      "0s - loss: 0.2556 - val_loss: 0.0748\n",
      "Epoch 48/300\n",
      "0s - loss: 0.2507 - val_loss: 0.0748\n",
      "Epoch 49/300\n",
      "0s - loss: 0.2525 - val_loss: 0.0781\n",
      "Epoch 50/300\n",
      "0s - loss: 0.2480 - val_loss: 0.0735\n",
      "Epoch 51/300\n",
      "0s - loss: 0.2422 - val_loss: 0.0726\n",
      "Epoch 52/300\n",
      "0s - loss: 0.2411 - val_loss: 0.0871\n",
      "Epoch 53/300\n",
      "0s - loss: 0.2430 - val_loss: 0.0793\n",
      "Epoch 54/300\n",
      "0s - loss: 0.2382 - val_loss: 0.0877\n",
      "Epoch 55/300\n",
      "0s - loss: 0.2358 - val_loss: 0.0690\n",
      "Epoch 56/300\n",
      "0s - loss: 0.2442 - val_loss: 0.0855\n",
      "Epoch 57/300\n",
      "0s - loss: 0.2346 - val_loss: 0.0715\n",
      "Epoch 58/300\n",
      "0s - loss: 0.2362 - val_loss: 0.0764\n",
      "Epoch 59/300\n",
      "0s - loss: 0.2392 - val_loss: 0.0954\n",
      "Epoch 60/300\n",
      "0s - loss: 0.2310 - val_loss: 0.0743\n",
      "Epoch 61/300\n",
      "0s - loss: 0.2324 - val_loss: 0.0787\n",
      "Epoch 62/300\n",
      "0s - loss: 0.2336 - val_loss: 0.0888\n",
      "Epoch 63/300\n",
      "0s - loss: 0.2296 - val_loss: 0.0819\n",
      "Epoch 64/300\n",
      "0s - loss: 0.2288 - val_loss: 0.1071\n",
      "Epoch 65/300\n",
      "0s - loss: 0.2417 - val_loss: 0.0723\n",
      "Epoch 66/300\n",
      "0s - loss: 0.2346 - val_loss: 0.0904\n",
      "Epoch 67/300\n",
      "0s - loss: 0.2342 - val_loss: 0.0664\n",
      "Epoch 68/300\n",
      "0s - loss: 0.2273 - val_loss: 0.0787\n",
      "Epoch 69/300\n",
      "0s - loss: 0.2280 - val_loss: 0.0683\n",
      "Epoch 70/300\n",
      "0s - loss: 0.2240 - val_loss: 0.0949\n",
      "Epoch 71/300\n",
      "0s - loss: 0.2290 - val_loss: 0.0813\n",
      "Epoch 72/300\n",
      "0s - loss: 0.2242 - val_loss: 0.0827\n",
      "Epoch 73/300\n",
      "0s - loss: 0.2267 - val_loss: 0.0923\n",
      "Epoch 74/300\n",
      "0s - loss: 0.2233 - val_loss: 0.0751\n",
      "Epoch 75/300\n",
      "0s - loss: 0.2162 - val_loss: 0.0793\n",
      "Epoch 76/300\n",
      "0s - loss: 0.2298 - val_loss: 0.0711\n",
      "Epoch 77/300\n",
      "0s - loss: 0.2240 - val_loss: 0.0690\n",
      "Epoch 78/300\n",
      "0s - loss: 0.2236 - val_loss: 0.0679\n",
      "Epoch 79/300\n",
      "0s - loss: 0.2179 - val_loss: 0.0698\n",
      "Epoch 80/300\n",
      "0s - loss: 0.2189 - val_loss: 0.0894\n",
      "Epoch 81/300\n",
      "0s - loss: 0.2238 - val_loss: 0.0686\n",
      "Epoch 82/300\n",
      "0s - loss: 0.2145 - val_loss: 0.1034\n",
      "Epoch 83/300\n",
      "0s - loss: 0.2256 - val_loss: 0.0724\n",
      "Epoch 84/300\n",
      "0s - loss: 0.2146 - val_loss: 0.0780\n",
      "Epoch 85/300\n",
      "0s - loss: 0.2189 - val_loss: 0.0797\n",
      "Epoch 86/300\n",
      "0s - loss: 0.2036 - val_loss: 0.0942\n",
      "Epoch 87/300\n",
      "0s - loss: 0.2231 - val_loss: 0.0787\n",
      "Epoch 88/300\n",
      "0s - loss: 0.2224 - val_loss: 0.0834\n",
      "Epoch 89/300\n",
      "0s - loss: 0.2173 - val_loss: 0.0915\n",
      "Epoch 90/300\n",
      "0s - loss: 0.2149 - val_loss: 0.0744\n",
      "Epoch 91/300\n",
      "0s - loss: 0.2141 - val_loss: 0.0837\n",
      "Epoch 92/300\n",
      "0s - loss: 0.2090 - val_loss: 0.0832\n",
      "Epoch 93/300\n",
      "0s - loss: 0.2071 - val_loss: 0.0723\n",
      "Epoch 94/300\n",
      "0s - loss: 0.2096 - val_loss: 0.0857\n",
      "Epoch 95/300\n",
      "0s - loss: 0.2038 - val_loss: 0.0764\n",
      "Epoch 96/300\n",
      "0s - loss: 0.2055 - val_loss: 0.0758\n",
      "Epoch 97/300\n",
      "0s - loss: 0.2075 - val_loss: 0.0763\n",
      "Epoch 98/300\n",
      "0s - loss: 0.2103 - val_loss: 0.0685\n",
      "Epoch 99/300\n",
      "0s - loss: 0.1967 - val_loss: 0.0719\n",
      "Epoch 100/300\n",
      "0s - loss: 0.2062 - val_loss: 0.0717\n",
      "Epoch 101/300\n",
      "0s - loss: 0.2070 - val_loss: 0.0764\n",
      "Epoch 102/300\n",
      "0s - loss: 0.2006 - val_loss: 0.0804\n",
      "Epoch 103/300\n",
      "0s - loss: 0.2033 - val_loss: 0.0798\n",
      "Epoch 104/300\n",
      "0s - loss: 0.2081 - val_loss: 0.0867\n",
      "Epoch 105/300\n",
      "0s - loss: 0.2024 - val_loss: 0.0764\n",
      "Epoch 106/300\n",
      "0s - loss: 0.1999 - val_loss: 0.0708\n",
      "Epoch 107/300\n",
      "0s - loss: 0.2019 - val_loss: 0.0837\n",
      "Epoch 108/300\n",
      "0s - loss: 0.1982 - val_loss: 0.0648\n",
      "Epoch 109/300\n",
      "0s - loss: 0.1999 - val_loss: 0.0912\n",
      "Epoch 110/300\n",
      "0s - loss: 0.1997 - val_loss: 0.0738\n",
      "Epoch 111/300\n",
      "0s - loss: 0.2017 - val_loss: 0.0717\n",
      "Epoch 112/300\n",
      "0s - loss: 0.1914 - val_loss: 0.0658\n",
      "Epoch 113/300\n",
      "0s - loss: 0.1885 - val_loss: 0.0782\n",
      "Epoch 114/300\n",
      "0s - loss: 0.1935 - val_loss: 0.0763\n",
      "Epoch 115/300\n",
      "0s - loss: 0.2018 - val_loss: 0.0739\n",
      "Epoch 116/300\n",
      "0s - loss: 0.1967 - val_loss: 0.0634\n",
      "Epoch 117/300\n",
      "0s - loss: 0.1909 - val_loss: 0.0878\n",
      "Epoch 118/300\n",
      "0s - loss: 0.1960 - val_loss: 0.0642\n",
      "Epoch 119/300\n",
      "0s - loss: 0.1847 - val_loss: 0.0748\n",
      "Epoch 120/300\n",
      "0s - loss: 0.1868 - val_loss: 0.0670\n",
      "Epoch 121/300\n",
      "0s - loss: 0.1930 - val_loss: 0.0819\n",
      "Epoch 122/300\n",
      "0s - loss: 0.1905 - val_loss: 0.0725\n",
      "Epoch 123/300\n",
      "0s - loss: 0.1849 - val_loss: 0.0822\n",
      "Epoch 124/300\n",
      "0s - loss: 0.1898 - val_loss: 0.0695\n",
      "Epoch 125/300\n",
      "0s - loss: 0.1857 - val_loss: 0.0762\n",
      "Epoch 126/300\n",
      "0s - loss: 0.1833 - val_loss: 0.0674\n",
      "Epoch 127/300\n",
      "0s - loss: 0.1872 - val_loss: 0.0648\n",
      "Epoch 128/300\n",
      "0s - loss: 0.1856 - val_loss: 0.0713\n",
      "Epoch 129/300\n",
      "0s - loss: 0.1787 - val_loss: 0.0677\n",
      "Epoch 130/300\n",
      "0s - loss: 0.1772 - val_loss: 0.0739\n",
      "Epoch 131/300\n",
      "0s - loss: 0.1789 - val_loss: 0.0695\n",
      "Epoch 132/300\n",
      "0s - loss: 0.1841 - val_loss: 0.0622\n",
      "Epoch 133/300\n",
      "0s - loss: 0.1788 - val_loss: 0.0736\n",
      "Epoch 134/300\n",
      "0s - loss: 0.1875 - val_loss: 0.0763\n",
      "Epoch 135/300\n",
      "0s - loss: 0.1832 - val_loss: 0.0725\n",
      "Epoch 136/300\n",
      "0s - loss: 0.1853 - val_loss: 0.0693\n",
      "Epoch 137/300\n",
      "0s - loss: 0.1799 - val_loss: 0.0868\n",
      "Epoch 138/300\n",
      "0s - loss: 0.1802 - val_loss: 0.0877\n",
      "Epoch 139/300\n",
      "0s - loss: 0.1793 - val_loss: 0.0644\n",
      "Epoch 140/300\n",
      "0s - loss: 0.1793 - val_loss: 0.0803\n",
      "Epoch 141/300\n",
      "0s - loss: 0.1848 - val_loss: 0.0697\n",
      "Epoch 142/300\n",
      "0s - loss: 0.1729 - val_loss: 0.0696\n",
      "Epoch 143/300\n",
      "0s - loss: 0.1767 - val_loss: 0.0799\n",
      "Epoch 144/300\n",
      "0s - loss: 0.1690 - val_loss: 0.0672\n",
      "Epoch 145/300\n",
      "0s - loss: 0.1739 - val_loss: 0.0732\n",
      "Epoch 146/300\n",
      "0s - loss: 0.1827 - val_loss: 0.0616\n",
      "Epoch 147/300\n",
      "0s - loss: 0.1762 - val_loss: 0.0634\n",
      "Epoch 148/300\n",
      "0s - loss: 0.1711 - val_loss: 0.0783\n",
      "Epoch 149/300\n",
      "0s - loss: 0.1736 - val_loss: 0.0762\n",
      "Epoch 150/300\n",
      "0s - loss: 0.1758 - val_loss: 0.0703\n",
      "Epoch 151/300\n",
      "0s - loss: 0.1760 - val_loss: 0.0687\n",
      "Epoch 152/300\n",
      "0s - loss: 0.1724 - val_loss: 0.0828\n",
      "Epoch 153/300\n",
      "0s - loss: 0.1735 - val_loss: 0.0642\n",
      "Epoch 154/300\n",
      "0s - loss: 0.1701 - val_loss: 0.0713\n",
      "Epoch 155/300\n",
      "0s - loss: 0.1716 - val_loss: 0.0720\n",
      "Epoch 156/300\n",
      "0s - loss: 0.1730 - val_loss: 0.0745\n",
      "Epoch 157/300\n",
      "0s - loss: 0.1810 - val_loss: 0.0744\n",
      "Epoch 158/300\n",
      "0s - loss: 0.1688 - val_loss: 0.0821\n",
      "Epoch 159/300\n",
      "0s - loss: 0.1784 - val_loss: 0.0772\n",
      "Epoch 160/300\n",
      "0s - loss: 0.1711 - val_loss: 0.0688\n",
      "Epoch 161/300\n",
      "0s - loss: 0.1730 - val_loss: 0.0806\n",
      "Epoch 162/300\n",
      "0s - loss: 0.1669 - val_loss: 0.0748\n",
      "Epoch 163/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.1718 - val_loss: 0.0701\n",
      "Epoch 164/300\n",
      "0s - loss: 0.1717 - val_loss: 0.0768\n",
      "Epoch 165/300\n",
      "0s - loss: 0.1831 - val_loss: 0.0683\n",
      "Epoch 166/300\n",
      "0s - loss: 0.1692 - val_loss: 0.0706\n",
      "Epoch 167/300\n",
      "0s - loss: 0.1712 - val_loss: 0.0822\n",
      "Epoch 168/300\n",
      "0s - loss: 0.1730 - val_loss: 0.0731\n",
      "Epoch 169/300\n",
      "0s - loss: 0.1738 - val_loss: 0.0714\n",
      "Epoch 170/300\n",
      "0s - loss: 0.1709 - val_loss: 0.0758\n",
      "Epoch 171/300\n",
      "0s - loss: 0.1713 - val_loss: 0.0810\n",
      "Epoch 172/300\n",
      "0s - loss: 0.1631 - val_loss: 0.0807\n",
      "Epoch 173/300\n",
      "0s - loss: 0.1676 - val_loss: 0.0766\n",
      "Epoch 174/300\n",
      "0s - loss: 0.1691 - val_loss: 0.0714\n",
      "Epoch 175/300\n",
      "0s - loss: 0.1669 - val_loss: 0.0772\n",
      "Epoch 176/300\n",
      "0s - loss: 0.1666 - val_loss: 0.0705\n",
      "Epoch 177/300\n",
      "0s - loss: 0.1657 - val_loss: 0.0759\n",
      "Epoch 178/300\n",
      "0s - loss: 0.1640 - val_loss: 0.0639\n",
      "Epoch 179/300\n",
      "0s - loss: 0.1775 - val_loss: 0.0724\n",
      "Epoch 180/300\n",
      "0s - loss: 0.1679 - val_loss: 0.0711\n",
      "Epoch 181/300\n",
      "0s - loss: 0.1775 - val_loss: 0.0735\n",
      "Epoch 182/300\n",
      "0s - loss: 0.1657 - val_loss: 0.0778\n",
      "Epoch 183/300\n",
      "0s - loss: 0.1628 - val_loss: 0.0754\n",
      "Epoch 184/300\n",
      "0s - loss: 0.1678 - val_loss: 0.0778\n",
      "Epoch 185/300\n",
      "0s - loss: 0.1667 - val_loss: 0.0758\n",
      "Epoch 186/300\n",
      "0s - loss: 0.1631 - val_loss: 0.0731\n",
      "Epoch 187/300\n",
      "0s - loss: 0.1595 - val_loss: 0.0762\n",
      "Epoch 188/300\n",
      "0s - loss: 0.1605 - val_loss: 0.0671\n",
      "Epoch 189/300\n",
      "0s - loss: 0.1696 - val_loss: 0.0818\n",
      "Epoch 190/300\n",
      "0s - loss: 0.1622 - val_loss: 0.0708\n",
      "Epoch 191/300\n",
      "0s - loss: 0.1665 - val_loss: 0.0769\n",
      "Epoch 192/300\n",
      "0s - loss: 0.1655 - val_loss: 0.0851\n",
      "Epoch 193/300\n",
      "0s - loss: 0.1644 - val_loss: 0.0720\n",
      "Epoch 194/300\n",
      "0s - loss: 0.1678 - val_loss: 0.0699\n",
      "Epoch 195/300\n",
      "0s - loss: 0.1641 - val_loss: 0.0670\n",
      "Epoch 196/300\n",
      "0s - loss: 0.1622 - val_loss: 0.0734\n",
      "Epoch 197/300\n",
      "0s - loss: 0.1608 - val_loss: 0.0671\n",
      "Epoch 198/300\n",
      "0s - loss: 0.1624 - val_loss: 0.0659\n",
      "Epoch 199/300\n",
      "0s - loss: 0.1657 - val_loss: 0.0806\n",
      "Epoch 200/300\n",
      "0s - loss: 0.1602 - val_loss: 0.0754\n",
      "Epoch 201/300\n",
      "0s - loss: 0.1656 - val_loss: 0.0682\n",
      "Epoch 202/300\n",
      "0s - loss: 0.1596 - val_loss: 0.0768\n",
      "Epoch 203/300\n",
      "0s - loss: 0.1655 - val_loss: 0.0750\n",
      "Epoch 204/300\n",
      "0s - loss: 0.1610 - val_loss: 0.0742\n",
      "Epoch 205/300\n",
      "0s - loss: 0.1631 - val_loss: 0.0797\n",
      "Epoch 206/300\n",
      "0s - loss: 0.1604 - val_loss: 0.0784\n",
      "Epoch 207/300\n",
      "0s - loss: 0.1621 - val_loss: 0.0782\n",
      "Epoch 208/300\n",
      "0s - loss: 0.1636 - val_loss: 0.0739\n",
      "Epoch 209/300\n",
      "0s - loss: 0.1614 - val_loss: 0.0751\n",
      "Epoch 210/300\n",
      "0s - loss: 0.1632 - val_loss: 0.0709\n",
      "Epoch 211/300\n",
      "0s - loss: 0.1632 - val_loss: 0.0707\n",
      "Epoch 212/300\n",
      "0s - loss: 0.1577 - val_loss: 0.0729\n",
      "Epoch 213/300\n",
      "0s - loss: 0.1629 - val_loss: 0.0714\n",
      "Epoch 214/300\n",
      "0s - loss: 0.1612 - val_loss: 0.0699\n",
      "Epoch 215/300\n",
      "0s - loss: 0.1549 - val_loss: 0.0719\n",
      "Epoch 216/300\n",
      "0s - loss: 0.1575 - val_loss: 0.0757\n",
      "Epoch 217/300\n",
      "0s - loss: 0.1652 - val_loss: 0.0713\n",
      "Epoch 218/300\n",
      "0s - loss: 0.1649 - val_loss: 0.0710\n",
      "Epoch 219/300\n",
      "0s - loss: 0.1594 - val_loss: 0.0887\n",
      "Epoch 220/300\n",
      "0s - loss: 0.1556 - val_loss: 0.0718\n",
      "Epoch 221/300\n",
      "0s - loss: 0.1606 - val_loss: 0.0713\n",
      "Epoch 222/300\n",
      "0s - loss: 0.1637 - val_loss: 0.0743\n",
      "Epoch 223/300\n",
      "0s - loss: 0.1580 - val_loss: 0.0884\n",
      "Epoch 224/300\n",
      "0s - loss: 0.1570 - val_loss: 0.0740\n",
      "Epoch 225/300\n",
      "0s - loss: 0.1609 - val_loss: 0.0801\n",
      "Epoch 226/300\n",
      "0s - loss: 0.1574 - val_loss: 0.0766\n",
      "Epoch 227/300\n",
      "0s - loss: 0.1563 - val_loss: 0.0788\n",
      "Epoch 228/300\n",
      "0s - loss: 0.1582 - val_loss: 0.0803\n",
      "Epoch 229/300\n",
      "0s - loss: 0.1623 - val_loss: 0.0826\n",
      "Epoch 230/300\n",
      "0s - loss: 0.1601 - val_loss: 0.0782\n",
      "Epoch 231/300\n",
      "0s - loss: 0.1597 - val_loss: 0.0731\n",
      "Epoch 232/300\n",
      "0s - loss: 0.1628 - val_loss: 0.0740\n",
      "Epoch 233/300\n",
      "0s - loss: 0.1552 - val_loss: 0.0707\n",
      "Epoch 234/300\n",
      "0s - loss: 0.1565 - val_loss: 0.0815\n",
      "Epoch 235/300\n",
      "0s - loss: 0.1574 - val_loss: 0.0742\n",
      "Epoch 236/300\n",
      "0s - loss: 0.1516 - val_loss: 0.0808\n",
      "Epoch 237/300\n",
      "0s - loss: 0.1615 - val_loss: 0.0839\n",
      "Epoch 238/300\n",
      "0s - loss: 0.1589 - val_loss: 0.0849\n",
      "Epoch 239/300\n",
      "0s - loss: 0.1551 - val_loss: 0.0769\n",
      "Epoch 240/300\n",
      "0s - loss: 0.1593 - val_loss: 0.0732\n",
      "Epoch 241/300\n",
      "0s - loss: 0.1604 - val_loss: 0.0815\n",
      "Epoch 242/300\n",
      "0s - loss: 0.1577 - val_loss: 0.0755\n",
      "Epoch 243/300\n",
      "0s - loss: 0.1579 - val_loss: 0.0866\n",
      "Epoch 244/300\n",
      "0s - loss: 0.1564 - val_loss: 0.0758\n",
      "Epoch 245/300\n",
      "0s - loss: 0.1550 - val_loss: 0.0711\n",
      "Epoch 246/300\n",
      "0s - loss: 0.1563 - val_loss: 0.0762\n",
      "Epoch 247/300\n",
      "0s - loss: 0.1586 - val_loss: 0.0707\n",
      "Epoch 248/300\n",
      "0s - loss: 0.1584 - val_loss: 0.0808\n",
      "Epoch 249/300\n",
      "0s - loss: 0.1587 - val_loss: 0.0763\n",
      "Epoch 250/300\n",
      "0s - loss: 0.1551 - val_loss: 0.0739\n",
      "Epoch 251/300\n",
      "0s - loss: 0.1546 - val_loss: 0.0808\n",
      "Epoch 252/300\n",
      "0s - loss: 0.1555 - val_loss: 0.0748\n",
      "Epoch 253/300\n",
      "0s - loss: 0.1545 - val_loss: 0.0774\n",
      "Epoch 254/300\n",
      "0s - loss: 0.1554 - val_loss: 0.0772\n",
      "Epoch 255/300\n",
      "0s - loss: 0.1502 - val_loss: 0.0751\n",
      "Epoch 256/300\n",
      "0s - loss: 0.1549 - val_loss: 0.0899\n",
      "Epoch 257/300\n",
      "0s - loss: 0.1593 - val_loss: 0.0731\n",
      "Epoch 258/300\n",
      "0s - loss: 0.1524 - val_loss: 0.0740\n",
      "Epoch 259/300\n",
      "0s - loss: 0.1519 - val_loss: 0.0715\n",
      "Epoch 260/300\n",
      "0s - loss: 0.1511 - val_loss: 0.0809\n",
      "Epoch 261/300\n",
      "0s - loss: 0.1574 - val_loss: 0.0730\n",
      "Epoch 262/300\n",
      "0s - loss: 0.1579 - val_loss: 0.0776\n",
      "Epoch 263/300\n",
      "0s - loss: 0.1615 - val_loss: 0.0773\n",
      "Epoch 264/300\n",
      "0s - loss: 0.1549 - val_loss: 0.0746\n",
      "Epoch 265/300\n",
      "0s - loss: 0.1505 - val_loss: 0.0845\n",
      "Epoch 266/300\n",
      "0s - loss: 0.1572 - val_loss: 0.0764\n",
      "Epoch 267/300\n",
      "0s - loss: 0.1556 - val_loss: 0.0743\n",
      "Epoch 268/300\n",
      "0s - loss: 0.1513 - val_loss: 0.0758\n",
      "Epoch 269/300\n",
      "0s - loss: 0.1486 - val_loss: 0.0871\n",
      "Epoch 270/300\n",
      "0s - loss: 0.1546 - val_loss: 0.0777\n",
      "Epoch 271/300\n",
      "0s - loss: 0.1603 - val_loss: 0.0810\n",
      "Epoch 272/300\n",
      "0s - loss: 0.1588 - val_loss: 0.0741\n",
      "Epoch 273/300\n",
      "0s - loss: 0.1537 - val_loss: 0.0760\n",
      "Epoch 274/300\n",
      "0s - loss: 0.1593 - val_loss: 0.0832\n",
      "Epoch 275/300\n",
      "0s - loss: 0.1510 - val_loss: 0.0780\n",
      "Epoch 276/300\n",
      "0s - loss: 0.1509 - val_loss: 0.0745\n",
      "Epoch 277/300\n",
      "0s - loss: 0.1522 - val_loss: 0.0802\n",
      "Epoch 278/300\n",
      "0s - loss: 0.1516 - val_loss: 0.0781\n",
      "Epoch 279/300\n",
      "0s - loss: 0.1517 - val_loss: 0.0750\n",
      "Epoch 280/300\n",
      "0s - loss: 0.1502 - val_loss: 0.0793\n",
      "Epoch 281/300\n",
      "0s - loss: 0.1518 - val_loss: 0.0947\n",
      "Epoch 282/300\n",
      "0s - loss: 0.1526 - val_loss: 0.0748\n",
      "Epoch 283/300\n",
      "0s - loss: 0.1505 - val_loss: 0.0783\n",
      "Epoch 284/300\n",
      "0s - loss: 0.1571 - val_loss: 0.0756\n",
      "Epoch 285/300\n",
      "0s - loss: 0.1544 - val_loss: 0.0773\n",
      "Epoch 286/300\n",
      "0s - loss: 0.1526 - val_loss: 0.0812\n",
      "Epoch 287/300\n",
      "0s - loss: 0.1527 - val_loss: 0.0810\n",
      "Epoch 288/300\n",
      "0s - loss: 0.1522 - val_loss: 0.0762\n",
      "Epoch 289/300\n",
      "0s - loss: 0.1499 - val_loss: 0.0805\n",
      "Epoch 290/300\n",
      "0s - loss: 0.1530 - val_loss: 0.0849\n",
      "Epoch 291/300\n",
      "0s - loss: 0.1532 - val_loss: 0.0748\n",
      "Epoch 292/300\n",
      "0s - loss: 0.1490 - val_loss: 0.0814\n",
      "Epoch 293/300\n",
      "0s - loss: 0.1520 - val_loss: 0.0802\n",
      "Epoch 294/300\n",
      "0s - loss: 0.1541 - val_loss: 0.0803\n",
      "Epoch 295/300\n",
      "0s - loss: 0.1457 - val_loss: 0.0756\n",
      "Epoch 296/300\n",
      "0s - loss: 0.1509 - val_loss: 0.0817\n",
      "Epoch 297/300\n",
      "0s - loss: 0.1419 - val_loss: 0.0761\n",
      "Epoch 298/300\n",
      "0s - loss: 0.1512 - val_loss: 0.0776\n",
      "Epoch 299/300\n",
      "0s - loss: 0.1513 - val_loss: 0.0843\n",
      "Epoch 300/300\n",
      "0s - loss: 0.1551 - val_loss: 0.0735\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h+4cQs9ovhRUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f30d45abf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(15, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(1))\n",
    "model2.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model2.fit(train_X, train_y, epochs=300, batch_size=64, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.120\n"
     ]
    }
   ],
   "source": [
    "yhat = model2.predict(test_X)\n",
    "rmse = sqrt(mean_squared_error(test_y, yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   4.249634   2.999878        0.0        0.0   0.371230   0.696677   \n",
      "2   4.409720   2.839792       11.0        0.0   0.220883   0.527402   \n",
      "3   4.482361   2.767151       22.0        0.0   0.141776   0.477051   \n",
      "4   4.542626   2.706886       33.0        0.0   0.156459   0.513401   \n",
      "5   4.616296   2.633216       44.0        0.0   0.285218   0.638627   \n",
      "\n",
      "   var7(t-1)  var4(t)  \n",
      "1   0.136833      0.0  \n",
      "2   0.062817      0.0  \n",
      "3   0.055497      0.0  \n",
      "4   0.066184      0.0  \n",
      "5   0.158079      0.0  \n"
     ]
    }
   ],
   "source": [
    "reframed3 = reframed.drop(reframed.columns[[7,8,9,11,12,13]], axis=1)\n",
    "print(reframed3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 7) (2000,) (729, 7) (729,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "n_train_hours = 2000\n",
    "train = reframed3.iloc[:n_train_hours, :]\n",
    "test = reframed3.iloc[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train.iloc[:, :-1], train.iloc[:, -1]\n",
    "test_X, test_y = test.iloc[:, :-1], test.iloc[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "#train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "#test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0:00:00.178401\n",
      "testing time:  0:00:00.001536\n",
      "classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.97      0.97       688\n",
      "        1.0       0.48      0.49      0.48        41\n",
      "\n",
      "avg / total       0.94      0.94      0.94       729\n",
      "\n",
      "f1 score\n",
      "0.725327491785\n",
      "accuracy score\n",
      "0.941015089163\n",
      "confusion matrix:\n",
      "[[666  22]\n",
      " [ 21  20]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAAD8CAYAAABZ0jAcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMlQkNWWoSGrq/wAIQWi9VBA3jgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f30b0586160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def testClassifier(x_train, y_train, x_test, y_test, clf):\n",
    "    \"\"\"\n",
    "    this method will first train the classifier on the training data\n",
    "    and will then test the trained classifier on test data.\n",
    "    Finally it will report some metrics on the classifier performance.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    x_train: (np.ndarray) train data matrix\n",
    "    \n",
    "    y_train: (list) train data label\n",
    "    \n",
    "    x_test: (np.ndarray) test data matrix\n",
    "    \n",
    "    y_test: (list) test data label\n",
    "    \n",
    "    clf: sklearn classifier object implementing fit() and predict() methods\n",
    "    \n",
    "    Returns:\n",
    "\n",
    "    metrics: list\n",
    "             [training time, testing time, recall and precision for every class, macro-averaged F1 score]\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    start = dt.now()\n",
    "    clf.fit(x_train, y_train)\n",
    "    end = dt.now()\n",
    "    print ('training time: ', (end - start))\n",
    "    \n",
    "    # add training time to metrics\n",
    "    metrics.append(end-start)\n",
    "    \n",
    "    start = dt.now()\n",
    "    pred = clf.predict(x_test)\n",
    "    end = dt.now()\n",
    "    print( 'testing time: ', (end - start))\n",
    "    \n",
    "    # add testing time to metrics\n",
    "    metrics.append(end-start)\n",
    "    \n",
    "    print( 'classification report: ')\n",
    "    # print classification_report(y_test, yhat)\n",
    "    print (classification_report(y_test, pred))\n",
    "    \n",
    "    print ('f1 score')\n",
    "    print (f1_score(y_test, pred, average='macro'))\n",
    "    \n",
    "    print ('accuracy score')\n",
    "    print (accuracy_score(y_test, pred))\n",
    "    \n",
    "    precision = precision_score(y_test, pred, average=None)\n",
    "    recall = recall_score(y_test, pred, average=None)\n",
    "    \n",
    "    # add precision and recall values to metrics\n",
    "    for p, r in zip(precision, recall):\n",
    "        metrics.append(p)\n",
    "        metrics.append(r)\n",
    "    \n",
    "    \n",
    "    #add macro-averaged F1 score to metrics\n",
    "    metrics.append(f1_score(y_test, pred, average='macro'))\n",
    "    \n",
    "    print ('confusion matrix:')\n",
    "    print (confusion_matrix(y_test, pred))\n",
    "    \n",
    "    # plotting the confusion matrix\n",
    "    plt.imshow(confusion_matrix(y_test, pred), interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "gbm = GradientBoostingClassifier(n_estimators=40, learning_rate=0.1,\n",
    "                                max_depth=5, random_state=0, subsample=0.8, max_features=0.8)\n",
    "\n",
    "# If we tune we can get more accuracy\n",
    "boost = testClassifier(train_X, train_y, test_X, test_y, gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0:00:00.182533\n",
      "testing time:  0:00:00.003595\n",
      "classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.83      0.90       688\n",
      "        1.0       0.24      0.90      0.38        41\n",
      "\n",
      "avg / total       0.95      0.83      0.87       729\n",
      "\n",
      "f1 score\n",
      "0.641841768683\n",
      "accuracy score\n",
      "0.83401920439\n",
      "confusion matrix:\n",
      "[[571 117]\n",
      " [  4  37]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAAD8CAYAAABZ0jAcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkdSUoSKpqf8D8N9xAvSinoMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f30b035a198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate =0.1,\n",
    "                     n_estimators=50,\n",
    "                     max_depth=4,\n",
    "                     min_child_weight=6,\n",
    "                     gamma=0.1,\n",
    "                     reg_alpha=0.01,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.9,\n",
    "                     objective= 'binary:logistic',\n",
    "                     scale_pos_weight=8,\n",
    "                     seed=27)\n",
    "xgboost = testClassifier(train_X, train_y, test_X, test_y, xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itachi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('gcPredictionFile.csv')\n",
    "#test['CUMSUM_cputime'] = test['cpuTimeTaken'].cumsum(axis = 0)\n",
    "test = test.merge(small, on='query token', right_index=True)\n",
    "test = test.sort_index()\n",
    "test = test.merge(ll, on='query token', right_index=True)\n",
    "test = test.sort_index()\n",
    "test['query token'] = encoder.fit_transform(test['query token'].astype('str'))\n",
    "test['gcRun'] = encoder.fit_transform(test['gcRun'].astype('str'))\n",
    "test.loc[:,['gcRun','cpuTimeTaken']] = test.loc[:,['cpuTimeTaken','gcRun']].values\n",
    "test.columns = cols\n",
    "\n",
    "test['gcRun'][0] = 1\n",
    "test['gcRun'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   4.247186   2.774299        2.0        1.0   0.408436   0.520126   \n",
      "2   0.000000   0.000000       73.0        0.0   0.124429   0.522675   \n",
      "3   0.000000   0.000000       48.0        0.0   0.245838   0.468081   \n",
      "4   0.000000   0.000000       86.0        0.0   0.169346   0.674019   \n",
      "5   0.000000   0.000000       67.0        0.0   0.296311   0.732314   \n",
      "\n",
      "   var7(t-1)  var1(t)  \n",
      "1   0.098823      0.0  \n",
      "2   0.044418      0.0  \n",
      "3   0.047545      0.0  \n",
      "4   0.125974      0.0  \n",
      "5   0.240021      0.0  \n"
     ]
    }
   ],
   "source": [
    "test = series_to_supervised(test, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "test = test.drop(reframed.columns[[8,9,10,11,12,13]], axis=1)\n",
    "print(test.head())\n",
    "column = test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [[ 3.5836153]] [[ 3.48845387]]\n",
      "[ 0.] [[ 4.47977066]] [[ 3.29340601]]\n",
      "[ 0.] [[ 4.80966234]] [[ 3.07471275]]\n",
      "[ 0.] [[ 5.09656239]] [[ 2.84313893]]\n",
      "[ 0.] [[ 5.40188217]] [[ 2.54655504]]\n",
      "[ 0.] [[ 5.32863045]] [[ 2.50224161]]\n",
      "[ 0.] [[ 5.4665947]] [[ 2.41112423]]\n",
      "[ 0.] [[ 5.68060207]] [[ 2.23359346]]\n",
      "[ 0.] [[ 5.82052612]] [[ 2.12784696]]\n",
      "[ 0.] [[ 5.8784852]] [[ 2.00846577]]\n",
      "[ 0.] [[ 6.05766201]] [[ 1.7919457]]\n",
      "[ 0.] [[ 6.18350792]] [[ 1.6745404]]\n",
      "[ 0.] [[ 6.8057785]] [[ 0.97511631]]\n",
      "[ 0.] [[ 6.83011055]] [[ 0.996086]]\n",
      "[ 0.] [[ 6.99691868]] [[ 0.91961277]]\n",
      "[ 1.] [[ 4.82819653]] [[ 2.92858505]]\n",
      "[ 0.] [[ 5.23391819]] [[ 2.6683383]]\n",
      "[ 0.] [[ 5.2122736]] [[ 2.50374961]]\n",
      "[ 0.] [[ 5.37121725]] [[ 2.40819263]]\n",
      "[ 0.] [[ 5.75603151]] [[ 2.09550905]]\n",
      "[ 0.] [[ 5.92153072]] [[ 1.99858451]]\n",
      "[ 0.] [[ 6.03078747]] [[ 1.90244246]]\n",
      "[ 0.] [[ 6.11689472]] [[ 1.8066622]]\n",
      "[ 0.] [[ 6.13123035]] [[ 1.69761765]]\n",
      "[ 0.] [[ 6.10865021]] [[ 1.65958965]]\n",
      "[ 0.] [[ 6.27952433]] [[ 1.56307709]]\n",
      "[ 1.] [[ 4.44028664]] [[ 3.30830359]]\n",
      "[ 0.] [[ 4.85733509]] [[ 3.01489282]]\n",
      "[ 0.] [[ 5.00477171]] [[ 2.86629987]]\n",
      "[ 0.] [[ 5.09025574]] [[ 2.64232588]]\n",
      "[ 0.] [[ 5.18176556]] [[ 2.61832952]]\n",
      "[ 0.] [[ 5.46069479]] [[ 2.44577909]]\n",
      "[ 0.] [[ 5.35064697]] [[ 2.38287878]]\n",
      "[ 0.] [[ 5.52710342]] [[ 2.32488537]]\n",
      "[ 0.] [[ 5.73785019]] [[ 2.18751073]]\n",
      "[ 0.] [[ 5.82723141]] [[ 2.12603879]]\n",
      "[ 0.] [[ 5.88298893]] [[ 2.03508139]]\n",
      "[ 0.] [[ 5.98264599]] [[ 1.95107436]]\n",
      "[ 0.] [[ 6.06647682]] [[ 1.85303807]]\n",
      "[ 0.] [[ 6.12062454]] [[ 1.76069176]]\n",
      "[ 0.] [[ 6.2209177]] [[ 1.63657975]]\n",
      "[ 0.] [[ 6.31914234]] [[ 1.51579857]]\n",
      "[ 0.] [[ 6.35317755]] [[ 1.43202031]]\n",
      "[ 0.] [[ 6.5120163]] [[ 1.29548275]]\n",
      "[ 0.] [[ 6.59394073]] [[ 1.17888629]]\n",
      "[ 0.] [[ 6.76405048]] [[ 1.04831147]]\n",
      "[ 0.] [[ 6.87190723]] [[ 0.9760139]]\n",
      "[ 0.] [[ 6.887393]] [[ 0.98173058]]\n",
      "[ 0.] [[ 6.87897301]] [[ 0.97636932]]\n",
      "[ 0.] [[ 6.89372063]] [[ 0.96938127]]\n",
      "[ 0.] [[ 6.87442303]] [[ 0.98010653]]\n",
      "[ 1.] [[ 4.9846859]] [[ 2.89298034]]\n",
      "[ 0.] [[ 4.89485216]] [[ 2.75067568]]\n",
      "[ 0.] [[ 5.27069664]] [[ 2.61313772]]\n",
      "[ 0.] [[ 5.44550371]] [[ 2.51563406]]\n",
      "[ 0.] [[ 5.57299423]] [[ 2.39851189]]\n",
      "[ 0.] [[ 5.67055416]] [[ 2.31099248]]\n",
      "[ 0.] [[ 5.75579262]] [[ 2.22014523]]\n",
      "[ 0.] [[ 5.84677887]] [[ 2.10871959]]\n",
      "[ 0.] [[ 5.99770784]] [[ 1.92173839]]\n",
      "[ 0.] [[ 6.0863266]] [[ 1.80381989]]\n",
      "[ 0.] [[ 6.22972679]] [[ 1.6309526]]\n",
      "[ 0.] [[ 6.2871685]] [[ 1.48176277]]\n",
      "[ 0.] [[ 6.76485777]] [[ 1.01147008]]\n",
      "[ 0.] [[ 6.76665974]] [[ 1.01546669]]\n",
      "[ 0.] [[ 6.81831932]] [[ 1.00713634]]\n",
      "[ 0.] [[ 6.80774593]] [[ 1.00224137]]\n",
      "[ 1.] [[ 4.9320755]] [[ 2.9177072]]\n",
      "[ 0.] [[ 5.18156195]] [[ 2.75754213]]\n",
      "[ 0.] [[ 5.70344353]] [[ 2.1755538]]\n",
      "[ 0.] [[ 5.68543625]] [[ 2.04282093]]\n",
      "[ 0.] [[ 5.93120193]] [[ 1.94916177]]\n",
      "[ 0.] [[ 6.14107418]] [[ 1.73262608]]\n",
      "[ 0.] [[ 6.19444418]] [[ 1.65227723]]\n",
      "[ 0.] [[ 6.28686428]] [[ 1.55149686]]\n",
      "[ 0.] [[ 6.50298643]] [[ 1.21663523]]\n",
      "[ 0.] [[ 6.63477898]] [[ 1.17659056]]\n",
      "[ 0.] [[ 6.74229813]] [[ 1.04965925]]\n",
      "[ 0.] [[ 6.7903018]] [[ 0.99614072]]\n",
      "[ 0.] [[ 6.73436069]] [[ 1.04065323]]\n",
      "[ 0.] [[ 6.79737282]] [[ 1.02885139]]\n",
      "[ 0.] [[ 6.86837864]] [[ 0.97613961]]\n",
      "[ 0.] [[ 6.88557243]] [[ 0.97538769]]\n",
      "[ 1.] [[ 5.11241436]] [[ 2.78236389]]\n",
      "[ 0.] [[ 5.27472496]] [[ 2.59670782]]\n",
      "[ 0.] [[ 5.70899391]] [[ 2.17747164]]\n",
      "[ 0.] [[ 5.80099583]] [[ 2.00243664]]\n",
      "[ 0.] [[ 6.04505301]] [[ 1.82567883]]\n",
      "[ 0.] [[ 6.15534258]] [[ 1.73965943]]\n",
      "[ 0.] [[ 6.24346113]] [[ 1.55528474]]\n",
      "[ 0.] [[ 6.37624645]] [[ 1.46782637]]\n",
      "[ 0.] [[ 6.4537735]] [[ 1.38684893]]\n",
      "[ 0.] [[ 6.46483135]] [[ 1.28430009]]\n",
      "[ 0.] [[ 6.63719082]] [[ 1.16501427]]\n",
      "[ 0.] [[ 6.77559614]] [[ 1.02292299]]\n",
      "[ 0.] [[ 6.83386612]] [[ 1.01315355]]\n",
      "[ 0.] [[ 6.88775444]] [[ 0.9699837]]\n",
      "[ 0.] [[ 6.93226433]] [[ 0.94409841]]\n",
      "[ 1.] [[ 4.74761009]] [[ 2.89567947]]\n",
      "[ 0.] [[ 5.07203817]] [[ 2.8226788]]\n",
      "[ 0.] [[ 5.64126444]] [[ 2.21793461]]\n",
      "[ 0.] [[ 5.78922939]] [[ 2.15092564]]\n",
      "[ 0.] [[ 5.9177084]] [[ 1.9849031]]\n",
      "[ 0.] [[ 6.02398443]] [[ 1.89014208]]\n",
      "[ 1.] [[ 4.45921993]] [[ 3.39260769]]\n",
      "[ 0.] [[ 4.67569208]] [[ 3.16140175]]\n",
      "[ 0.] [[ 5.00482178]] [[ 2.89066744]]\n",
      "[ 0.] [[ 5.20526552]] [[ 2.75202084]]\n",
      "[ 0.] [[ 5.48626804]] [[ 2.46632719]]\n",
      "[ 0.] [[ 5.42266273]] [[ 2.38188219]]\n",
      "[ 0.] [[ 5.67806768]] [[ 2.21445107]]\n",
      "[ 0.] [[ 5.75010443]] [[ 2.13415146]]\n",
      "[ 0.] [[ 5.84627724]] [[ 1.94334602]]\n",
      "[ 0.] [[ 6.36291695]] [[ 1.37727463]]\n",
      "[ 0.] [[ 6.55408192]] [[ 1.24879265]]\n",
      "[ 0.] [[ 6.64659977]] [[ 1.16215146]]\n",
      "[ 0.] [[ 6.87559891]] [[ 0.96206462]]\n",
      "[ 1.] [[ 5.00272942]] [[ 2.86345911]]\n",
      "[ 0.] [[ 5.00498676]] [[ 2.69077921]]\n",
      "[ 0.] [[ 4.98693752]] [[ 2.63160753]]\n",
      "[ 0.] [[ 5.59177971]] [[ 2.23050451]]\n",
      "[ 0.] [[ 5.80488586]] [[ 2.10248327]]\n",
      "[ 0.] [[ 5.88205004]] [[ 1.93296123]]\n",
      "[ 0.] [[ 5.96165419]] [[ 1.80817199]]\n",
      "[ 0.] [[ 6.11924553]] [[ 1.73114014]]\n",
      "[ 0.] [[ 6.18897533]] [[ 1.64490259]]\n",
      "[ 0.] [[ 6.31514168]] [[ 1.54529881]]\n",
      "[ 0.] [[ 6.31371689]] [[ 1.50801873]]\n",
      "[ 1.] [[ 4.5462904]] [[ 3.23798442]]\n",
      "[ 0.] [[ 5.48908997]] [[ 2.28061581]]\n",
      "[ 0.] [[ 5.72921467]] [[ 2.18458915]]\n",
      "[ 0.] [[ 5.83827496]] [[ 2.10857153]]\n",
      "[ 0.] [[ 6.05960369]] [[ 1.81066775]]\n",
      "[ 0.] [[ 6.0879283]] [[ 1.73697805]]\n",
      "[ 0.] [[ 6.29498482]] [[ 1.54929066]]\n",
      "[ 0.] [[ 6.3606205]] [[ 1.46646523]]\n",
      "[ 0.] [[ 6.46523285]] [[ 1.37031293]]\n",
      "[ 0.] [[ 6.52196407]] [[ 1.2662977]]\n",
      "[ 0.] [[ 6.71118736]] [[ 1.00350308]]\n",
      "[ 0.] [[ 6.81285572]] [[ 1.01054156]]\n",
      "[ 0.] [[ 6.8184104]] [[ 0.99174833]]\n",
      "[ 0.] [[ 6.86338234]] [[ 0.93374979]]\n",
      "[ 1.] [[ 4.86829376]] [[ 2.93853521]]\n",
      "[ 0.] [[ 5.10905027]] [[ 2.79736662]]\n",
      "[ 0.] [[ 5.03991413]] [[ 2.62751055]]\n",
      "[ 0.] [[ 5.23660707]] [[ 2.54428101]]\n",
      "[ 0.] [[ 5.4578371]] [[ 2.4778738]]\n",
      "[ 0.] [[ 5.5638237]] [[ 2.39610577]]\n",
      "[ 0.] [[ 5.69376183]] [[ 2.25933552]]\n",
      "[ 0.] [[ 5.66102648]] [[ 2.23782563]]\n",
      "[ 0.] [[ 5.79768181]] [[ 2.14734793]]\n",
      "[ 0.] [[ 5.85795593]] [[ 1.96704555]]\n",
      "[ 0.] [[ 6.00406837]] [[ 1.89987278]]\n",
      "[ 0.] [[ 6.1074729]] [[ 1.78218806]]\n",
      "[ 0.] [[ 6.17277145]] [[ 1.67401433]]\n",
      "[ 0.] [[ 6.35015011]] [[ 1.48023629]]\n",
      "[ 0.] [[ 6.44085121]] [[ 1.36077106]]\n",
      "[ 0.] [[ 6.55262423]] [[ 1.2326566]]\n",
      "[ 0.] [[ 6.63986397]] [[ 1.15824831]]\n",
      "[ 0.] [[ 6.78546619]] [[ 1.03433466]]\n",
      "[ 0.] [[ 6.83751678]] [[ 1.00481355]]\n",
      "[ 0.] [[ 6.83984995]] [[ 1.00612903]]\n",
      "[ 0.] [[ 6.78813267]] [[ 0.99457312]]\n",
      "[ 0.] [[ 6.77695465]] [[ 1.02680993]]\n",
      "[ 0.] [[ 6.79526472]] [[ 1.01990592]]\n",
      "[ 0.] [[ 6.83041096]] [[ 0.99780887]]\n",
      "[ 0.] [[ 6.84060144]] [[ 0.99750566]]\n",
      "[ 0.] [[ 6.91813087]] [[ 0.95462459]]\n",
      "[ 0.] [[ 6.86119938]] [[ 0.97275317]]\n",
      "[ 0.] [[ 6.87473297]] [[ 0.9738161]]\n",
      "[ 0.] [[ 6.84543753]] [[ 0.96914852]]\n",
      "[ 0.] [[ 6.94120121]] [[ 0.91665262]]\n",
      "[ 1.] [[ 4.993927]] [[ 2.89363146]]\n",
      "[ 0.] [[ 5.23601151]] [[ 2.69685221]]\n",
      "[ 0.] [[ 5.47238827]] [[ 2.46123314]]\n",
      "[ 0.] [[ 5.425951]] [[ 2.39028978]]\n",
      "[ 0.] [[ 5.62527752]] [[ 2.30687714]]\n",
      "[ 0.] [[ 5.7408123]] [[ 2.22144651]]\n",
      "[ 0.] [[ 5.71009636]] [[ 2.07372928]]\n",
      "[ 0.] [[ 5.91290188]] [[ 1.98486066]]\n",
      "[ 0.] [[ 6.04401159]] [[ 1.83080029]]\n",
      "[ 0.] [[ 6.14221144]] [[ 1.73654616]]\n",
      "[ 0.] [[ 6.16657543]] [[ 1.65792203]]\n",
      "[ 0.] [[ 6.31188631]] [[ 1.54946542]]\n",
      "[ 0.] [[ 6.37231064]] [[ 1.46806586]]\n",
      "[ 0.] [[ 6.46592045]] [[ 1.35909259]]\n",
      "[ 0.] [[ 6.59108496]] [[ 1.16644871]]\n",
      "[ 0.] [[ 6.76999092]] [[ 1.04581475]]\n",
      "[ 0.] [[ 6.78934288]] [[ 1.01426852]]\n",
      "[ 0.] [[ 6.7683177]] [[ 1.03808498]]\n",
      "[ 0.] [[ 6.87668991]] [[ 0.97088635]]\n",
      "[ 0.] [[ 6.86910343]] [[ 0.98114705]]\n",
      "[ 1.] [[ 4.99593449]] [[ 2.87289429]]\n",
      "[ 0.] [[ 5.21199656]] [[ 2.74431491]]\n",
      "[ 0.] [[ 5.37687016]] [[ 2.59116316]]\n",
      "[ 0.] [[ 5.33221912]] [[ 2.43522787]]\n",
      "[ 0.] [[ 5.47580481]] [[ 2.36134171]]\n",
      "[ 0.] [[ 5.7931571]] [[ 2.10210085]]\n",
      "[ 0.] [[ 5.90976954]] [[ 2.00998545]]\n",
      "[ 0.] [[ 5.99073362]] [[ 1.81091762]]\n",
      "[ 0.] [[ 6.02215481]] [[ 1.7891221]]\n",
      "[ 0.] [[ 6.17814112]] [[ 1.69721401]]\n",
      "[ 0.] [[ 6.29484463]] [[ 1.58090353]]\n",
      "[ 1.] [[ 4.52741051]] [[ 3.27306128]]\n",
      "[ 0.] [[ 4.859869]] [[ 3.06820726]]\n",
      "[ 0.] [[ 5.21942091]] [[ 2.67777967]]\n",
      "[ 0.] [[ 5.41722107]] [[ 2.53487182]]\n",
      "[ 0.] [[ 5.48888683]] [[ 2.4796021]]\n",
      "[ 0.] [[ 5.60192823]] [[ 2.35688066]]\n",
      "[ 0.] [[ 5.71669674]] [[ 2.24966407]]\n",
      "[ 0.] [[ 5.80747223]] [[ 2.16135645]]\n",
      "[ 0.] [[ 5.95980549]] [[ 1.97009385]]\n",
      "[ 0.] [[ 6.08569002]] [[ 1.80092812]]\n",
      "[ 0.] [[ 6.18007565]] [[ 1.71041441]]\n",
      "[ 0.] [[ 6.34599304]] [[ 1.51135683]]\n",
      "[ 0.] [[ 6.43444633]] [[ 1.42891943]]\n",
      "[ 0.] [[ 6.5398488]] [[ 1.24743712]]\n",
      "[ 0.] [[ 6.65285587]] [[ 1.17521882]]\n",
      "[ 0.] [[ 6.70078564]] [[ 1.12368572]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [[ 6.745718]] [[ 1.08183885]]\n",
      "[ 0.] [[ 6.79040051]] [[ 1.00676465]]\n",
      "[ 0.] [[ 6.87081432]] [[ 0.95275724]]\n",
      "[ 1.] [[ 4.72327614]] [[ 2.87886667]]\n",
      "[ 0.] [[ 5.11977577]] [[ 2.7696476]]\n",
      "[ 0.] [[ 5.19371796]] [[ 2.57688808]]\n",
      "[ 0.] [[ 5.46194124]] [[ 2.4633944]]\n",
      "[ 0.] [[ 5.9598856]] [[ 1.8910042]]\n",
      "[ 0.] [[ 6.2340045]] [[ 1.52166188]]\n",
      "[ 1.] [[ 4.43374443]] [[ 3.35061502]]\n",
      "[ 0.] [[ 4.67793608]] [[ 3.14718771]]\n",
      "[ 0.] [[ 4.70727348]] [[ 3.00201797]]\n",
      "[ 0.] [[ 4.81616879]] [[ 2.83527136]]\n",
      "[ 0.] [[ 4.99158096]] [[ 2.74746656]]\n",
      "[ 0.] [[ 5.29566669]] [[ 2.6160574]]\n",
      "[ 0.] [[ 5.59089613]] [[ 2.34583426]]\n",
      "[ 0.] [[ 5.54049301]] [[ 2.26909971]]\n",
      "[ 0.] [[ 5.77644634]] [[ 2.12972832]]\n",
      "[ 0.] [[ 5.79155302]] [[ 2.06207848]]\n",
      "[ 0.] [[ 5.88857412]] [[ 1.88365448]]\n",
      "[ 0.] [[ 6.29811954]] [[ 1.46515751]]\n",
      "[ 1.] [[ 4.71697617]] [[ 3.19007659]]\n",
      "[ 0.] [[ 4.98377228]] [[ 2.96776152]]\n",
      "[ 0.] [[ 5.17286491]] [[ 2.80159521]]\n",
      "[ 0.] [[ 5.39739132]] [[ 2.54859781]]\n",
      "[ 0.] [[ 5.51172686]] [[ 2.46571684]]\n",
      "[ 0.] [[ 5.63833761]] [[ 2.32250071]]\n",
      "[ 0.] [[ 5.77086926]] [[ 2.17219067]]\n",
      "[ 0.] [[ 6.21025133]] [[ 1.58888555]]\n",
      "[ 0.] [[ 6.3231492]] [[ 1.48257184]]\n",
      "[ 0.] [[ 6.3307786]] [[ 1.41672134]]\n",
      "[ 0.] [[ 6.9682703]] [[ 0.90440071]]\n",
      "[ 1.] [[ 4.82289124]] [[ 2.89006186]]\n",
      "[ 0.] [[ 5.22007084]] [[ 2.58116412]]\n",
      "[ 0.] [[ 5.37727451]] [[ 2.48768044]]\n",
      "[ 0.] [[ 5.56599903]] [[ 2.3867569]]\n",
      "[ 0.] [[ 5.73239994]] [[ 2.20335627]]\n",
      "[ 0.] [[ 5.77413464]] [[ 2.09532166]]\n",
      "[ 0.] [[ 5.88679695]] [[ 2.01754189]]\n",
      "[ 0.] [[ 5.83920479]] [[ 1.91456759]]\n",
      "[ 0.] [[ 6.1286459]] [[ 1.7059772]]\n",
      "[ 1.] [[ 4.32995415]] [[ 3.3064158]]\n",
      "[ 0.] [[ 4.77194786]] [[ 3.10045409]]\n",
      "[ 0.] [[ 4.99598646]] [[ 2.86152124]]\n",
      "[ 0.] [[ 5.13559437]] [[ 2.73909044]]\n",
      "[ 0.] [[ 5.38350487]] [[ 2.56498051]]\n",
      "[ 0.] [[ 5.55306721]] [[ 2.40499377]]\n",
      "[ 0.] [[ 5.69425201]] [[ 2.25977182]]\n",
      "[ 0.] [[ 5.7477417]] [[ 2.1072607]]\n",
      "[ 0.] [[ 5.84176445]] [[ 2.0212903]]\n",
      "[ 0.] [[ 5.97843742]] [[ 1.94149089]]\n",
      "[ 0.] [[ 6.06146336]] [[ 1.86834645]]\n",
      "[ 0.] [[ 6.12756443]] [[ 1.7894541]]\n",
      "[ 0.] [[ 6.19743967]] [[ 1.6891607]]\n",
      "[ 0.] [[ 6.29446125]] [[ 1.57191074]]\n",
      "[ 0.] [[ 6.38954449]] [[ 1.46729589]]\n",
      "[ 0.] [[ 6.45924282]] [[ 1.34749246]]\n",
      "[ 0.] [[ 6.54913521]] [[ 1.24902308]]\n",
      "[ 0.] [[ 6.66799116]] [[ 1.13938749]]\n",
      "[ 0.] [[ 6.70841885]] [[ 1.07651579]]\n",
      "[ 0.] [[ 6.78484726]] [[ 1.04460263]]\n",
      "[ 0.] [[ 6.86126804]] [[ 0.97273672]]\n",
      "[ 0.] [[ 6.84156322]] [[ 0.97423279]]\n",
      "[ 0.] [[ 6.9108839]] [[ 0.95304799]]\n",
      "[ 0.] [[ 6.84415531]] [[ 0.99641758]]\n",
      "[ 0.] [[ 6.84819317]] [[ 0.9800204]]\n",
      "[ 0.] [[ 6.92599201]] [[ 0.93156749]]\n",
      "[ 0.] [[ 6.87180901]] [[ 0.99208009]]\n",
      "[ 0.] [[ 6.87970638]] [[ 0.99033022]]\n",
      "[ 0.] [[ 7.29035759]] [[ 0.83673805]]\n",
      "[ 1.] [[ 5.03393841]] [[ 2.81037855]]\n",
      "[ 0.] [[ 5.25661373]] [[ 2.68308258]]\n",
      "[ 0.] [[ 5.20275497]] [[ 2.59301949]]\n",
      "[ 0.] [[ 5.26376152]] [[ 2.46393633]]\n",
      "[ 0.] [[ 5.51085138]] [[ 2.40898681]]\n",
      "[ 0.] [[ 5.6473999]] [[ 2.31661463]]\n",
      "[ 0.] [[ 5.61148882]] [[ 2.16578937]]\n",
      "[ 0.] [[ 5.74286652]] [[ 2.0728879]]\n",
      "[ 0.] [[ 5.93310547]] [[ 1.9215529]]\n",
      "[ 0.] [[ 6.42250729]] [[ 1.33472347]]\n",
      "[ 0.] [[ 6.57721376]] [[ 1.15110278]]\n",
      "[ 0.] [[ 6.77196407]] [[ 1.02974916]]\n",
      "[ 1.] [[ 4.93857431]] [[ 2.93234634]]\n",
      "[ 0.] [[ 5.15866566]] [[ 2.77821422]]\n",
      "[ 0.] [[ 5.23402023]] [[ 2.66377807]]\n",
      "[ 0.] [[ 5.33449173]] [[ 2.55335808]]\n",
      "[ 0.] [[ 5.56050682]] [[ 2.36125541]]\n",
      "[ 0.] [[ 5.55974007]] [[ 2.28979445]]\n",
      "[ 0.] [[ 5.74231911]] [[ 2.18246603]]\n",
      "[ 0.] [[ 5.85379219]] [[ 2.10002518]]\n",
      "[ 0.] [[ 6.06888723]] [[ 1.83679414]]\n",
      "[ 0.] [[ 6.37885094]] [[ 1.41261935]]\n",
      "[ 0.] [[ 6.59408951]] [[ 1.17655706]]\n",
      "[ 0.] [[ 6.77192593]] [[ 0.96058667]]\n",
      "[ 0.] [[ 7.00953484]] [[ 0.90519685]]\n",
      "[ 1.] [[ 5.11753178]] [[ 2.8242569]]\n",
      "[ 0.] [[ 5.09753418]] [[ 2.68490696]]\n",
      "[ 0.] [[ 5.19421291]] [[ 2.59640169]]\n",
      "[ 0.] [[ 5.38982344]] [[ 2.50026178]]\n",
      "[ 0.] [[ 5.46706963]] [[ 2.30851436]]\n",
      "[ 0.] [[ 5.53172112]] [[ 2.25529814]]\n",
      "[ 0.] [[ 5.73097229]] [[ 2.18254709]]\n",
      "[ 0.] [[ 5.9108181]] [[ 2.01502895]]\n",
      "[ 0.] [[ 6.04010487]] [[ 1.84878409]]\n",
      "[ 0.] [[ 6.21535492]] [[ 1.65928984]]\n",
      "[ 0.] [[ 6.36948681]] [[ 1.46842802]]\n",
      "[ 0.] [[ 6.45129871]] [[ 1.36241388]]\n",
      "[ 0.] [[ 6.51157951]] [[ 1.2953198]]\n",
      "[ 0.] [[ 6.74806976]] [[ 1.0590111]]\n",
      "[ 0.] [[ 6.73882866]] [[ 1.03013432]]\n",
      "[ 0.] [[ 6.78348637]] [[ 1.02267718]]\n",
      "[ 0.] [[ 7.12587833]] [[ 0.87855905]]\n",
      "[ 1.] [[ 4.97596073]] [[ 2.87552857]]\n",
      "[ 0.] [[ 5.01098919]] [[ 2.8101871]]\n",
      "[ 0.] [[ 5.20415974]] [[ 2.7334981]]\n",
      "[ 0.] [[ 5.36229706]] [[ 2.59748363]]\n",
      "[ 0.] [[ 5.36130142]] [[ 2.50226498]]\n",
      "[ 0.] [[ 5.53261948]] [[ 2.4224906]]\n",
      "[ 0.] [[ 5.39964485]] [[ 2.35585356]]\n",
      "[ 0.] [[ 5.44049358]] [[ 2.30006552]]\n",
      "[ 0.] [[ 5.67736244]] [[ 2.23802376]]\n",
      "[ 0.] [[ 5.80955219]] [[ 2.13846374]]\n",
      "[ 0.] [[ 5.89420795]] [[ 2.04383183]]\n",
      "[ 0.] [[ 5.94509697]] [[ 1.85843444]]\n",
      "[ 0.] [[ 6.09592438]] [[ 1.79199481]]\n",
      "[ 0.] [[ 6.19920349]] [[ 1.70466423]]\n",
      "[ 0.] [[ 6.25832272]] [[ 1.6067878]]\n",
      "[ 1.] [[ 4.63463974]] [[ 3.27139068]]\n",
      "[ 0.] [[ 4.85393953]] [[ 3.07017112]]\n",
      "[ 0.] [[ 5.10067463]] [[ 2.81765938]]\n",
      "[ 0.] [[ 5.26764059]] [[ 2.61857557]]\n",
      "[ 0.] [[ 5.53878593]] [[ 2.38720632]]\n",
      "[ 0.] [[ 5.48082256]] [[ 2.24700832]]\n",
      "[ 0.] [[ 5.66903973]] [[ 2.18768549]]\n",
      "[ 0.] [[ 5.84466696]] [[ 2.06441092]]\n",
      "[ 0.] [[ 5.96787357]] [[ 1.9602896]]\n",
      "[ 0.] [[ 5.92152596]] [[ 1.85283959]]\n",
      "[ 0.] [[ 6.13944578]] [[ 1.71181655]]\n",
      "[ 0.] [[ 6.24429035]] [[ 1.5934422]]\n",
      "[ 0.] [[ 6.35733223]] [[ 1.43525207]]\n",
      "[ 0.] [[ 6.4606781]] [[ 1.35389829]]\n",
      "[ 0.] [[ 6.5414238]] [[ 1.22221959]]\n",
      "[ 0.] [[ 6.62468243]] [[ 1.16403627]]\n",
      "[ 0.] [[ 6.71642876]] [[ 1.11332273]]\n",
      "[ 0.] [[ 6.80973148]] [[ 1.00667715]]\n",
      "[ 0.] [[ 6.90586281]] [[ 0.90524077]]\n",
      "[ 1.] [[ 4.93002033]] [[ 2.90534401]]\n",
      "[ 0.] [[ 5.19917107]] [[ 2.73928022]]\n",
      "[ 0.] [[ 5.3050499]] [[ 2.66125679]]\n",
      "[ 0.] [[ 5.59256268]] [[ 2.32289791]]\n",
      "[ 0.] [[ 5.96369267]] [[ 1.9039278]]\n",
      "[ 0.] [[ 6.15556431]] [[ 1.71629167]]\n",
      "[ 0.] [[ 6.24153948]] [[ 1.63645732]]\n",
      "[ 0.] [[ 6.26585197]] [[ 1.55379474]]\n",
      "[ 1.] [[ 4.64820337]] [[ 3.24419212]]\n",
      "[ 0.] [[ 4.86374664]] [[ 2.98257017]]\n",
      "[ 0.] [[ 4.94079399]] [[ 2.75320864]]\n",
      "[ 0.] [[ 5.15355778]] [[ 2.6696465]]\n",
      "[ 0.] [[ 5.36091614]] [[ 2.49835443]]\n",
      "[ 0.] [[ 5.45283985]] [[ 2.41155672]]\n",
      "[ 0.] [[ 5.657341]] [[ 2.26142025]]\n",
      "[ 0.] [[ 5.78241634]] [[ 2.17279291]]\n",
      "[ 0.] [[ 6.00299358]] [[ 1.91354036]]\n",
      "[ 0.] [[ 6.06121445]] [[ 1.8163271]]\n",
      "[ 0.] [[ 6.16719818]] [[ 1.61559749]]\n",
      "[ 0.] [[ 6.3681016]] [[ 1.44724107]]\n",
      "[ 0.] [[ 6.47441435]] [[ 1.34341466]]\n",
      "[ 0.] [[ 6.5481596]] [[ 1.24328816]]\n",
      "[ 0.] [[ 6.62852669]] [[ 1.16227257]]\n",
      "[ 1.] [[ 4.58987427]] [[ 3.02993298]]\n",
      "[ 0.] [[ 4.99570751]] [[ 2.84328961]]\n",
      "[ 0.] [[ 4.99938631]] [[ 2.67032456]]\n",
      "[ 0.] [[ 5.32525301]] [[ 2.56917381]]\n",
      "[ 0.] [[ 5.33511925]] [[ 2.43186235]]\n",
      "[ 0.] [[ 5.36107206]] [[ 2.41612005]]\n",
      "[ 0.] [[ 5.51393175]] [[ 2.31137371]]\n",
      "[ 0.] [[ 5.62939548]] [[ 2.15291405]]\n",
      "[ 0.] [[ 5.78633308]] [[ 2.07793117]]\n",
      "[ 0.] [[ 5.93529224]] [[ 1.97025132]]\n",
      "[ 0.] [[ 6.09753704]] [[ 1.74833691]]\n",
      "[ 0.] [[ 6.22838497]] [[ 1.6114229]]\n",
      "[ 0.] [[ 6.30211353]] [[ 1.54641628]]\n",
      "[ 1.] [[ 4.4234848]] [[ 3.19633436]]\n",
      "[ 0.] [[ 4.88340473]] [[ 2.94521713]]\n",
      "[ 0.] [[ 4.80041504]] [[ 2.83890605]]\n",
      "[ 0.] [[ 5.15588856]] [[ 2.73295498]]\n",
      "[ 0.] [[ 5.32394695]] [[ 2.611835]]\n",
      "[ 0.] [[ 5.33648348]] [[ 2.51263404]]\n",
      "[ 0.] [[ 5.35966349]] [[ 2.48932862]]\n",
      "[ 0.] [[ 5.64249754]] [[ 2.26358032]]\n",
      "[ 0.] [[ 5.81660795]] [[ 2.11980772]]\n",
      "[ 0.] [[ 5.88418961]] [[ 1.9372859]]\n",
      "[ 0.] [[ 6.03825378]] [[ 1.84786129]]\n",
      "[ 0.] [[ 6.13242197]] [[ 1.76065159]]\n",
      "[ 0.] [[ 6.21757698]] [[ 1.66018271]]\n",
      "[ 0.] [[ 6.29873419]] [[ 1.56691599]]\n",
      "[ 0.] [[ 6.40781403]] [[ 1.44996941]]\n",
      "[ 0.] [[ 6.47443342]] [[ 1.36254406]]\n",
      "[ 0.] [[ 6.48816395]] [[ 1.26126468]]\n",
      "[ 0.] [[ 6.67899084]] [[ 1.12735367]]\n",
      "[ 0.] [[ 6.73617315]] [[ 1.09872305]]\n",
      "[ 0.] [[ 6.74857903]] [[ 1.07307148]]\n",
      "[ 0.] [[ 6.81710529]] [[ 1.00591707]]\n",
      "[ 0.] [[ 6.82286596]] [[ 1.00412202]]\n",
      "[ 0.] [[ 6.84340668]] [[ 1.0009495]]\n",
      "[ 0.] [[ 6.86303902]] [[ 0.99802375]]\n",
      "[ 0.] [[ 6.86654663]] [[ 0.98352718]]\n",
      "[ 0.] [[ 7.1635704]] [[ 0.87444007]]\n",
      "[ 1.] [[ 5.74692917]] [[ 2.09070253]]\n",
      "[ 0.] [[ 5.92155075]] [[ 1.9937737]]\n",
      "[ 0.] [[ 6.02706146]] [[ 1.90974724]]\n",
      "[ 0.] [[ 6.12308359]] [[ 1.79408121]]\n",
      "[ 0.] [[ 6.1828537]] [[ 1.68013668]]\n",
      "[ 0.] [[ 6.20068789]] [[ 1.61040401]]\n",
      "[ 1.] [[ 4.48568487]] [[ 3.24844718]]\n",
      "[ 0.] [[ 5.00159693]] [[ 2.89886522]]\n",
      "[ 0.] [[ 5.20347929]] [[ 2.76245594]]\n",
      "[ 0.] [[ 5.34156418]] [[ 2.6254704]]\n",
      "[ 0.] [[ 5.36165953]] [[ 2.49547172]]\n",
      "[ 0.] [[ 5.59043121]] [[ 2.34694695]]\n",
      "[ 0.] [[ 5.80003166]] [[ 2.13627791]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [[ 5.88683224]] [[ 2.05268621]]\n",
      "[ 0.] [[ 5.90395355]] [[ 1.97663975]]\n",
      "[ 0.] [[ 5.97498131]] [[ 1.88033366]]\n",
      "[ 0.] [[ 5.92705297]] [[ 1.84901619]]\n",
      "[ 0.] [[ 6.09698248]] [[ 1.78107142]]\n",
      "[ 0.] [[ 6.34102154]] [[ 1.48224604]]\n",
      "[ 0.] [[ 6.52192497]] [[ 1.29880321]]\n",
      "[ 0.] [[ 6.91123009]] [[ 0.94105804]]\n",
      "[ 1.] [[ 4.79258776]] [[ 2.94779587]]\n",
      "[ 0.] [[ 5.12689209]] [[ 2.78637075]]\n",
      "[ 0.] [[ 5.31573772]] [[ 2.65105653]]\n",
      "[ 0.] [[ 5.45047998]] [[ 2.52953053]]\n",
      "[ 0.] [[ 5.61911774]] [[ 2.32909775]]\n",
      "[ 0.] [[ 5.78396368]] [[ 2.14718294]]\n",
      "[ 0.] [[ 5.78295898]] [[ 2.00752735]]\n",
      "[ 0.] [[ 5.96702814]] [[ 1.93467784]]\n",
      "[ 0.] [[ 6.13752747]] [[ 1.74952435]]\n",
      "[ 0.] [[ 6.2369132]] [[ 1.55937767]]\n",
      "[ 0.] [[ 6.36922455]] [[ 1.46402311]]\n",
      "[ 0.] [[ 6.4536438]] [[ 1.35849977]]\n",
      "[ 0.] [[ 6.62633991]] [[ 1.18886805]]\n",
      "[ 0.] [[ 6.67114353]] [[ 1.14240682]]\n",
      "[ 0.] [[ 6.72719765]] [[ 1.0559324]]\n",
      "[ 0.] [[ 6.75889158]] [[ 1.0364939]]\n",
      "[ 0.] [[ 6.80918598]] [[ 1.00988984]]\n",
      "[ 0.] [[ 6.85660744]] [[ 0.98909575]]\n",
      "[ 0.] [[ 6.85259151]] [[ 0.99061167]]\n",
      "[ 0.] [[ 6.8209486]] [[ 1.00325811]]\n",
      "[ 0.] [[ 6.86420727]] [[ 0.99128497]]\n",
      "[ 0.] [[ 6.81049633]] [[ 1.00262284]]\n",
      "[ 0.] [[ 6.86259508]] [[ 0.9839111]]\n",
      "[ 0.] [[ 6.83881283]] [[ 0.99531657]]\n",
      "[ 0.] [[ 6.90042782]] [[ 0.95661962]]\n",
      "[ 0.] [[ 6.87674427]] [[ 0.97812706]]\n",
      "[ 0.] [[ 6.93389034]] [[ 0.93189621]]\n",
      "[ 1.] [[ 4.93161535]] [[ 2.91734076]]\n",
      "[ 0.] [[ 5.35653973]] [[ 2.52841663]]\n",
      "[ 0.] [[ 5.49757862]] [[ 2.44729042]]\n",
      "[ 0.] [[ 5.62097692]] [[ 2.35226154]]\n",
      "[ 0.] [[ 5.78682995]] [[ 2.13287401]]\n",
      "[ 0.] [[ 5.96072721]] [[ 1.95043492]]\n",
      "[ 0.] [[ 6.03096485]] [[ 1.76193345]]\n",
      "[ 0.] [[ 6.20771265]] [[ 1.65815198]]\n",
      "[ 0.] [[ 6.35503864]] [[ 1.50196218]]\n",
      "[ 0.] [[ 6.44338322]] [[ 1.41279328]]\n",
      "[ 0.] [[ 6.66715527]] [[ 1.14242506]]\n",
      "[ 1.] [[ 4.84749556]] [[ 3.00476694]]\n",
      "[ 0.] [[ 5.00126171]] [[ 2.85239363]]\n",
      "[ 0.] [[ 4.9579649]] [[ 2.68037796]]\n",
      "[ 0.] [[ 5.40349388]] [[ 2.46255684]]\n",
      "[ 0.] [[ 5.37642288]] [[ 2.43348193]]\n",
      "[ 0.] [[ 5.31451988]] [[ 2.38225365]]\n",
      "[ 0.] [[ 5.39300251]] [[ 2.34240627]]\n",
      "[ 0.] [[ 5.37000704]] [[ 2.32641029]]\n",
      "[ 0.] [[ 5.59027481]] [[ 2.2635715]]\n",
      "[ 0.] [[ 5.61516762]] [[ 2.20212054]]\n",
      "[ 0.] [[ 5.93467236]] [[ 1.94219923]]\n",
      "[ 0.] [[ 5.94917488]] [[ 1.92757106]]\n",
      "[ 0.] [[ 6.29689932]] [[ 1.49483168]]\n",
      "[ 0.] [[ 6.92602634]] [[ 0.92170364]]\n",
      "[ 1.] [[ 4.80540037]] [[ 2.83827591]]\n",
      "[ 0.] [[ 5.15476608]] [[ 2.74892974]]\n",
      "[ 0.] [[ 5.41385555]] [[ 2.5339489]]\n",
      "[ 0.] [[ 5.70683479]] [[ 2.19852757]]\n",
      "[ 0.] [[ 5.85271835]] [[ 2.06907916]]\n",
      "[ 0.] [[ 5.80609608]] [[ 1.9601016]]\n",
      "[ 0.] [[ 6.0325222]] [[ 1.80118036]]\n",
      "[ 0.] [[ 6.18080616]] [[ 1.68926215]]\n",
      "[ 0.] [[ 6.28546572]] [[ 1.52590811]]\n",
      "[ 0.] [[ 6.41568661]] [[ 1.42371893]]\n",
      "[ 0.] [[ 6.51063871]] [[ 1.31282032]]\n",
      "[ 0.] [[ 6.59389448]] [[ 1.22714579]]\n",
      "[ 0.] [[ 6.63851118]] [[ 1.16911101]]\n",
      "[ 0.] [[ 6.75943756]] [[ 1.03223312]]\n",
      "[ 0.] [[ 6.81162262]] [[ 1.02032363]]\n",
      "[ 0.] [[ 6.838521]] [[ 1.01395595]]\n",
      "[ 0.] [[ 6.81513596]] [[ 0.98844457]]\n",
      "[ 0.] [[ 6.91212654]] [[ 0.95189875]]\n",
      "[ 0.] [[ 6.86651802]] [[ 0.95792973]]\n",
      "[ 0.] [[ 6.88546848]] [[ 0.97747612]]\n",
      "[ 0.] [[ 6.76914644]] [[ 1.02467752]]\n",
      "[ 0.] [[ 6.81089497]] [[ 1.00932002]]\n",
      "[ 0.] [[ 6.77966928]] [[ 0.99642259]]\n",
      "[ 0.] [[ 6.90897751]] [[ 0.94321245]]\n",
      "[ 1.] [[ 4.88181257]] [[ 2.93868065]]\n",
      "[ 0.] [[ 5.45205784]] [[ 2.32925415]]\n",
      "[ 0.] [[ 5.71094322]] [[ 2.18936706]]\n",
      "[ 0.] [[ 5.79866219]] [[ 2.07206416]]\n",
      "[ 0.] [[ 5.84425163]] [[ 1.94459867]]\n",
      "[ 0.] [[ 6.06125355]] [[ 1.77925086]]\n",
      "[ 0.] [[ 6.1849699]] [[ 1.65991402]]\n",
      "[ 0.] [[ 6.30823469]] [[ 1.56084836]]\n",
      "[ 0.] [[ 6.38128519]] [[ 1.46206415]]\n",
      "[ 0.] [[ 6.47508621]] [[ 1.36708677]]\n",
      "[ 0.] [[ 6.53127861]] [[ 1.2909162]]\n",
      "[ 0.] [[ 6.92322063]] [[ 0.9349153]]\n",
      "[ 0.] [[ 6.88525867]] [[ 0.95187974]]\n",
      "[ 0.] [[ 6.82745934]] [[ 0.97551888]]\n",
      "[ 0.] [[ 6.82729387]] [[ 0.96891618]]\n",
      "[ 0.] [[ 6.93962383]] [[ 0.9144069]]\n",
      "[ 1.] [[ 5.04368591]] [[ 2.82630324]]\n",
      "[ 0.] [[ 5.26322985]] [[ 2.68318272]]\n",
      "[ 0.] [[ 5.4359684]] [[ 2.51750493]]\n",
      "[ 0.] [[ 5.40294743]] [[ 2.36685801]]\n",
      "[ 0.] [[ 5.66662693]] [[ 2.22367239]]\n",
      "[ 0.] [[ 5.60842276]] [[ 2.1252656]]\n",
      "[ 0.] [[ 5.88062525]] [[ 1.99094725]]\n",
      "[ 0.] [[ 5.86760998]] [[ 1.96970963]]\n",
      "[ 0.] [[ 6.02304888]] [[ 1.88337517]]\n",
      "[ 0.] [[ 6.10275459]] [[ 1.80241191]]\n",
      "[ 0.] [[ 6.0349555]] [[ 1.76075315]]\n",
      "[ 0.] [[ 6.24211884]] [[ 1.53819239]]\n",
      "[ 1.] [[ 4.43511868]] [[ 3.2964499]]\n",
      "[ 0.] [[ 4.59024906]] [[ 3.11938667]]\n",
      "[ 0.] [[ 4.90361691]] [[ 2.96906853]]\n",
      "[ 0.] [[ 5.12355661]] [[ 2.80137491]]\n",
      "[ 0.] [[ 5.48128033]] [[ 2.41397619]]\n",
      "[ 0.] [[ 5.45736408]] [[ 2.34910607]]\n",
      "[ 0.] [[ 5.59698105]] [[ 2.24003029]]\n",
      "[ 0.] [[ 5.53820229]] [[ 2.19085789]]\n",
      "[ 0.] [[ 5.72662449]] [[ 2.12086511]]\n",
      "[ 0.] [[ 5.95301533]] [[ 1.93711877]]\n",
      "[ 0.] [[ 6.03189993]] [[ 1.86139727]]\n",
      "[ 1.] [[ 4.38068533]] [[ 3.29873657]]\n",
      "[ 0.] [[ 4.8227911]] [[ 3.05272532]]\n",
      "[ 0.] [[ 4.91629982]] [[ 2.87461662]]\n",
      "[ 0.] [[ 5.21090698]] [[ 2.71618819]]\n",
      "[ 0.] [[ 5.26828814]] [[ 2.50024128]]\n",
      "[ 0.] [[ 5.50848675]] [[ 2.34203863]]\n",
      "[ 0.] [[ 5.49369621]] [[ 2.20819736]]\n",
      "[ 0.] [[ 5.78393173]] [[ 2.07360482]]\n",
      "[ 0.] [[ 5.9757576]] [[ 1.93088675]]\n",
      "[ 0.] [[ 6.07473564]] [[ 1.83547962]]\n",
      "[ 0.] [[ 6.10279846]] [[ 1.68398571]]\n",
      "[ 0.] [[ 6.40253735]] [[ 1.38338017]]\n",
      "[ 0.] [[ 6.57502651]] [[ 1.21291685]]\n",
      "[ 0.] [[ 6.64606857]] [[ 1.13383555]]\n",
      "[ 0.] [[ 6.72574329]] [[ 1.07555306]]\n",
      "[ 0.] [[ 6.80210543]] [[ 0.96796823]]\n",
      "[ 0.] [[ 7.01885605]] [[ 0.90460622]]\n",
      "[ 1.] [[ 5.08960342]] [[ 2.84796047]]\n",
      "[ 0.] [[ 5.58291769]] [[ 2.23938203]]\n",
      "[ 0.] [[ 5.69444656]] [[ 2.15696645]]\n",
      "[ 0.] [[ 5.91447544]] [[ 1.98948455]]\n",
      "[ 0.] [[ 6.06259632]] [[ 1.83927107]]\n",
      "[ 0.] [[ 6.08867455]] [[ 1.68119907]]\n",
      "[ 0.] [[ 6.25754261]] [[ 1.59453523]]\n",
      "[ 1.] [[ 4.75147676]] [[ 3.1485548]]\n",
      "[ 0.] [[ 4.86724758]] [[ 2.96891546]]\n",
      "[ 0.] [[ 5.48952293]] [[ 2.36138988]]\n",
      "[ 0.] [[ 5.43841553]] [[ 2.2651825]]\n",
      "[ 0.] [[ 5.70797777]] [[ 2.18064356]]\n",
      "[ 0.] [[ 5.80110884]] [[ 2.00225282]]\n",
      "[ 0.] [[ 5.97017765]] [[ 1.91526055]]\n",
      "[ 0.] [[ 6.09736061]] [[ 1.77952635]]\n",
      "[ 0.] [[ 6.29188442]] [[ 1.5534302]]\n",
      "[ 0.] [[ 6.37237072]] [[ 1.47407591]]\n",
      "[ 0.] [[ 6.43375015]] [[ 1.39075649]]\n",
      "[ 0.] [[ 6.62447071]] [[ 1.150594]]\n",
      "[ 0.] [[ 6.77541494]] [[ 1.0441823]]\n",
      "[ 0.] [[ 6.81075382]] [[ 1.0274775]]\n",
      "[ 0.] [[ 6.82577515]] [[ 1.0232451]]\n",
      "[ 0.] [[ 6.81742954]] [[ 1.01395631]]\n",
      "[ 0.] [[ 6.90050793]] [[ 0.96240222]]\n",
      "[ 0.] [[ 7.30684471]] [[ 0.83425331]]\n",
      "[ 1.] [[ 5.46243715]] [[ 2.50186634]]\n",
      "[ 0.] [[ 5.57899904]] [[ 2.38995218]]\n",
      "[ 0.] [[ 5.68180275]] [[ 2.29563379]]\n",
      "[ 0.] [[ 5.83931923]] [[ 2.10119247]]\n",
      "[ 0.] [[ 5.94276667]] [[ 1.99041271]]\n",
      "[ 0.] [[ 6.10258484]] [[ 1.79791689]]\n",
      "[ 0.] [[ 6.10289192]] [[ 1.77535081]]\n",
      "[ 0.] [[ 6.21199608]] [[ 1.6845448]]\n",
      "[ 1.] [[ 4.35946512]] [[ 3.29288888]]\n",
      "[ 0.] [[ 4.53568459]] [[ 3.10039902]]\n",
      "[ 0.] [[ 4.90886784]] [[ 2.94598269]]\n",
      "[ 0.] [[ 5.00691319]] [[ 2.79726338]]\n",
      "[ 0.] [[ 5.24481773]] [[ 2.69877052]]\n",
      "[ 0.] [[ 5.29923439]] [[ 2.52493525]]\n",
      "[ 0.] [[ 5.51805878]] [[ 2.42413378]]\n",
      "[ 0.] [[ 5.69385052]] [[ 2.23940611]]\n",
      "[ 0.] [[ 5.69869041]] [[ 2.10760641]]\n",
      "[ 0.] [[ 5.86949635]] [[ 2.0333426]]\n",
      "[ 0.] [[ 5.9521904]] [[ 1.8597343]]\n",
      "[ 0.] [[ 6.10739136]] [[ 1.76743746]]\n",
      "[ 0.] [[ 6.20542049]] [[ 1.67662859]]\n",
      "[ 0.] [[ 6.27145863]] [[ 1.56133962]]\n",
      "[ 0.] [[ 6.3751688]] [[ 1.4407419]]\n",
      "[ 0.] [[ 6.4675827]] [[ 1.36312103]]\n",
      "[ 0.] [[ 6.55405569]] [[ 1.28265584]]\n",
      "[ 0.] [[ 6.67104816]] [[ 1.15235996]]\n",
      "[ 0.] [[ 6.73986673]] [[ 1.0983423]]\n",
      "[ 0.] [[ 6.6718092]] [[ 1.11101854]]\n",
      "[ 0.] [[ 6.73541546]] [[ 1.06160069]]\n",
      "[ 0.] [[ 6.78489351]] [[ 1.02806842]]\n",
      "[ 0.] [[ 6.8162775]] [[ 1.01776624]]\n",
      "[ 0.] [[ 6.84986115]] [[ 1.00739408]]\n",
      "[ 0.] [[ 6.808321]] [[ 0.98724741]]\n",
      "[ 0.] [[ 6.85266399]] [[ 0.97966015]]\n",
      "[ 0.] [[ 6.91646862]] [[ 0.94609845]]\n",
      "[ 0.] [[ 6.94996452]] [[ 0.94251186]]\n",
      "[ 1.] [[ 4.80921507]] [[ 2.86229777]]\n",
      "[ 0.] [[ 4.80306244]] [[ 2.78473878]]\n",
      "[ 0.] [[ 5.33229685]] [[ 2.52166104]]\n",
      "[ 0.] [[ 5.6264677]] [[ 2.22914457]]\n",
      "[ 0.] [[ 5.55294752]] [[ 2.20200086]]\n",
      "[ 0.] [[ 5.59423304]] [[ 2.19505453]]\n",
      "[ 0.] [[ 6.13333988]] [[ 1.61641216]]\n",
      "[ 0.] [[ 6.36408806]] [[ 1.39191759]]\n",
      "[ 0.] [[ 6.57264853]] [[ 1.23247492]]\n",
      "[ 0.] [[ 6.65470552]] [[ 1.15347755]]\n",
      "[ 0.] [[ 6.71638584]] [[ 1.11038876]]\n",
      "[ 0.] [[ 6.7665019]] [[ 1.06339848]]\n",
      "[ 0.] [[ 6.77882481]] [[ 1.01020825]]\n",
      "[ 0.] [[ 6.79186296]] [[ 1.01706278]]\n",
      "[ 0.] [[ 6.8216424]] [[ 0.97468805]]\n",
      "[ 0.] [[ 6.92527866]] [[ 0.94473082]]\n",
      "[ 1.] [[ 5.01622963]] [[ 2.86471343]]\n",
      "[ 0.] [[ 5.21375275]] [[ 2.7484169]]\n",
      "[ 0.] [[ 5.37655163]] [[ 2.56704926]]\n",
      "[ 0.] [[ 5.60553455]] [[ 2.34218788]]\n",
      "[ 0.] [[ 5.57722569]] [[ 2.19146562]]\n",
      "[ 0.] [[ 6.15365219]] [[ 1.61235237]]\n",
      "[ 0.] [[ 6.31497192]] [[ 1.50085521]]\n",
      "[ 0.] [[ 6.45499229]] [[ 1.30342197]]\n",
      "[ 0.] [[ 6.56431389]] [[ 1.23721993]]\n",
      "[ 0.] [[ 6.64480257]] [[ 1.17604637]]\n",
      "[ 0.] [[ 6.78061771]] [[ 1.04171586]]\n",
      "[ 0.] [[ 6.82231712]] [[ 1.02141762]]\n",
      "[ 0.] [[ 7.26373768]] [[ 0.8394959]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.] [[ 5.23281765]] [[ 2.75581789]]\n",
      "[ 0.] [[ 5.35605526]] [[ 2.60752916]]\n",
      "[ 0.] [[ 5.47024441]] [[ 2.48949814]]\n",
      "[ 0.] [[ 5.40308857]] [[ 2.40180302]]\n",
      "[ 0.] [[ 5.74744749]] [[ 2.14704609]]\n",
      "[ 0.] [[ 5.82745838]] [[ 2.07648969]]\n",
      "[ 0.] [[ 5.82504082]] [[ 2.06210017]]\n",
      "[ 0.] [[ 5.92298126]] [[ 1.88023758]]\n",
      "[ 0.] [[ 6.0847702]] [[ 1.7914629]]\n",
      "[ 0.] [[ 6.11087894]] [[ 1.71487749]]\n",
      "[ 0.] [[ 6.25006485]] [[ 1.61308885]]\n",
      "[ 0.] [[ 6.34966755]] [[ 1.45082736]]\n",
      "[ 0.] [[ 6.46822929]] [[ 1.34486687]]\n",
      "[ 0.] [[ 6.52109241]] [[ 1.25365973]]\n",
      "[ 0.] [[ 6.62716627]] [[ 1.18634033]]\n",
      "[ 0.] [[ 6.69854259]] [[ 1.14120102]]\n",
      "[ 1.] [[ 4.71870041]] [[ 3.03209424]]\n",
      "[ 0.] [[ 5.02403402]] [[ 2.88413811]]\n",
      "[ 0.] [[ 5.24170065]] [[ 2.71986175]]\n",
      "[ 0.] [[ 5.29854822]] [[ 2.56974459]]\n",
      "[ 0.] [[ 5.32470465]] [[ 2.4901371]]\n",
      "[ 0.] [[ 5.29486084]] [[ 2.39053988]]\n",
      "[ 0.] [[ 5.54923916]] [[ 2.33793974]]\n",
      "[ 0.] [[ 5.64161825]] [[ 2.30375624]]\n",
      "[ 0.] [[ 5.59512711]] [[ 2.23795223]]\n",
      "[ 0.] [[ 5.71635818]] [[ 2.09716249]]\n",
      "[ 0.] [[ 5.85855865]] [[ 2.01610422]]\n",
      "[ 0.] [[ 5.94218779]] [[ 1.92549789]]\n",
      "[ 0.] [[ 6.07250929]] [[ 1.81157398]]\n",
      "[ 0.] [[ 6.31121159]] [[ 1.43701506]]\n",
      "[ 0.] [[ 6.42995548]] [[ 1.36313903]]\n",
      "[ 0.] [[ 6.59348679]] [[ 1.19586813]]\n",
      "[ 0.] [[ 6.68899727]] [[ 1.14149678]]\n",
      "[ 0.] [[ 6.75615597]] [[ 1.08707368]]\n",
      "[ 0.] [[ 6.75676537]] [[ 1.03697467]]\n",
      "[ 0.] [[ 6.81208801]] [[ 0.95484787]]\n",
      "[ 0.] [[ 6.86735439]] [[ 0.97640258]]\n",
      "[ 0.] [[ 6.9463625]] [[ 0.93665642]]\n",
      "[ 1.] [[ 4.81550312]] [[ 2.87691545]]\n",
      "[ 0.] [[ 5.1787138]] [[ 2.67022371]]\n",
      "[ 0.] [[ 5.42868805]] [[ 2.47737265]]\n",
      "[ 0.] [[ 5.5185461]] [[ 2.38090706]]\n",
      "[ 0.] [[ 5.4429369]] [[ 2.27823591]]\n",
      "[ 0.] [[ 5.94138622]] [[ 1.8649404]]\n",
      "[ 0.] [[ 6.07777643]] [[ 1.7872479]]\n",
      "[ 0.] [[ 6.2022543]] [[ 1.68538928]]\n",
      "[ 0.] [[ 6.28842211]] [[ 1.55610669]]\n",
      "[ 0.] [[ 6.42518806]] [[ 1.40776622]]\n",
      "[ 0.] [[ 6.50041103]] [[ 1.33114552]]\n",
      "[ 0.] [[ 6.62430382]] [[ 1.19868457]]\n",
      "[ 0.] [[ 6.66164732]] [[ 1.14565754]]\n",
      "[ 0.] [[ 6.89112949]] [[ 0.95364988]]\n",
      "[ 0.] [[ 6.83610439]] [[ 0.97866005]]\n",
      "[ 1.] [[ 4.92128849]] [[ 2.87794685]]\n",
      "[ 0.] [[ 5.192626]] [[ 2.73462772]]\n",
      "[ 0.] [[ 5.35528088]] [[ 2.61235619]]\n",
      "[ 0.] [[ 5.46908188]] [[ 2.43358946]]\n",
      "[ 0.] [[ 5.62633324]] [[ 2.3242991]]\n",
      "[ 0.] [[ 5.71880913]] [[ 2.22470403]]\n",
      "[ 0.] [[ 6.16556168]] [[ 1.63371396]]\n",
      "[ 0.] [[ 6.29800749]] [[ 1.5534091]]\n",
      "[ 0.] [[ 6.5117569]] [[ 1.20279241]]\n",
      "[ 0.] [[ 6.68533325]] [[ 1.07011843]]\n",
      "[ 0.] [[ 6.71749735]] [[ 1.05448651]]\n",
      "[ 0.] [[ 6.86395168]] [[ 0.96922481]]\n",
      "[ 0.] [[ 7.03618908]] [[ 0.88587624]]\n",
      "[ 1.] [[ 5.03842449]] [[ 2.86438465]]\n",
      "[ 0.] [[ 4.99407959]] [[ 2.78894544]]\n",
      "[ 0.] [[ 5.13859272]] [[ 2.6214242]]\n",
      "[ 0.] [[ 5.39542484]] [[ 2.53434324]]\n",
      "[ 0.] [[ 5.37381649]] [[ 2.50037503]]\n",
      "[ 0.] [[ 5.38079929]] [[ 2.42689991]]\n",
      "[ 0.] [[ 5.63018608]] [[ 2.28107548]]\n",
      "[ 0.] [[ 5.70201969]] [[ 2.11165857]]\n",
      "[ 0.] [[ 5.87963486]] [[ 2.03742218]]\n",
      "[ 0.] [[ 5.99604607]] [[ 1.93987393]]\n",
      "[ 0.] [[ 6.14799881]] [[ 1.74584317]]\n",
      "[ 0.] [[ 6.23894882]] [[ 1.62052023]]\n",
      "[ 0.] [[ 6.20387936]] [[ 1.57533169]]\n",
      "[ 0.] [[ 6.35492563]] [[ 1.44061553]]\n",
      "[ 0.] [[ 6.46510315]] [[ 1.36195469]]\n",
      "[ 0.] [[ 6.51642084]] [[ 1.22299337]]\n",
      "[ 0.] [[ 6.6176033]] [[ 1.16487372]]\n",
      "[ 0.] [[ 6.67863989]] [[ 1.09464347]]\n",
      "[ 0.] [[ 6.73346519]] [[ 1.0199734]]\n",
      "[ 1.] [[ 4.71475029]] [[ 2.91668034]]\n",
      "[ 0.] [[ 5.05066061]] [[ 2.81352758]]\n",
      "[ 0.] [[ 5.26120758]] [[ 2.68905067]]\n",
      "[ 0.] [[ 5.20213699]] [[ 2.59682417]]\n",
      "[ 0.] [[ 5.51652622]] [[ 2.37827682]]\n",
      "[ 0.] [[ 5.67978859]] [[ 2.21235585]]\n",
      "[ 0.] [[ 5.70699692]] [[ 2.08564258]]\n",
      "[ 0.] [[ 5.8959074]] [[ 2.01254988]]\n",
      "[ 0.] [[ 5.91537571]] [[ 1.91134048]]\n",
      "[ 0.] [[ 6.10264301]] [[ 1.77152133]]\n",
      "[ 0.] [[ 6.20614433]] [[ 1.69021702]]\n",
      "[ 0.] [[ 6.29934502]] [[ 1.58725536]]\n",
      "[ 0.] [[ 6.37813663]] [[ 1.49033237]]\n",
      "[ 0.] [[ 6.39305019]] [[ 1.40306044]]\n",
      "[ 0.] [[ 6.50975323]] [[ 1.31549263]]\n",
      "[ 0.] [[ 6.66989899]] [[ 1.15215945]]\n",
      "[ 0.] [[ 6.71933794]] [[ 1.1054399]]\n",
      "[ 1.] [[ 4.89890003]] [[ 2.97824073]]\n",
      "[ 0.] [[ 5.04147148]] [[ 2.82553148]]\n",
      "[ 0.] [[ 5.14273643]] [[ 2.70322537]]\n",
      "[ 0.] [[ 5.18210125]] [[ 2.61308646]]\n",
      "[ 0.] [[ 5.55475903]] [[ 2.34740543]]\n",
      "[ 0.] [[ 5.67420864]] [[ 2.25325346]]\n",
      "[ 0.] [[ 5.80116272]] [[ 2.14351821]]\n",
      "[ 0.] [[ 5.7871666]] [[ 1.99360394]]\n",
      "[ 0.] [[ 5.92052174]] [[ 1.894943]]\n",
      "[ 0.] [[ 6.08647442]] [[ 1.80137467]]\n",
      "[ 0.] [[ 6.36039448]] [[ 1.46281004]]\n",
      "[ 0.] [[ 6.42967796]] [[ 1.35791159]]\n",
      "[ 0.] [[ 6.48319817]] [[ 1.25534976]]\n",
      "[ 0.] [[ 6.68476105]] [[ 1.11355817]]\n",
      "[ 0.] [[ 6.80925083]] [[ 1.02020991]]\n",
      "[ 0.] [[ 6.77111769]] [[ 1.03284717]]\n",
      "[ 0.] [[ 6.83557892]] [[ 1.00218511]]\n",
      "[ 0.] [[ 6.81238461]] [[ 1.00829816]]\n",
      "[ 0.] [[ 6.73472118]] [[ 1.04715872]]\n",
      "[ 0.] [[ 6.78982162]] [[ 1.03074408]]\n",
      "[ 0.] [[ 6.84195518]] [[ 0.94524992]]\n",
      "[ 0.] [[ 6.87923145]] [[ 0.97453755]]\n",
      "[ 0.] [[ 6.86756659]] [[ 0.97198117]]\n",
      "[ 0.] [[ 6.86394405]] [[ 0.95103574]]\n",
      "[ 0.] [[ 6.9390583]] [[ 0.93882179]]\n",
      "[ 1.] [[ 5.66322613]] [[ 2.11379623]]\n",
      "[ 0.] [[ 5.95943832]] [[ 1.90632153]]\n",
      "[ 0.] [[ 6.12591457]] [[ 1.75562072]]\n",
      "[ 1.] [[ 4.58312511]] [[ 3.32368326]]\n",
      "[ 0.] [[ 4.76196003]] [[ 3.10742378]]\n",
      "[ 0.] [[ 5.15637207]] [[ 2.77250195]]\n",
      "[ 0.] [[ 5.2021594]] [[ 2.6399889]]\n",
      "[ 0.] [[ 5.33549118]] [[ 2.53571367]]\n",
      "[ 0.] [[ 5.52687263]] [[ 2.41445041]]\n",
      "[ 0.] [[ 5.66188002]] [[ 2.24093342]]\n",
      "[ 0.] [[ 5.80041409]] [[ 2.12782693]]\n",
      "[ 0.] [[ 6.03709126]] [[ 1.82647359]]\n",
      "[ 0.] [[ 6.1508646]] [[ 1.73705339]]\n",
      "[ 0.] [[ 6.58458328]] [[ 1.1808672]]\n",
      "[ 0.] [[ 6.75942183]] [[ 1.04899001]]\n",
      "[ 0.] [[ 6.86023998]] [[ 0.96543837]]\n",
      "[ 0.] [[ 6.84580898]] [[ 0.97036034]]\n",
      "[ 0.] [[ 6.85126019]] [[ 0.96947289]]\n",
      "[ 0.] [[ 6.86301327]] [[ 0.9663204]]\n",
      "[ 0.] [[ 6.82959652]] [[ 0.99096793]]\n",
      "[ 0.] [[ 6.86856842]] [[ 0.98565686]]\n",
      "[ 0.] [[ 6.89977074]] [[ 0.96902555]]\n",
      "[ 0.] [[ 7.04578304]] [[ 0.90626466]]\n",
      "[ 1.] [[ 5.06882668]] [[ 2.83236718]]\n",
      "[ 0.] [[ 5.22320271]] [[ 2.71194315]]\n",
      "[ 0.] [[ 5.27469826]] [[ 2.51742315]]\n",
      "[ 0.] [[ 5.43122482]] [[ 2.43009138]]\n",
      "[ 0.] [[ 5.65184307]] [[ 2.28172469]]\n",
      "[ 0.] [[ 5.7580409]] [[ 2.20580316]]\n",
      "[ 0.] [[ 5.86782742]] [[ 2.09072399]]\n",
      "[ 0.] [[ 5.94796658]] [[ 2.00176024]]\n",
      "[ 0.] [[ 5.99252987]] [[ 1.92306638]]\n",
      "[ 0.] [[ 6.01942396]] [[ 1.78551698]]\n",
      "[ 0.] [[ 6.14126301]] [[ 1.69866896]]\n",
      "[ 0.] [[ 6.30502701]] [[ 1.52968228]]\n",
      "[ 0.] [[ 6.41512156]] [[ 1.42122054]]\n",
      "[ 0.] [[ 6.46703291]] [[ 1.31954718]]\n",
      "[ 0.] [[ 6.58197021]] [[ 1.24509799]]\n",
      "[ 0.] [[ 6.55522919]] [[ 1.23187554]]\n",
      "[ 0.] [[ 6.72531509]] [[ 1.08692515]]\n",
      "[ 0.] [[ 6.75209141]] [[ 1.05987787]]\n",
      "[ 0.] [[ 6.86171675]] [[ 0.98227537]]\n",
      "[ 0.] [[ 6.93508053]] [[ 0.89635503]]\n",
      "[ 1.] [[ 4.72317123]] [[ 2.9167738]]\n",
      "[ 0.] [[ 5.35869598]] [[ 2.48234558]]\n",
      "[ 0.] [[ 5.59927464]] [[ 2.3052907]]\n",
      "[ 0.] [[ 5.80897665]] [[ 2.12200451]]\n",
      "[ 0.] [[ 5.92397022]] [[ 2.02498055]]\n",
      "[ 0.] [[ 6.04544401]] [[ 1.85129213]]\n",
      "[ 1.] [[ 4.51694822]] [[ 3.40136409]]\n",
      "[ 0.] [[ 4.80578566]] [[ 3.15382195]]\n",
      "[ 0.] [[ 4.79308987]] [[ 2.98438215]]\n",
      "[ 0.] [[ 5.11083603]] [[ 2.81944084]]\n",
      "[ 0.] [[ 5.07160282]] [[ 2.63655281]]\n",
      "[ 0.] [[ 5.50334263]] [[ 2.3771069]]\n",
      "[ 0.] [[ 5.71526623]] [[ 2.19532609]]\n",
      "[ 0.] [[ 5.77216911]] [[ 2.08865309]]\n",
      "[ 0.] [[ 5.90940666]] [[ 1.99920833]]\n",
      "[ 0.] [[ 6.10661221]] [[ 1.78131676]]\n",
      "[ 0.] [[ 6.11400986]] [[ 1.75924325]]\n",
      "[ 0.] [[ 6.19574738]] [[ 1.67009974]]\n",
      "[ 1.] [[ 4.71423721]] [[ 3.19517517]]\n",
      "[ 0.] [[ 5.00750446]] [[ 2.90959859]]\n",
      "[ 0.] [[ 4.90075302]] [[ 2.75869322]]\n",
      "[ 0.] [[ 5.22558403]] [[ 2.64427519]]\n",
      "[ 0.] [[ 5.12048912]] [[ 2.59218502]]\n",
      "[ 0.] [[ 5.39191675]] [[ 2.52720308]]\n",
      "[ 0.] [[ 5.53905487]] [[ 2.42321968]]\n",
      "[ 0.] [[ 5.57040787]] [[ 2.32128811]]\n",
      "[ 0.] [[ 5.70864773]] [[ 2.24336243]]\n",
      "[ 0.] [[ 5.87120533]] [[ 2.06801772]]\n",
      "[ 0.] [[ 5.98045349]] [[ 1.93371105]]\n",
      "[ 0.] [[ 6.05926371]] [[ 1.8385514]]\n",
      "[ 0.] [[ 6.12062025]] [[ 1.73256278]]\n",
      "[ 0.] [[ 6.17686749]] [[ 1.62480557]]\n",
      "[ 0.] [[ 6.30510044]] [[ 1.53834796]]\n",
      "[ 1.] [[ 4.46289825]] [[ 3.19681573]]\n",
      "[ 0.] [[ 4.58380795]] [[ 3.08956194]]\n",
      "[ 0.] [[ 4.7586689]] [[ 2.85766268]]\n",
      "[ 0.] [[ 5.08066845]] [[ 2.7470181]]\n",
      "[ 0.] [[ 5.32960224]] [[ 2.60630012]]\n",
      "[ 0.] [[ 5.3826189]] [[ 2.39999342]]\n",
      "[ 0.] [[ 5.71371078]] [[ 2.11817408]]\n",
      "[ 0.] [[ 5.88948536]] [[ 2.01739621]]\n",
      "[ 0.] [[ 6.02001858]] [[ 1.86089683]]\n",
      "[ 0.] [[ 6.12751675]] [[ 1.74171555]]\n",
      "[ 0.] [[ 6.1427927]] [[ 1.67168152]]\n",
      "[ 0.] [[ 6.62012243]] [[ 1.13028419]]\n",
      "[ 0.] [[ 6.70935917]] [[ 1.09940386]]\n",
      "[ 1.] [[ 4.63282919]] [[ 2.99143052]]\n",
      "[ 0.] [[ 5.02131462]] [[ 2.84627962]]\n",
      "[ 0.] [[ 5.11301851]] [[ 2.63486052]]\n",
      "[ 0.] [[ 5.41401768]] [[ 2.48730183]]\n",
      "[ 0.] [[ 5.64599228]] [[ 2.2671361]]\n",
      "[ 0.] [[ 5.65419292]] [[ 2.19745278]]\n",
      "[ 0.] [[ 5.81942177]] [[ 2.10789895]]\n",
      "[ 0.] [[ 5.93026972]] [[ 1.99505734]]\n",
      "[ 0.] [[ 5.9040494]] [[ 1.91872454]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [[ 6.03691959]] [[ 1.80102706]]\n",
      "[ 0.] [[ 6.23672533]] [[ 1.56931114]]\n",
      "[ 0.] [[ 6.40058994]] [[ 1.42394114]]\n",
      "[ 0.] [[ 6.47443008]] [[ 1.33849192]]\n",
      "[ 0.] [[ 6.56348133]] [[ 1.2729497]]\n",
      "[ 0.] [[ 6.60950994]] [[ 1.17854536]]\n",
      "[ 0.] [[ 6.69027519]] [[ 1.13136995]]\n",
      "[ 0.] [[ 7.04394531]] [[ 0.89095151]]\n",
      "[ 1.] [[ 5.00907803]] [[ 2.88193607]]\n",
      "[ 0.] [[ 5.22436571]] [[ 2.73583841]]\n",
      "[ 0.] [[ 5.27041578]] [[ 2.55630207]]\n",
      "[ 0.] [[ 5.4709754]] [[ 2.46540833]]\n",
      "[ 0.] [[ 6.18060684]] [[ 1.56756234]]\n",
      "[ 0.] [[ 6.33820295]] [[ 1.49107254]]\n",
      "[ 1.] [[ 4.44380474]] [[ 3.16918373]]\n",
      "[ 0.] [[ 4.49253702]] [[ 3.06675816]]\n",
      "[ 0.] [[ 4.93494225]] [[ 2.91415548]]\n",
      "[ 0.] [[ 5.17519665]] [[ 2.77398014]]\n",
      "[ 0.] [[ 5.58440876]] [[ 2.33198738]]\n",
      "[ 0.] [[ 5.66483641]] [[ 2.25065327]]\n",
      "[ 0.] [[ 5.72353363]] [[ 2.15858984]]\n",
      "[ 0.] [[ 5.77296352]] [[ 2.08299446]]\n",
      "[ 0.] [[ 5.86277866]] [[ 1.97984076]]\n",
      "[ 0.] [[ 5.98361683]] [[ 1.83186197]]\n",
      "[ 0.] [[ 6.20985699]] [[ 1.63992012]]\n",
      "[ 0.] [[ 6.30144882]] [[ 1.55541933]]\n",
      "[ 0.] [[ 6.39289188]] [[ 1.43740261]]\n",
      "[ 0.] [[ 6.58847952]] [[ 1.18912899]]\n",
      "[ 0.] [[ 6.67967796]] [[ 1.08255792]]\n",
      "[ 0.] [[ 6.76936722]] [[ 0.97827417]]\n",
      "[ 0.] [[ 6.83456802]] [[ 0.97776508]]\n",
      "[ 0.] [[ 6.92345047]] [[ 0.9307434]]\n",
      "[ 1.] [[ 5.02622795]] [[ 2.88663101]]\n",
      "[ 0.] [[ 5.22808552]] [[ 2.73747778]]\n",
      "[ 0.] [[ 5.20267248]] [[ 2.63059664]]\n",
      "[ 0.] [[ 5.51397991]] [[ 2.39698267]]\n",
      "[ 0.] [[ 5.65547991]] [[ 2.302495]]\n",
      "[ 0.] [[ 5.74223137]] [[ 2.20334721]]\n",
      "[ 0.] [[ 5.91577291]] [[ 2.01602054]]\n",
      "[ 0.] [[ 5.99690104]] [[ 1.94322658]]\n",
      "[ 0.] [[ 6.0769968]] [[ 1.84330285]]\n",
      "[ 0.] [[ 6.15083361]] [[ 1.75142789]]\n",
      "[ 0.] [[ 6.31421661]] [[ 1.54927766]]\n",
      "[ 0.] [[ 6.45284176]] [[ 1.3791703]]\n",
      "[ 0.] [[ 6.65043545]] [[ 1.14381433]]\n",
      "[ 0.] [[ 6.73566246]] [[ 1.09562659]]\n",
      "[ 1.] [[ 4.69565201]] [[ 2.95833635]]\n",
      "[ 0.] [[ 4.92955017]] [[ 2.83907008]]\n",
      "[ 0.] [[ 5.81279659]] [[ 1.92382848]]\n",
      "[ 0.] [[ 6.03605366]] [[ 1.8284874]]\n",
      "[ 0.] [[ 6.16918564]] [[ 1.66858125]]\n",
      "[ 0.] [[ 6.29436398]] [[ 1.52980816]]\n",
      "[ 0.] [[ 6.38958454]] [[ 1.41122401]]\n",
      "[ 0.] [[ 6.47125816]] [[ 1.30867016]]\n",
      "[ 0.] [[ 6.52133751]] [[ 1.29483938]]\n",
      "[ 0.] [[ 6.66829395]] [[ 1.14974427]]\n",
      "[ 0.] [[ 6.73237753]] [[ 1.09407842]]\n",
      "[ 0.] [[ 6.74910164]] [[ 1.04282176]]\n",
      "[ 0.] [[ 6.85188055]] [[ 0.9667238]]\n",
      "[ 0.] [[ 6.87652206]] [[ 0.98319715]]\n",
      "[ 0.] [[ 6.90369129]] [[ 0.9677881]]\n",
      "[ 0.] [[ 6.84670258]] [[ 0.98605627]]\n",
      "[ 1.] [[ 4.7067728]] [[ 2.92439175]]\n",
      "[ 0.] [[ 5.11115837]] [[ 2.7763443]]\n",
      "[ 0.] [[ 5.2293148]] [[ 2.65246177]]\n",
      "[ 0.] [[ 5.57098722]] [[ 2.31759596]]\n",
      "[ 0.] [[ 5.76255894]] [[ 2.16777849]]\n",
      "[ 0.] [[ 6.22775841]] [[ 1.58299816]]\n",
      "[ 0.] [[ 6.27591896]] [[ 1.54835093]]\n",
      "[ 0.] [[ 6.41238594]] [[ 1.34760201]]\n",
      "[ 0.] [[ 6.54735661]] [[ 1.26578629]]\n",
      "[ 0.] [[ 6.56133366]] [[ 1.24464643]]\n",
      "[ 0.] [[ 6.6414032]] [[ 1.13621926]]\n",
      "[ 1.] [[ 4.86522055]] [[ 3.00185728]]\n",
      "[ 0.] [[ 4.78389215]] [[ 2.84327793]]\n",
      "[ 0.] [[ 4.89585209]] [[ 2.76924896]]\n",
      "[ 0.] [[ 5.31379318]] [[ 2.47545457]]\n",
      "[ 0.] [[ 5.54412127]] [[ 2.37079144]]\n",
      "[ 0.] [[ 5.49614716]] [[ 2.22871161]]\n",
      "[ 0.] [[ 5.7340889]] [[ 2.16820478]]\n",
      "[ 0.] [[ 5.85965633]] [[ 2.08640385]]\n",
      "[ 0.] [[ 5.95932913]] [[ 1.96517384]]\n",
      "[ 0.] [[ 6.19605827]] [[ 1.58774853]]\n",
      "[ 0.] [[ 6.3633604]] [[ 1.43722582]]\n",
      "[ 0.] [[ 6.48229218]] [[ 1.34285891]]\n",
      "[ 0.] [[ 6.56561995]] [[ 1.26443756]]\n",
      "[ 0.] [[ 6.62885284]] [[ 1.17959237]]\n",
      "[ 0.] [[ 6.68712902]] [[ 1.13377166]]\n",
      "[ 0.] [[ 6.67822027]] [[ 1.10625553]]\n",
      "[ 0.] [[ 6.69781065]] [[ 1.08059025]]\n",
      "[ 1.] [[ 4.84545612]] [[ 2.9456687]]\n",
      "[ 0.] [[ 4.98041058]] [[ 2.73804975]]\n",
      "[ 0.] [[ 5.03099442]] [[ 2.65685749]]\n",
      "[ 0.] [[ 5.2060113]] [[ 2.56368065]]\n",
      "[ 0.] [[ 5.44848633]] [[ 2.48285294]]\n",
      "[ 0.] [[ 5.61256266]] [[ 2.33602309]]\n",
      "[ 0.] [[ 5.72341347]] [[ 2.24480534]]\n",
      "[ 0.] [[ 5.84709454]] [[ 2.09438992]]\n",
      "[ 0.] [[ 5.94530201]] [[ 2.00825357]]\n",
      "[ 0.] [[ 6.36846066]] [[ 1.41861153]]\n",
      "[ 0.] [[ 6.56845093]] [[ 1.24260998]]\n",
      "[ 0.] [[ 6.61336517]] [[ 1.18585289]]\n",
      "[ 0.] [[ 6.76134968]] [[ 1.05699432]]\n",
      "[ 1.] [[ 4.93832397]] [[ 2.92252851]]\n",
      "[ 0.] [[ 5.15807056]] [[ 2.79880619]]\n",
      "[ 0.] [[ 5.20133543]] [[ 2.5836904]]\n",
      "[ 0.] [[ 5.69365597]] [[ 2.16635847]]\n",
      "[ 0.] [[ 5.82406807]] [[ 2.110461]]\n",
      "[ 0.] [[ 5.87246466]] [[ 2.01669312]]\n",
      "[ 0.] [[ 5.79828072]] [[ 1.98517346]]\n",
      "[ 0.] [[ 5.84569836]] [[ 1.85424614]]\n",
      "[ 0.] [[ 6.07027626]] [[ 1.78115749]]\n",
      "[ 1.] [[ 4.66013718]] [[ 3.25179553]]\n",
      "[ 0.] [[ 4.94206476]] [[ 3.01794696]]\n",
      "[ 0.] [[ 5.03813934]] [[ 2.85924959]]\n",
      "[ 0.] [[ 5.2829051]] [[ 2.64733696]]\n",
      "[ 0.] [[ 5.17474556]] [[ 2.52523756]]\n",
      "[ 0.] [[ 5.5382247]] [[ 2.35053015]]\n",
      "[ 0.] [[ 5.68855858]] [[ 2.24305391]]\n",
      "[ 0.] [[ 5.75969696]] [[ 2.15268612]]\n",
      "[ 0.] [[ 5.91293621]] [[ 2.00625801]]\n",
      "[ 0.] [[ 6.0286026]] [[ 1.87123215]]\n",
      "[ 0.] [[ 6.10766697]] [[ 1.78424776]]\n",
      "[ 0.] [[ 6.20091581]] [[ 1.62252033]]\n",
      "[ 0.] [[ 6.30835056]] [[ 1.53891444]]\n",
      "[ 0.] [[ 6.39279556]] [[ 1.44067276]]\n",
      "[ 0.] [[ 6.48142815]] [[ 1.32976973]]\n",
      "[ 0.] [[ 6.53766584]] [[ 1.265571]]\n",
      "[ 0.] [[ 6.67011166]] [[ 1.1048317]]\n",
      "[ 1.] [[ 4.71934605]] [[ 3.01358891]]\n",
      "[ 0.] [[ 4.86537409]] [[ 2.88821411]]\n",
      "[ 0.] [[ 5.2056675]] [[ 2.67197084]]\n",
      "[ 0.] [[ 5.53164101]] [[ 2.39473367]]\n",
      "[ 0.] [[ 5.45409298]] [[ 2.28704691]]\n",
      "[ 0.] [[ 6.05499554]] [[ 1.71985364]]\n",
      "[ 1.] [[ 4.50906992]] [[ 3.30301714]]\n",
      "[ 0.] [[ 4.84129667]] [[ 3.08447981]]\n",
      "[ 0.] [[ 4.84559202]] [[ 2.90521693]]\n",
      "[ 0.] [[ 4.80221605]] [[ 2.81166315]]\n",
      "[ 0.] [[ 5.16092205]] [[ 2.6947403]]\n",
      "[ 0.] [[ 5.31541729]] [[ 2.6308825]]\n",
      "[ 0.] [[ 5.54935265]] [[ 2.40071344]]\n",
      "[ 0.] [[ 5.61597443]] [[ 2.30276012]]\n",
      "[ 0.] [[ 5.74968433]] [[ 2.14403677]]\n",
      "[ 0.] [[ 5.86246777]] [[ 2.07661057]]\n",
      "[ 0.] [[ 5.95957565]] [[ 1.98933744]]\n",
      "[ 0.] [[ 6.01927567]] [[ 1.86280608]]\n",
      "[ 1.] [[ 4.52607107]] [[ 3.4046452]]\n",
      "[ 0.] [[ 4.56067038]] [[ 3.13152599]]\n",
      "[ 0.] [[ 4.88148022]] [[ 2.96371698]]\n",
      "[ 0.] [[ 4.87395334]] [[ 2.87978768]]\n",
      "[ 0.] [[ 5.21553421]] [[ 2.69117856]]\n",
      "[ 0.] [[ 5.42376232]] [[ 2.52183294]]\n",
      "[ 0.] [[ 5.55352879]] [[ 2.41030908]]\n",
      "[ 0.] [[ 5.67033148]] [[ 2.29913664]]\n",
      "[ 0.] [[ 5.82244682]] [[ 2.11429596]]\n",
      "[ 0.] [[ 5.95584011]] [[ 1.97272503]]\n",
      "[ 0.] [[ 6.00042343]] [[ 1.8698647]]\n",
      "[ 1.] [[ 4.37103796]] [[ 3.3011446]]\n",
      "[ 0.] [[ 4.53778124]] [[ 3.1314373]]\n",
      "[ 0.] [[ 4.63629198]] [[ 2.99488688]]\n",
      "[ 0.] [[ 4.75022602]] [[ 2.8193171]]\n",
      "[ 0.] [[ 4.89126492]] [[ 2.75493717]]\n",
      "[ 0.] [[ 5.23423767]] [[ 2.6429472]]\n",
      "[ 0.] [[ 5.51737452]] [[ 2.4055171]]\n",
      "[ 0.] [[ 5.72485828]] [[ 2.18660021]]\n",
      "[ 0.] [[ 5.84329557]] [[ 2.09704542]]\n",
      "[ 0.] [[ 5.8885932]] [[ 2.00992942]]\n",
      "[ 0.] [[ 6.14898396]] [[ 1.63927186]]\n",
      "[ 0.] [[ 6.29539871]] [[ 1.5214057]]\n",
      "[ 0.] [[ 6.4226346]] [[ 1.42112327]]\n",
      "[ 0.] [[ 6.49330902]] [[ 1.30564928]]\n",
      "[ 0.] [[ 6.59362268]] [[ 1.24178386]]\n",
      "[ 0.] [[ 6.72038746]] [[ 1.10742176]]\n",
      "[ 0.] [[ 6.77541542]] [[ 1.02833509]]\n",
      "[ 0.] [[ 6.81879568]] [[ 1.01734042]]\n",
      "[ 0.] [[ 6.80984783]] [[ 0.99333191]]\n",
      "[ 0.] [[ 6.83670521]] [[ 1.00010276]]\n",
      "[ 0.] [[ 6.8111825]] [[ 1.0416261]]\n",
      "[ 0.] [[ 6.90262604]] [[ 0.96171284]]\n",
      "[ 0.] [[ 6.86165524]] [[ 0.97579789]]\n",
      "[ 0.] [[ 6.84328747]] [[ 0.98916233]]\n",
      "[ 0.] [[ 6.9306736]] [[ 0.9406932]]\n",
      "[ 1.] [[ 5.0463419]] [[ 2.87834716]]\n",
      "[ 0.] [[ 5.83094978]] [[ 1.95470583]]\n",
      "[ 0.] [[ 5.98975992]] [[ 1.77497101]]\n",
      "[ 0.] [[ 6.15393209]] [[ 1.60125148]]\n",
      "[ 0.] [[ 6.34290695]] [[ 1.45297456]]\n",
      "[ 0.] [[ 6.46511841]] [[ 1.34696841]]\n",
      "[ 0.] [[ 6.89273167]] [[ 0.95362091]]\n",
      "[ 0.] [[ 7.05006599]] [[ 0.90373898]]\n",
      "[ 1.] [[ 5.06246376]] [[ 2.87360859]]\n",
      "[ 0.] [[ 5.23190689]] [[ 2.74160647]]\n",
      "[ 0.] [[ 5.35824966]] [[ 2.61642241]]\n",
      "[ 0.] [[ 5.58577633]] [[ 2.30747938]]\n",
      "[ 0.] [[ 5.73140621]] [[ 2.22349334]]\n",
      "[ 0.] [[ 5.79693127]] [[ 2.13702488]]\n",
      "[ 0.] [[ 5.90320826]] [[ 2.05219889]]\n",
      "[ 0.] [[ 5.9926815]] [[ 1.92941689]]\n",
      "[ 0.] [[ 6.1021843]] [[ 1.8125093]]\n",
      "[ 1.] [[ 4.30441475]] [[ 3.35634375]]\n",
      "[ 0.] [[ 4.76919937]] [[ 3.13425589]]\n",
      "[ 0.] [[ 5.01122379]] [[ 2.95406437]]\n",
      "[ 0.] [[ 5.49827862]] [[ 2.33027935]]\n",
      "[ 0.] [[ 5.59804106]] [[ 2.23041558]]\n",
      "[ 0.] [[ 5.8078413]] [[ 2.10089159]]\n",
      "[ 0.] [[ 6.05488777]] [[ 1.83655715]]\n",
      "[ 0.] [[ 6.17407894]] [[ 1.72350812]]\n",
      "[ 0.] [[ 6.2686348]] [[ 1.61704659]]\n",
      "[ 0.] [[ 6.43350315]] [[ 1.39451528]]\n",
      "[ 0.] [[ 6.67401409]] [[ 1.12824488]]\n",
      "[ 0.] [[ 6.8140192]] [[ 1.0102731]]\n",
      "[ 0.] [[ 6.89669991]] [[ 0.95254904]]\n",
      "[ 0.] [[ 6.88957787]] [[ 0.96978933]]\n",
      "[ 1.] [[ 5.0073204]] [[ 2.86361313]]\n",
      "[ 0.] [[ 5.22087383]] [[ 2.7360487]]\n",
      "[ 0.] [[ 5.3474493]] [[ 2.6077137]]\n",
      "[ 0.] [[ 5.49932861]] [[ 2.47615099]]\n",
      "[ 0.] [[ 5.66027308]] [[ 2.28258085]]\n",
      "[ 0.] [[ 5.79031563]] [[ 2.14938164]]\n",
      "[ 0.] [[ 5.93494892]] [[ 2.00238776]]\n",
      "[ 0.] [[ 6.02179146]] [[ 1.90658569]]\n",
      "[ 0.] [[ 5.9725523]] [[ 1.79409361]]\n",
      "[ 0.] [[ 6.2039156]] [[ 1.57668078]]\n",
      "[ 1.] [[ 4.42351389]] [[ 3.20584345]]\n",
      "[ 0.] [[ 5.12111473]] [[ 2.72559118]]\n",
      "[ 0.] [[ 5.41159153]] [[ 2.52208781]]\n",
      "[ 0.] [[ 5.51978397]] [[ 2.41526628]]\n",
      "[ 0.] [[ 5.56613827]] [[ 2.31699324]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [[ 5.65672493]] [[ 2.14072561]]\n",
      "[ 0.] [[ 5.77373028]] [[ 2.05639315]]\n",
      "[ 0.] [[ 5.94562101]] [[ 1.96249652]]\n",
      "[ 0.] [[ 6.05491352]] [[ 1.86979127]]\n",
      "[ 0.] [[ 6.0832634]] [[ 1.78198218]]\n",
      "[ 0.] [[ 6.10391235]] [[ 1.76205492]]\n",
      "[ 0.] [[ 6.21516085]] [[ 1.6413033]]\n",
      "[ 0.] [[ 6.32113266]] [[ 1.50893247]]\n",
      "[ 0.] [[ 6.33679676]] [[ 1.47374594]]\n",
      "[ 0.] [[ 6.4398303]] [[ 1.38118255]]\n",
      "[ 0.] [[ 6.52571201]] [[ 1.2399224]]\n",
      "[ 0.] [[ 6.64520741]] [[ 1.17178833]]\n",
      "[ 0.] [[ 6.76612186]] [[ 1.06188941]]\n",
      "[ 0.] [[ 7.09615612]] [[ 0.87927359]]\n",
      "[ 1.] [[ 5.04103374]] [[ 2.80028629]]\n",
      "[ 0.] [[ 5.03981972]] [[ 2.70772743]]\n",
      "[ 0.] [[ 5.22925282]] [[ 2.60822392]]\n",
      "[ 0.] [[ 5.49354458]] [[ 2.41414523]]\n",
      "[ 0.] [[ 5.54770947]] [[ 2.22881317]]\n",
      "[ 0.] [[ 5.80226994]] [[ 2.0928812]]\n",
      "[ 0.] [[ 5.8113451]] [[ 2.0258522]]\n",
      "[ 0.] [[ 5.86913157]] [[ 1.93233061]]\n",
      "[ 0.] [[ 6.02753067]] [[ 1.83110499]]\n",
      "[ 0.] [[ 6.13169813]] [[ 1.74606931]]\n",
      "[ 0.] [[ 6.23769474]] [[ 1.65115607]]\n",
      "[ 0.] [[ 6.1866703]] [[ 1.60289645]]\n",
      "[ 0.] [[ 6.33656979]] [[ 1.42148781]]\n",
      "[ 1.] [[ 4.7005434]] [[ 3.16859055]]\n",
      "[ 0.] [[ 4.69624901]] [[ 3.00368595]]\n",
      "[ 0.] [[ 5.06928873]] [[ 2.83552074]]\n",
      "[ 0.] [[ 5.21106625]] [[ 2.74642491]]\n",
      "[ 0.] [[ 5.3604784]] [[ 2.60393476]]\n",
      "[ 0.] [[ 5.41019917]] [[ 2.50609255]]\n",
      "[ 0.] [[ 5.52914524]] [[ 2.41953802]]\n",
      "[ 0.] [[ 5.63851452]] [[ 2.33608675]]\n",
      "[ 0.] [[ 5.7117424]] [[ 2.26470113]]\n",
      "[ 0.] [[ 5.9675684]] [[ 1.93092382]]\n",
      "[ 0.] [[ 6.07246399]] [[ 1.81296897]]\n",
      "[ 0.] [[ 6.17229605]] [[ 1.72371686]]\n",
      "[ 0.] [[ 6.26175976]] [[ 1.60354686]]\n",
      "[ 0.] [[ 6.86420631]] [[ 0.95161992]]\n",
      "[ 1.] [[ 4.99246788]] [[ 2.84420919]]\n",
      "[ 0.] [[ 4.95748043]] [[ 2.67496133]]\n",
      "[ 0.] [[ 5.27728558]] [[ 2.51967359]]\n",
      "[ 0.] [[ 5.21709728]] [[ 2.46376705]]\n",
      "[ 0.] [[ 5.34574223]] [[ 2.41184092]]\n",
      "[ 0.] [[ 5.53196716]] [[ 2.34013534]]\n",
      "[ 0.] [[ 5.56321049]] [[ 2.21490884]]\n",
      "[ 0.] [[ 5.75142288]] [[ 2.15812993]]\n",
      "[ 0.] [[ 6.02773905]] [[ 1.78892982]]\n",
      "[ 0.] [[ 6.29117584]] [[ 1.51696026]]\n",
      "[ 1.] [[ 4.6470747]] [[ 3.22364593]]\n",
      "[ 0.] [[ 4.77800751]] [[ 2.97663045]]\n",
      "[ 0.] [[ 5.1927824]] [[ 2.71028733]]\n",
      "[ 0.] [[ 5.37233162]] [[ 2.59325838]]\n",
      "[ 0.] [[ 5.32982349]] [[ 2.43638587]]\n",
      "[ 0.] [[ 5.56214094]] [[ 2.35816622]]\n",
      "[ 0.] [[ 5.69544935]] [[ 2.25873041]]\n",
      "[ 0.] [[ 5.7013731]] [[ 2.18104625]]\n",
      "[ 0.] [[ 5.80040264]] [[ 2.09604025]]\n",
      "[ 0.] [[ 5.82247162]] [[ 2.0280385]]\n",
      "[ 0.] [[ 5.96005249]] [[ 1.92578423]]\n",
      "[ 0.] [[ 6.05877447]] [[ 1.84799254]]\n",
      "[ 0.] [[ 6.15427732]] [[ 1.74727464]]\n",
      "[ 0.] [[ 6.31774473]] [[ 1.54590988]]\n",
      "[ 0.] [[ 6.60871601]] [[ 1.1476903]]\n",
      "[ 0.] [[ 6.67446232]] [[ 1.08688819]]\n",
      "[ 0.] [[ 6.78306293]] [[ 0.97439408]]\n",
      "[ 0.] [[ 6.83861113]] [[ 0.98544061]]\n",
      "[ 0.] [[ 6.82432556]] [[ 0.98725367]]\n",
      "[ 0.] [[ 6.81330919]] [[ 1.03411329]]\n",
      "[ 0.] [[ 6.81212521]] [[ 1.00619018]]\n",
      "[ 0.] [[ 6.84568214]] [[ 1.00716949]]\n",
      "[ 0.] [[ 6.8645525]] [[ 0.98757625]]\n",
      "[ 0.] [[ 6.85735798]] [[ 0.9789387]]\n",
      "[ 0.] [[ 6.8215456]] [[ 0.99797654]]\n",
      "[ 0.] [[ 6.84355736]] [[ 0.99274004]]\n",
      "[ 0.] [[ 6.8231163]] [[ 0.9960289]]\n",
      "[ 0.] [[ 6.85303497]] [[ 0.9838326]]\n",
      "[ 0.] [[ 6.85701561]] [[ 0.98839748]]\n",
      "[ 0.] [[ 6.8816433]] [[ 0.97470665]]\n",
      "[ 0.] [[ 6.94218063]] [[ 0.94508189]]\n",
      "[ 1.] [[ 4.74997807]] [[ 2.89660835]]\n",
      "[ 0.] [[ 4.93217087]] [[ 2.79416227]]\n",
      "[ 0.] [[ 5.22678852]] [[ 2.69373488]]\n",
      "[ 0.] [[ 5.30556488]] [[ 2.55104876]]\n",
      "[ 0.] [[ 5.51631355]] [[ 2.39983869]]\n",
      "[ 0.] [[ 5.56667709]] [[ 2.21408844]]\n",
      "[ 0.] [[ 5.86675406]] [[ 2.01376796]]\n",
      "[ 0.] [[ 5.99833488]] [[ 1.90250611]]\n",
      "[ 0.] [[ 6.09104633]] [[ 1.82888126]]\n",
      "[ 0.] [[ 6.34733868]] [[ 1.48718762]]\n",
      "[ 0.] [[ 6.45679283]] [[ 1.38485456]]\n",
      "[ 0.] [[ 6.57635212]] [[ 1.19693053]]\n",
      "[ 0.] [[ 6.71911144]] [[ 1.06401968]]\n",
      "[ 0.] [[ 6.77933264]] [[ 1.00202429]]\n",
      "[ 0.] [[ 6.84735489]] [[ 0.96874684]]\n",
      "[ 0.] [[ 7.15869141]] [[ 0.86631149]]\n",
      "[ 1.] [[ 5.0568018]] [[ 2.85630703]]\n",
      "[ 0.] [[ 5.05672169]] [[ 2.68585491]]\n",
      "[ 0.] [[ 5.37677193]] [[ 2.52386045]]\n",
      "[ 0.] [[ 5.54042912]] [[ 2.35173655]]\n",
      "[ 0.] [[ 5.75349569]] [[ 2.16550708]]\n",
      "[ 0.] [[ 5.86491203]] [[ 2.08813]]\n",
      "[ 0.] [[ 5.97035217]] [[ 1.97346091]]\n",
      "[ 0.] [[ 6.12190723]] [[ 1.7803154]]\n",
      "[ 0.] [[ 6.32621479]] [[ 1.5016737]]\n",
      "[ 0.] [[ 6.31143093]] [[ 1.45690262]]\n",
      "[ 0.] [[ 6.56109905]] [[ 1.13473535]]\n",
      "[ 0.] [[ 7.15794086]] [[ 0.84773272]]\n",
      "[ 1.] [[ 4.8968606]] [[ 2.79195595]]\n",
      "[ 0.] [[ 5.05037785]] [[ 2.7050631]]\n",
      "[ 0.] [[ 5.11992073]] [[ 2.62690711]]\n",
      "[ 0.] [[ 5.3993597]] [[ 2.51382828]]\n",
      "[ 0.] [[ 5.58932257]] [[ 2.35389853]]\n",
      "[ 0.] [[ 5.82621861]] [[ 2.0541389]]\n",
      "[ 0.] [[ 5.78781509]] [[ 1.95449471]]\n",
      "[ 0.] [[ 6.02810669]] [[ 1.79790568]]\n",
      "[ 0.] [[ 6.04608536]] [[ 1.77328849]]\n",
      "[ 0.] [[ 6.17700529]] [[ 1.6794405]]\n",
      "[ 0.] [[ 6.28916502]] [[ 1.51747477]]\n",
      "[ 0.] [[ 6.44609737]] [[ 1.37314308]]\n",
      "[ 0.] [[ 6.59619379]] [[ 1.19688737]]\n",
      "[ 0.] [[ 6.75102329]] [[ 1.0645709]]\n",
      "[ 0.] [[ 6.77416039]] [[ 1.01115501]]\n",
      "[ 0.] [[ 6.82581139]] [[ 1.00738871]]\n",
      "[ 0.] [[ 6.85457993]] [[ 1.00228202]]\n",
      "[ 0.] [[ 6.89460564]] [[ 0.9623735]]\n",
      "[ 0.] [[ 6.88454723]] [[ 0.95477009]]\n",
      "[ 0.] [[ 6.8829546]] [[ 0.92243099]]\n",
      "[ 0.] [[ 6.83699799]] [[ 0.97221124]]\n",
      "[ 0.] [[ 6.8550148]] [[ 0.97565687]]\n",
      "[ 0.] [[ 6.8518405]] [[ 0.98685443]]\n",
      "[ 0.] [[ 6.82853889]] [[ 0.97405469]]\n",
      "[ 0.] [[ 6.83013535]] [[ 0.96956706]]\n",
      "[ 0.] [[ 6.87746096]] [[ 0.97962558]]\n",
      "[ 0.] [[ 6.89328384]] [[ 0.97609693]]\n",
      "[ 0.] [[ 6.88555717]] [[ 0.98605931]]\n",
      "[ 0.] [[ 6.88420391]] [[ 0.98474765]]\n",
      "[ 0.] [[ 6.88978004]] [[ 0.9811511]]\n",
      "[ 0.] [[ 6.81516361]] [[ 0.9909972]]\n",
      "[ 0.] [[ 6.86095142]] [[ 0.98236209]]\n",
      "[ 0.] [[ 6.89017582]] [[ 0.97328138]]\n",
      "[ 1.] [[ 5.00693464]] [[ 2.86485815]]\n",
      "[ 0.] [[ 5.22531796]] [[ 2.73016787]]\n",
      "[ 0.] [[ 5.16361284]] [[ 2.63277459]]\n",
      "[ 0.] [[ 5.53544712]] [[ 2.36984038]]\n",
      "[ 0.] [[ 5.61938095]] [[ 2.33215499]]\n",
      "[ 0.] [[ 6.06972885]] [[ 1.73921323]]\n",
      "[ 0.] [[ 6.20881319]] [[ 1.56010413]]\n",
      "[ 1.] [[ 4.41944218]] [[ 3.37081218]]\n",
      "[ 0.] [[ 4.43112135]] [[ 3.11415815]]\n",
      "[ 0.] [[ 4.8543725]] [[ 2.98303604]]\n",
      "[ 0.] [[ 4.76922321]] [[ 2.89066458]]\n",
      "[ 0.] [[ 5.14899921]] [[ 2.74551773]]\n",
      "[ 0.] [[ 5.25581121]] [[ 2.62625241]]\n",
      "[ 0.] [[ 5.48531914]] [[ 2.46221662]]\n",
      "[ 0.] [[ 5.45342159]] [[ 2.3833046]]\n",
      "[ 0.] [[ 6.00468826]] [[ 1.80661213]]\n",
      "[ 0.] [[ 6.23200035]] [[ 1.61275887]]\n",
      "[ 0.] [[ 6.34440708]] [[ 1.4516176]]\n",
      "[ 1.] [[ 4.53938961]] [[ 3.21078539]]\n",
      "[ 0.] [[ 4.88920593]] [[ 3.01027226]]\n",
      "[ 0.] [[ 5.14415598]] [[ 2.76849222]]\n",
      "[ 0.] [[ 5.34250116]] [[ 2.62282228]]\n",
      "[ 0.] [[ 5.46584702]] [[ 2.51004744]]\n",
      "[ 0.] [[ 5.57093811]] [[ 2.33823442]]\n",
      "[ 0.] [[ 5.72888088]] [[ 2.22436261]]\n",
      "[ 0.] [[ 5.83875942]] [[ 2.12492704]]\n",
      "[ 0.] [[ 5.99494171]] [[ 1.93024063]]\n",
      "[ 0.] [[ 6.04798508]] [[ 1.83926034]]\n",
      "[ 0.] [[ 6.15970707]] [[ 1.74277973]]\n",
      "[ 0.] [[ 6.35855198]] [[ 1.46342897]]\n",
      "[ 0.] [[ 6.48352718]] [[ 1.35332298]]\n",
      "[ 0.] [[ 6.60693073]] [[ 1.21834743]]\n",
      "[ 0.] [[ 6.67538643]] [[ 1.10765159]]\n",
      "[ 1.] [[ 4.74349737]] [[ 2.96894264]]\n",
      "[ 0.] [[ 4.81778049]] [[ 2.86653733]]\n",
      "[ 0.] [[ 5.01801586]] [[ 2.7519381]]\n",
      "[ 0.] [[ 5.28085279]] [[ 2.63943553]]\n",
      "[ 0.] [[ 5.61720753]] [[ 2.26645708]]\n",
      "[ 0.] [[ 5.77285337]] [[ 2.16799307]]\n",
      "[ 0.] [[ 5.90758848]] [[ 2.02725291]]\n",
      "[ 0.] [[ 5.97941637]] [[ 1.94127429]]\n",
      "[ 0.] [[ 6.00422525]] [[ 1.90820646]]\n",
      "[ 0.] [[ 6.09982109]] [[ 1.80906558]]\n",
      "[ 0.] [[ 6.19703865]] [[ 1.66811371]]\n",
      "[ 0.] [[ 6.24693584]] [[ 1.55651903]]\n",
      "[ 0.] [[ 6.36365414]] [[ 1.4674716]]\n",
      "[ 0.] [[ 6.47377491]] [[ 1.34108901]]\n",
      "[ 0.] [[ 6.56614256]] [[ 1.26514232]]\n",
      "[ 0.] [[ 6.63311195]] [[ 1.20166767]]\n",
      "[ 0.] [[ 6.7651186]] [[ 1.06077909]]\n",
      "[ 0.] [[ 6.75030231]] [[ 1.07786036]]\n",
      "[ 0.] [[ 6.75790215]] [[ 1.02955544]]\n",
      "[ 0.] [[ 6.8225522]] [[ 1.00525904]]\n",
      "[ 0.] [[ 6.79327774]] [[ 1.01169825]]\n",
      "[ 0.] [[ 6.80679131]] [[ 1.01398921]]\n",
      "[ 0.] [[ 6.90156364]] [[ 0.95982194]]\n",
      "[ 0.] [[ 7.03756046]] [[ 0.91139907]]\n",
      "[ 0.] [[ 6.88365078]] [[ 0.96522295]]\n",
      "[ 0.] [[ 6.90054512]] [[ 0.97243261]]\n",
      "[ 0.] [[ 6.86149883]] [[ 0.96837467]]\n",
      "[ 0.] [[ 7.03492069]] [[ 0.9058364]]\n",
      "[ 1.] [[ 4.84047127]] [[ 2.83151317]]\n",
      "[ 0.] [[ 5.20965862]] [[ 2.66356373]]\n",
      "[ 0.] [[ 5.40764666]] [[ 2.53437543]]\n",
      "[ 0.] [[ 5.51266623]] [[ 2.44307518]]\n",
      "[ 0.] [[ 5.54108238]] [[ 2.25111127]]\n",
      "[ 0.] [[ 5.83285427]] [[ 2.03490758]]\n",
      "[ 0.] [[ 5.93658447]] [[ 1.95838726]]\n",
      "[ 0.] [[ 6.13868904]] [[ 1.73938918]]\n",
      "[ 0.] [[ 6.23421049]] [[ 1.64853978]]\n",
      "[ 0.] [[ 6.22269678]] [[ 1.53094244]]\n",
      "[ 0.] [[ 6.36203289]] [[ 1.45877075]]\n",
      "[ 0.] [[ 6.95865917]] [[ 0.91344774]]\n",
      "[ 1.] [[ 5.01202202]] [[ 2.85178351]]\n",
      "[ 0.] [[ 5.03765249]] [[ 2.68722916]]\n",
      "[ 0.] [[ 5.41287422]] [[ 2.46845722]]\n",
      "[ 0.] [[ 5.6340971]] [[ 2.29364491]]\n",
      "[ 0.] [[ 5.65518427]] [[ 2.21203423]]\n",
      "[ 0.] [[ 5.75808096]] [[ 2.02391386]]\n",
      "[ 0.] [[ 6.08023453]] [[ 1.7664144]]\n",
      "[ 0.] [[ 6.19763374]] [[ 1.64685881]]\n",
      "[ 0.] [[ 6.36446857]] [[ 1.4692266]]\n",
      "[ 0.] [[ 6.49062729]] [[ 1.28496468]]\n",
      "[ 0.] [[ 6.5708065]] [[ 1.2230835]]\n",
      "[ 0.] [[ 6.97976017]] [[ 0.91749775]]\n",
      "[ 1.] [[ 4.7842474]] [[ 2.91991878]]\n",
      "[ 0.] [[ 5.06561518]] [[ 2.78951502]]\n",
      "[ 0.] [[ 5.00428295]] [[ 2.65847111]]\n",
      "[ 0.] [[ 5.33784962]] [[ 2.56376076]]\n",
      "[ 0.] [[ 5.49278927]] [[ 2.46435642]]\n",
      "[ 0.] [[ 5.85750294]] [[ 2.03465748]]\n",
      "[ 0.] [[ 5.90220165]] [[ 1.96205783]]\n",
      "[ 0.] [[ 6.00783062]] [[ 1.7887814]]\n",
      "[ 0.] [[ 6.17662477]] [[ 1.69221294]]\n",
      "[ 0.] [[ 6.27598333]] [[ 1.56988287]]\n",
      "[ 0.] [[ 6.45639324]] [[ 1.37618279]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [[ 6.45013142]] [[ 1.31161785]]\n",
      "[ 0.] [[ 6.57163715]] [[ 1.24117863]]\n",
      "[ 0.] [[ 6.6951685]] [[ 1.12370884]]\n",
      "[ 0.] [[ 6.7591691]] [[ 1.08386958]]\n",
      "[ 0.] [[ 6.8062644]] [[ 1.04473341]]\n",
      "[ 0.] [[ 6.81722307]] [[ 1.02052534]]\n",
      "[ 0.] [[ 6.8811264]] [[ 0.96792096]]\n",
      "[ 0.] [[ 6.85456944]] [[ 0.96955621]]\n",
      "[ 0.] [[ 6.9034462]] [[ 0.96204841]]\n",
      "[ 1.] [[ 5.0147562]] [[ 2.85768008]]\n",
      "[ 0.] [[ 5.833395]] [[ 1.93188429]]\n",
      "[ 0.] [[ 5.98690081]] [[ 1.86732388]]\n",
      "[ 0.] [[ 6.05602455]] [[ 1.78560257]]\n",
      "[ 0.] [[ 6.18775272]] [[ 1.66310823]]\n",
      "[ 0.] [[ 6.27445602]] [[ 1.58031452]]\n",
      "[ 0.] [[ 6.35248947]] [[ 1.50030339]]\n",
      "[ 0.] [[ 6.44235611]] [[ 1.40788591]]\n",
      "[ 0.] [[ 6.51302958]] [[ 1.26121545]]\n",
      "[ 1.] [[ 4.91182613]] [[ 2.95896864]]\n",
      "[ 0.] [[ 5.40677643]] [[ 2.49235678]]\n",
      "[ 0.] [[ 5.65656567]] [[ 2.27643108]]\n",
      "[ 0.] [[ 5.7120676]] [[ 2.24078846]]\n",
      "[ 0.] [[ 5.77101326]] [[ 2.14798403]]\n",
      "[ 0.] [[ 5.89457035]] [[ 2.04208612]]\n",
      "[ 0.] [[ 5.96271992]] [[ 1.88611174]]\n",
      "[ 0.] [[ 6.00263834]] [[ 1.81709051]]\n",
      "[ 0.] [[ 6.14657307]] [[ 1.73311985]]\n",
      "[ 0.] [[ 6.31052589]] [[ 1.53610563]]\n",
      "[ 0.] [[ 6.41865158]] [[ 1.43102062]]\n",
      "[ 0.] [[ 6.52740908]] [[ 1.22688186]]\n",
      "[ 0.] [[ 6.61903]] [[ 1.17293513]]\n",
      "[ 0.] [[ 6.64739704]] [[ 1.17632926]]\n",
      "[ 0.] [[ 6.71008825]] [[ 1.13249981]]\n",
      "[ 0.] [[ 6.80092239]] [[ 1.01472974]]\n",
      "[ 0.] [[ 6.8813715]] [[ 0.96053612]]\n",
      "[ 0.] [[ 6.95733833]] [[ 0.91315073]]\n",
      "[ 1.] [[ 5.00447941]] [[ 2.88558722]]\n",
      "[ 0.] [[ 5.24099255]] [[ 2.70455956]]\n",
      "[ 0.] [[ 5.26679325]] [[ 2.49623299]]\n",
      "[ 0.] [[ 5.41076565]] [[ 2.41039109]]\n",
      "[ 0.] [[ 5.62109184]] [[ 2.31732202]]\n",
      "[ 0.] [[ 5.69382572]] [[ 2.22245026]]\n",
      "[ 0.] [[ 5.70236635]] [[ 2.15209484]]\n",
      "[ 0.] [[ 5.87116146]] [[ 1.99910975]]\n",
      "[ 0.] [[ 5.97351742]] [[ 1.91984332]]\n",
      "[ 0.] [[ 6.01283264]] [[ 1.784127]]\n",
      "[ 0.] [[ 6.2388525]] [[ 1.55365384]]\n",
      "[ 1.] [[ 4.44185209]] [[ 3.26490474]]\n",
      "[ 0.] [[ 4.87370014]] [[ 2.98369217]]\n",
      "[ 0.] [[ 5.2649765]] [[ 2.61331415]]\n",
      "[ 0.] [[ 5.77517128]] [[ 2.02747393]]\n",
      "[ 0.] [[ 5.93978024]] [[ 1.95126677]]\n",
      "[ 0.] [[ 6.07273006]] [[ 1.83641469]]\n",
      "[ 0.] [[ 6.21239901]] [[ 1.67840648]]\n",
      "[ 0.] [[ 6.16833544]] [[ 1.60716927]]\n",
      "[ 0.] [[ 6.32886457]] [[ 1.5022856]]\n",
      "[ 0.] [[ 6.44817543]] [[ 1.35329282]]\n",
      "[ 0.] [[ 6.53154373]] [[ 1.27144361]]\n",
      "[ 0.] [[ 6.62005091]] [[ 1.20543575]]\n",
      "[ 0.] [[ 6.62127686]] [[ 1.19208074]]\n",
      "[ 0.] [[ 6.75484371]] [[ 1.07105398]]\n",
      "[ 0.] [[ 6.84967518]] [[ 0.97363651]]\n",
      "[ 1.] [[ 4.71279144]] [[ 2.91515112]]\n",
      "[ 0.] [[ 4.83770275]] [[ 2.7596097]]\n",
      "[ 0.] [[ 5.24792671]] [[ 2.58201146]]\n",
      "[ 0.] [[ 5.46593857]] [[ 2.46230745]]\n",
      "[ 0.] [[ 5.63107061]] [[ 2.31588054]]\n",
      "[ 0.] [[ 5.75074959]] [[ 2.19947863]]\n",
      "[ 0.] [[ 6.20681572]] [[ 1.61327696]]\n",
      "[ 1.] [[ 4.38813496]] [[ 3.3355794]]\n",
      "[ 0.] [[ 4.60459137]] [[ 3.11611938]]\n",
      "[ 0.] [[ 5.00167942]] [[ 2.86405492]]\n",
      "[ 0.] [[ 4.89760017]] [[ 2.78645277]]\n",
      "[ 0.] [[ 5.20947027]] [[ 2.68461752]]\n",
      "[ 0.] [[ 5.24655485]] [[ 2.58761525]]\n",
      "[ 0.] [[ 5.63395166]] [[ 2.22412491]]\n",
      "[ 0.] [[ 5.77812099]] [[ 2.13568711]]\n",
      "[ 0.] [[ 5.95824957]] [[ 1.94974566]]\n",
      "[ 0.] [[ 6.02194452]] [[ 1.86075377]]\n",
      "[ 0.] [[ 6.12833881]] [[ 1.74116611]]\n",
      "[ 0.] [[ 6.24330139]] [[ 1.64236343]]\n",
      "[ 0.] [[ 6.29097271]] [[ 1.5731324]]\n",
      "[ 0.] [[ 6.37548399]] [[ 1.44919133]]\n",
      "[ 0.] [[ 6.4722023]] [[ 1.37439895]]\n",
      "[ 0.] [[ 6.51312733]] [[ 1.2317512]]\n",
      "[ 0.] [[ 6.63277292]] [[ 1.15779567]]\n",
      "[ 0.] [[ 6.77472353]] [[ 1.04819882]]\n",
      "[ 0.] [[ 6.78413391]] [[ 1.03700578]]\n",
      "[ 0.] [[ 6.82791138]] [[ 0.97991019]]\n",
      "[ 0.] [[ 6.84164906]] [[ 0.97502863]]\n",
      "[ 0.] [[ 6.84371567]] [[ 0.97096384]]\n",
      "[ 0.] [[ 7.01621628]] [[ 0.91226345]]\n",
      "[ 1.] [[ 4.79741287]] [[ 2.91525888]]\n",
      "[ 0.] [[ 5.0936451]] [[ 2.78664732]]\n",
      "[ 0.] [[ 5.34761238]] [[ 2.57057762]]\n",
      "[ 0.] [[ 5.57477188]] [[ 2.37463117]]\n",
      "[ 0.] [[ 5.68105888]] [[ 2.28861618]]\n",
      "[ 0.] [[ 5.78761244]] [[ 2.16505361]]\n",
      "[ 0.] [[ 5.82582664]] [[ 2.07760072]]\n",
      "[ 0.] [[ 5.86483288]] [[ 1.99871719]]\n",
      "[ 0.] [[ 5.99027967]] [[ 1.89387321]]\n",
      "[ 0.] [[ 6.10617828]] [[ 1.80791259]]\n",
      "[ 0.] [[ 6.19451952]] [[ 1.70512104]]\n",
      "[ 0.] [[ 6.2733469]] [[ 1.60989952]]\n",
      "[ 0.] [[ 6.23669243]] [[ 1.53621376]]\n",
      "[ 0.] [[ 6.4545269]] [[ 1.35415971]]\n",
      "[ 0.] [[ 6.52673054]] [[ 1.28823638]]\n",
      "[ 0.] [[ 6.55256271]] [[ 1.19595504]]\n",
      "[ 0.] [[ 6.70436716]] [[ 1.06323206]]\n",
      "[ 0.] [[ 6.75337887]] [[ 1.02516866]]\n",
      "[ 0.] [[ 6.81823826]] [[ 1.02186847]]\n",
      "[ 0.] [[ 6.82773399]] [[ 1.00029969]]\n",
      "[ 0.] [[ 6.84402752]] [[ 1.00613606]]\n",
      "[ 0.] [[ 6.84861851]] [[ 0.94157845]]\n",
      "[ 1.] [[ 4.76758766]] [[ 2.861058]]\n",
      "[ 0.] [[ 4.98512125]] [[ 2.74959373]]\n",
      "[ 0.] [[ 5.30858946]] [[ 2.55680704]]\n",
      "[ 0.] [[ 5.58553219]] [[ 2.34113979]]\n",
      "[ 0.] [[ 5.82950878]] [[ 2.04659605]]\n",
      "[ 0.] [[ 5.8311882]] [[ 1.98864949]]\n",
      "[ 0.] [[ 5.86122894]] [[ 1.92323852]]\n",
      "[ 0.] [[ 5.84758377]] [[ 1.90000391]]\n",
      "[ 0.] [[ 6.02574301]] [[ 1.72572994]]\n",
      "[ 1.] [[ 4.43582773]] [[ 3.3877306]]\n",
      "[ 0.] [[ 4.72760201]] [[ 3.15068412]]\n",
      "[ 0.] [[ 5.35169315]] [[ 2.51366854]]\n",
      "[ 0.] [[ 5.707304]] [[ 2.15135121]]\n",
      "[ 0.] [[ 5.86324978]] [[ 2.06737375]]\n",
      "[ 0.] [[ 5.94660568]] [[ 1.98225307]]\n",
      "[ 0.] [[ 6.04224396]] [[ 1.89334726]]\n",
      "[ 0.] [[ 6.03329277]] [[ 1.81635022]]\n",
      "[ 0.] [[ 6.06333542]] [[ 1.79943061]]\n",
      "[ 0.] [[ 6.12549877]] [[ 1.7205919]]\n",
      "[ 1.] [[ 4.39008617]] [[ 3.30684805]]\n",
      "[ 0.] [[ 4.82871437]] [[ 3.04735398]]\n",
      "[ 0.] [[ 5.04017162]] [[ 2.81586075]]\n",
      "[ 0.] [[ 5.12740278]] [[ 2.67604828]]\n",
      "[ 0.] [[ 5.33795452]] [[ 2.50938559]]\n",
      "[ 0.] [[ 5.6669426]] [[ 2.24141073]]\n",
      "[ 0.] [[ 5.81542683]] [[ 2.11152577]]\n",
      "[ 0.] [[ 5.76039505]] [[ 2.00598884]]\n",
      "[ 0.] [[ 5.9700985]] [[ 1.9114331]]\n",
      "[ 0.] [[ 6.08099842]] [[ 1.83323169]]\n",
      "[ 0.] [[ 6.15907907]] [[ 1.70288467]]\n",
      "[ 0.] [[ 6.30224323]] [[ 1.55324101]]\n",
      "[ 0.] [[ 6.6004076]] [[ 1.15416932]]\n",
      "[ 0.] [[ 6.68200874]] [[ 1.09048557]]\n",
      "[ 0.] [[ 6.75617981]] [[ 1.02018416]]\n",
      "[ 0.] [[ 6.82606983]] [[ 1.0130806]]\n",
      "[ 0.] [[ 6.83524466]] [[ 1.00702095]]\n",
      "[ 0.] [[ 6.84115696]] [[ 0.98519659]]\n",
      "[ 1.] [[ 5.09676743]] [[ 2.78869057]]\n",
      "[ 0.] [[ 5.2966423]] [[ 2.66289306]]\n",
      "[ 0.] [[ 5.46880531]] [[ 2.49190831]]\n",
      "[ 0.] [[ 5.6003809]] [[ 2.35766292]]\n",
      "[ 0.] [[ 5.65230703]] [[ 2.15647507]]\n",
      "[ 0.] [[ 5.8541441]] [[ 2.05887794]]\n",
      "[ 0.] [[ 6.02925301]] [[ 1.88315082]]\n",
      "[ 0.] [[ 6.29981136]] [[ 1.53425932]]\n",
      "[ 0.] [[ 6.39297771]] [[ 1.4361757]]\n",
      "[ 0.] [[ 6.47199821]] [[ 1.35066772]]\n",
      "[ 0.] [[ 7.03980732]] [[ 0.88636136]]\n",
      "[ 1.] [[ 4.91169262]] [[ 2.883286]]\n",
      "[ 0.] [[ 5.1685977]] [[ 2.77240896]]\n",
      "[ 0.] [[ 5.3215456]] [[ 2.57356596]]\n",
      "[ 0.] [[ 5.81851625]] [[ 1.98895621]]\n",
      "[ 0.] [[ 5.9969182]] [[ 1.89980173]]\n",
      "[ 1.] [[ 4.53785229]] [[ 3.42909622]]\n",
      "[ 0.] [[ 4.57936859]] [[ 3.19852757]]\n",
      "[ 0.] [[ 4.74487114]] [[ 2.94657445]]\n",
      "[ 0.] [[ 5.19648314]] [[ 2.69087315]]\n",
      "[ 0.] [[ 5.2949152]] [[ 2.59253216]]\n",
      "[ 0.] [[ 5.25408268]] [[ 2.55082178]]\n",
      "[ 0.] [[ 5.38439083]] [[ 2.40287542]]\n",
      "[ 0.] [[ 5.61239433]] [[ 2.30429316]]\n",
      "[ 0.] [[ 5.71202087]] [[ 2.19259501]]\n",
      "[ 0.] [[ 5.72526264]] [[ 2.0520134]]\n",
      "[ 0.] [[ 5.93017483]] [[ 1.9545083]]\n",
      "[ 0.] [[ 6.05957508]] [[ 1.85742879]]\n",
      "[ 0.] [[ 6.22550297]] [[ 1.65369189]]\n",
      "[ 0.] [[ 6.24547482]] [[ 1.49679184]]\n",
      "[ 1.] [[ 4.45467281]] [[ 3.23682833]]\n",
      "[ 0.] [[ 4.81774807]] [[ 3.08981657]]\n",
      "[ 0.] [[ 5.05693722]] [[ 2.86148715]]\n",
      "[ 0.] [[ 5.24179029]] [[ 2.72860432]]\n",
      "[ 0.] [[ 5.35957623]] [[ 2.59961843]]\n",
      "[ 0.] [[ 5.48059464]] [[ 2.50019836]]\n",
      "[ 0.] [[ 5.58263397]] [[ 2.40354753]]\n",
      "[ 0.] [[ 5.67707253]] [[ 2.30663776]]\n",
      "[ 0.] [[ 5.74868488]] [[ 2.20453]]\n",
      "[ 0.] [[ 5.78288698]] [[ 2.16929674]]\n",
      "[ 0.] [[ 6.00413513]] [[ 1.89754653]]\n",
      "[ 0.] [[ 6.08575249]] [[ 1.81063902]]\n",
      "[ 0.] [[ 6.09982872]] [[ 1.73370218]]\n",
      "[ 0.] [[ 6.23835754]] [[ 1.63355458]]\n",
      "[ 0.] [[ 6.33683872]] [[ 1.53276193]]\n",
      "[ 0.] [[ 6.49659348]] [[ 1.33669031]]\n",
      "[ 0.] [[ 6.57184601]] [[ 1.23969114]]\n",
      "[ 0.] [[ 7.11519432]] [[ 0.8618148]]\n",
      "[ 1.] [[ 4.97544765]] [[ 2.86530447]]\n",
      "[ 0.] [[ 5.08286572]] [[ 2.65321398]]\n",
      "[ 0.] [[ 5.39236736]] [[ 2.50576067]]\n",
      "[ 0.] [[ 5.38822985]] [[ 2.47760677]]\n",
      "[ 0.] [[ 5.55598402]] [[ 2.3189702]]\n",
      "[ 0.] [[ 5.72238159]] [[ 2.21749759]]\n",
      "[ 0.] [[ 5.95517969]] [[ 1.91839731]]\n",
      "[ 0.] [[ 6.42555618]] [[ 1.3437407]]\n",
      "[ 0.] [[ 6.51328468]] [[ 1.27658641]]\n",
      "[ 0.] [[ 6.6554327]] [[ 1.11357558]]\n",
      "[ 0.] [[ 6.78177452]] [[ 1.01034737]]\n",
      "[ 0.] [[ 6.78836489]] [[ 0.99125993]]\n",
      "[ 0.] [[ 6.85011959]] [[ 0.9950785]]\n",
      "[ 0.] [[ 6.83143902]] [[ 0.99670291]]\n",
      "[ 0.] [[ 6.86646366]] [[ 0.98849642]]\n",
      "[ 1.] [[ 4.71309376]] [[ 2.9243269]]\n",
      "[ 0.] [[ 5.1171031]] [[ 2.72168922]]\n",
      "[ 0.] [[ 5.33141136]] [[ 2.60103822]]\n",
      "[ 0.] [[ 5.49906778]] [[ 2.46929193]]\n",
      "[ 0.] [[ 5.42775822]] [[ 2.38235831]]\n",
      "[ 0.] [[ 5.72383785]] [[ 2.16282392]]\n",
      "[ 0.] [[ 5.80014896]] [[ 2.08196688]]\n",
      "[ 0.] [[ 5.75816536]] [[ 1.98321247]]\n",
      "[ 0.] [[ 5.9452877]] [[ 1.91354895]]\n",
      "[ 0.] [[ 6.15039158]] [[ 1.72137249]]\n",
      "[ 0.] [[ 6.24439621]] [[ 1.62935412]]\n",
      "[ 0.] [[ 6.37408495]] [[ 1.4049027]]\n",
      "[ 0.] [[ 6.43844604]] [[ 1.3398627]]\n",
      "[ 0.] [[ 6.6075139]] [[ 1.17816842]]\n",
      "[ 0.] [[ 6.69291353]] [[ 1.07395923]]\n",
      "[ 1.] [[ 4.85275078]] [[ 3.00195265]]\n",
      "[ 0.] [[ 5.08715343]] [[ 2.84936333]]\n",
      "[ 0.] [[ 4.94737339]] [[ 2.76531553]]\n",
      "[ 0.] [[ 5.34538984]] [[ 2.54332256]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [[ 5.52551174]] [[ 2.42316318]]\n",
      "[ 0.] [[ 5.69864225]] [[ 2.23318577]]\n",
      "[ 0.] [[ 5.8366642]] [[ 2.06510925]]\n",
      "[ 0.] [[ 5.92326355]] [[ 1.91446471]]\n",
      "[ 0.] [[ 6.0596199]] [[ 1.8421644]]\n",
      "[ 0.] [[ 6.20018482]] [[ 1.66550112]]\n",
      "[ 0.] [[ 6.22702217]] [[ 1.5100081]]\n",
      "[ 0.] [[ 6.39876509]] [[ 1.40544295]]\n",
      "[ 0.] [[ 6.51928616]] [[ 1.26740551]]\n",
      "[ 0.] [[ 6.6128664]] [[ 1.15586555]]\n",
      "[ 0.] [[ 6.70151615]] [[ 1.12293041]]\n",
      "[ 1.] [[ 4.88802814]] [[ 2.98341942]]\n",
      "[ 0.] [[ 5.1682663]] [[ 2.76746774]]\n",
      "[ 0.] [[ 5.35235548]] [[ 2.61020708]]\n",
      "[ 0.] [[ 5.48647881]] [[ 2.49145269]]\n",
      "[ 0.] [[ 5.59399843]] [[ 2.3681345]]\n",
      "[ 0.] [[ 5.63815403]] [[ 2.28660297]]\n",
      "[ 0.] [[ 5.68918657]] [[ 2.10175443]]\n",
      "[ 0.] [[ 5.76286316]] [[ 1.97614503]]\n",
      "[ 0.] [[ 5.96773052]] [[ 1.8955493]]\n",
      "[ 0.] [[ 6.0157299]] [[ 1.79390001]]\n",
      "[ 0.] [[ 6.1696434]] [[ 1.67779708]]\n",
      "[ 0.] [[ 6.29124451]] [[ 1.56841028]]\n",
      "[ 1.] [[ 4.66468143]] [[ 3.22465467]]\n",
      "[ 0.] [[ 4.74752235]] [[ 3.03778315]]\n",
      "[ 0.] [[ 4.95094967]] [[ 2.88476801]]\n",
      "[ 0.] [[ 5.22322083]] [[ 2.70878077]]\n",
      "[ 0.] [[ 5.4079833]] [[ 2.54114246]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(test.shape[0]):\n",
    "    gc = test['var4(t-1)'][i] = xgb.predict(test.iloc[i:i+1,:7])\n",
    "    test = test.values\n",
    "    test = test.reshape((test.shape[0], 1, test.shape[1]))\n",
    "    ffm = test[i+1:i+2,:,0] = test[i:i+1,:,7:] = model1.predict(test[i:i+1,:,:7])\n",
    "    fum = test[i+1:i+2,:,1] = model2.predict(test[i:i+1])\n",
    "    test = test.reshape((test.shape[0], test.shape[2]))\n",
    "    test = pd.DataFrame(test)\n",
    "    test.columns = column\n",
    "    print(gc, ffm, fum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.247186</td>\n",
       "      <td>2.774299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.408436</td>\n",
       "      <td>0.520126</td>\n",
       "      <td>0.098823</td>\n",
       "      <td>3.583615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.583615</td>\n",
       "      <td>3.488454</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124429</td>\n",
       "      <td>0.522675</td>\n",
       "      <td>0.044418</td>\n",
       "      <td>4.479771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.479771</td>\n",
       "      <td>3.293406</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245838</td>\n",
       "      <td>0.468081</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>4.809662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.809662</td>\n",
       "      <td>3.074713</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169346</td>\n",
       "      <td>0.674019</td>\n",
       "      <td>0.125974</td>\n",
       "      <td>5.096562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.096562</td>\n",
       "      <td>2.843139</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296311</td>\n",
       "      <td>0.732314</td>\n",
       "      <td>0.240021</td>\n",
       "      <td>5.401882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.401882</td>\n",
       "      <td>2.546555</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025018</td>\n",
       "      <td>0.497912</td>\n",
       "      <td>0.013522</td>\n",
       "      <td>5.328630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.328630</td>\n",
       "      <td>2.502242</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121191</td>\n",
       "      <td>0.513401</td>\n",
       "      <td>0.066184</td>\n",
       "      <td>5.466595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.466595</td>\n",
       "      <td>2.411124</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220577</td>\n",
       "      <td>0.660618</td>\n",
       "      <td>0.150208</td>\n",
       "      <td>5.680602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.680602</td>\n",
       "      <td>2.233593</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133468</td>\n",
       "      <td>0.526436</td>\n",
       "      <td>0.077532</td>\n",
       "      <td>5.820526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.820526</td>\n",
       "      <td>2.127847</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151191</td>\n",
       "      <td>0.578549</td>\n",
       "      <td>0.095986</td>\n",
       "      <td>5.878485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.878485</td>\n",
       "      <td>2.008466</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252240</td>\n",
       "      <td>0.704352</td>\n",
       "      <td>0.191045</td>\n",
       "      <td>6.057662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.057662</td>\n",
       "      <td>1.791946</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117464</td>\n",
       "      <td>0.655804</td>\n",
       "      <td>0.083546</td>\n",
       "      <td>6.183508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.183508</td>\n",
       "      <td>1.674540</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.877712</td>\n",
       "      <td>1.112496</td>\n",
       "      <td>0.950459</td>\n",
       "      <td>6.805779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.805779</td>\n",
       "      <td>0.975116</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088055</td>\n",
       "      <td>0.512298</td>\n",
       "      <td>0.049750</td>\n",
       "      <td>6.830111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.830111</td>\n",
       "      <td>0.996086</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355070</td>\n",
       "      <td>0.724511</td>\n",
       "      <td>0.271670</td>\n",
       "      <td>6.996919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.996919</td>\n",
       "      <td>0.919613</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.094717</td>\n",
       "      <td>0.527014</td>\n",
       "      <td>0.053245</td>\n",
       "      <td>4.828197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.828197</td>\n",
       "      <td>2.928585</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329133</td>\n",
       "      <td>0.581963</td>\n",
       "      <td>0.194431</td>\n",
       "      <td>5.233918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.233918</td>\n",
       "      <td>2.668338</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213073</td>\n",
       "      <td>0.663138</td>\n",
       "      <td>0.139480</td>\n",
       "      <td>5.212274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.212274</td>\n",
       "      <td>2.503750</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168086</td>\n",
       "      <td>0.513006</td>\n",
       "      <td>0.087936</td>\n",
       "      <td>5.371217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.371217</td>\n",
       "      <td>2.408193</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354663</td>\n",
       "      <td>0.836047</td>\n",
       "      <td>0.309898</td>\n",
       "      <td>5.756032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.756032</td>\n",
       "      <td>2.095509</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131777</td>\n",
       "      <td>0.514850</td>\n",
       "      <td>0.073842</td>\n",
       "      <td>5.921531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.921531</td>\n",
       "      <td>1.998585</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120180</td>\n",
       "      <td>0.486677</td>\n",
       "      <td>0.066470</td>\n",
       "      <td>6.030787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.030787</td>\n",
       "      <td>1.902442</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108008</td>\n",
       "      <td>0.514865</td>\n",
       "      <td>0.061840</td>\n",
       "      <td>6.116895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.116895</td>\n",
       "      <td>1.806662</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137727</td>\n",
       "      <td>0.553914</td>\n",
       "      <td>0.085025</td>\n",
       "      <td>6.131230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.131230</td>\n",
       "      <td>1.697618</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.455951</td>\n",
       "      <td>0.032086</td>\n",
       "      <td>6.108650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.108650</td>\n",
       "      <td>1.659590</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119744</td>\n",
       "      <td>0.520411</td>\n",
       "      <td>0.066828</td>\n",
       "      <td>6.279524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.279524</td>\n",
       "      <td>1.563077</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083319</td>\n",
       "      <td>0.596526</td>\n",
       "      <td>0.052575</td>\n",
       "      <td>4.440287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.440287</td>\n",
       "      <td>3.308304</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223720</td>\n",
       "      <td>0.655991</td>\n",
       "      <td>0.158389</td>\n",
       "      <td>4.857335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.857335</td>\n",
       "      <td>3.014893</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100534</td>\n",
       "      <td>0.518767</td>\n",
       "      <td>0.055362</td>\n",
       "      <td>5.004772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.004772</td>\n",
       "      <td>2.866300</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225168</td>\n",
       "      <td>0.742067</td>\n",
       "      <td>0.182763</td>\n",
       "      <td>5.090256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>5.087153</td>\n",
       "      <td>2.849363</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068506</td>\n",
       "      <td>0.455951</td>\n",
       "      <td>0.032086</td>\n",
       "      <td>4.947373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>4.947373</td>\n",
       "      <td>2.765316</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251725</td>\n",
       "      <td>0.739731</td>\n",
       "      <td>0.183607</td>\n",
       "      <td>5.345390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>5.345390</td>\n",
       "      <td>2.543323</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107215</td>\n",
       "      <td>0.710326</td>\n",
       "      <td>0.075301</td>\n",
       "      <td>5.525512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.525512</td>\n",
       "      <td>2.423163</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254963</td>\n",
       "      <td>0.580527</td>\n",
       "      <td>0.153574</td>\n",
       "      <td>5.698642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>5.698642</td>\n",
       "      <td>2.233186</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231971</td>\n",
       "      <td>0.590622</td>\n",
       "      <td>0.139106</td>\n",
       "      <td>5.836664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>5.836664</td>\n",
       "      <td>2.065109</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219733</td>\n",
       "      <td>0.586324</td>\n",
       "      <td>0.129217</td>\n",
       "      <td>5.923264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>5.923264</td>\n",
       "      <td>1.914465</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099099</td>\n",
       "      <td>0.468081</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>6.059620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>6.059620</td>\n",
       "      <td>1.842164</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233825</td>\n",
       "      <td>0.581574</td>\n",
       "      <td>0.137589</td>\n",
       "      <td>6.200185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>6.200185</td>\n",
       "      <td>1.665501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190747</td>\n",
       "      <td>0.696677</td>\n",
       "      <td>0.136833</td>\n",
       "      <td>6.227022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>6.227022</td>\n",
       "      <td>1.510008</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141028</td>\n",
       "      <td>0.526436</td>\n",
       "      <td>0.077532</td>\n",
       "      <td>6.398765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>6.398765</td>\n",
       "      <td>1.405443</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221535</td>\n",
       "      <td>0.515221</td>\n",
       "      <td>0.116079</td>\n",
       "      <td>6.519286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>6.519286</td>\n",
       "      <td>1.267406</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174257</td>\n",
       "      <td>0.668248</td>\n",
       "      <td>0.117840</td>\n",
       "      <td>6.612866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>6.612866</td>\n",
       "      <td>1.155866</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078527</td>\n",
       "      <td>0.521422</td>\n",
       "      <td>0.042307</td>\n",
       "      <td>6.701516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>6.701516</td>\n",
       "      <td>1.122930</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.195269</td>\n",
       "      <td>0.609855</td>\n",
       "      <td>0.121039</td>\n",
       "      <td>4.888028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>4.888028</td>\n",
       "      <td>2.983419</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181139</td>\n",
       "      <td>0.674019</td>\n",
       "      <td>0.125974</td>\n",
       "      <td>5.168266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>5.168266</td>\n",
       "      <td>2.767468</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134919</td>\n",
       "      <td>0.629907</td>\n",
       "      <td>0.087853</td>\n",
       "      <td>5.352355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>5.352355</td>\n",
       "      <td>2.610207</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115468</td>\n",
       "      <td>0.532430</td>\n",
       "      <td>0.063177</td>\n",
       "      <td>5.486479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>5.486479</td>\n",
       "      <td>2.491453</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136218</td>\n",
       "      <td>0.552585</td>\n",
       "      <td>0.079445</td>\n",
       "      <td>5.593998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>5.593998</td>\n",
       "      <td>2.368134</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088760</td>\n",
       "      <td>0.543223</td>\n",
       "      <td>0.049324</td>\n",
       "      <td>5.638154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>5.638154</td>\n",
       "      <td>2.286603</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268915</td>\n",
       "      <td>0.628202</td>\n",
       "      <td>0.171790</td>\n",
       "      <td>5.689187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>5.689187</td>\n",
       "      <td>2.101754</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221899</td>\n",
       "      <td>0.548274</td>\n",
       "      <td>0.128292</td>\n",
       "      <td>5.762863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>5.762863</td>\n",
       "      <td>1.976145</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126035</td>\n",
       "      <td>0.508217</td>\n",
       "      <td>0.065990</td>\n",
       "      <td>5.967731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>5.967731</td>\n",
       "      <td>1.895549</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148782</td>\n",
       "      <td>0.553914</td>\n",
       "      <td>0.085025</td>\n",
       "      <td>6.015730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>6.015730</td>\n",
       "      <td>1.793900</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125190</td>\n",
       "      <td>0.655804</td>\n",
       "      <td>0.083546</td>\n",
       "      <td>6.169643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>6.169643</td>\n",
       "      <td>1.677797</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107789</td>\n",
       "      <td>0.627657</td>\n",
       "      <td>0.069538</td>\n",
       "      <td>6.291245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>6.291245</td>\n",
       "      <td>1.568410</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.251481</td>\n",
       "      <td>0.535789</td>\n",
       "      <td>0.138739</td>\n",
       "      <td>4.664681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>4.664681</td>\n",
       "      <td>3.224655</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118954</td>\n",
       "      <td>0.496095</td>\n",
       "      <td>0.061535</td>\n",
       "      <td>4.747522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>4.747522</td>\n",
       "      <td>3.037783</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.513401</td>\n",
       "      <td>0.066184</td>\n",
       "      <td>4.950950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>4.950950</td>\n",
       "      <td>2.884768</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130116</td>\n",
       "      <td>0.755169</td>\n",
       "      <td>0.098450</td>\n",
       "      <td>5.223221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>5.223221</td>\n",
       "      <td>2.708781</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148145</td>\n",
       "      <td>0.725251</td>\n",
       "      <td>0.106769</td>\n",
       "      <td>5.407983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1624 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
       "0      4.247186   2.774299        2.0        1.0   0.408436   0.520126   \n",
       "1      3.583615   3.488454       73.0        0.0   0.124429   0.522675   \n",
       "2      4.479771   3.293406       48.0        0.0   0.245838   0.468081   \n",
       "3      4.809662   3.074713       86.0        0.0   0.169346   0.674019   \n",
       "4      5.096562   2.843139       67.0        0.0   0.296311   0.732314   \n",
       "5      5.401882   2.546555       18.0        0.0   0.025018   0.497912   \n",
       "6      5.328630   2.502242       33.0        0.0   0.121191   0.513401   \n",
       "7      5.466595   2.411124       43.0        0.0   0.220577   0.660618   \n",
       "8      5.680602   2.233593       72.0        0.0   0.133468   0.526436   \n",
       "9      5.820526   2.127847       24.0        0.0   0.151191   0.578549   \n",
       "10     5.878485   2.008466       87.0        0.0   0.252240   0.704352   \n",
       "11     6.057662   1.791946       78.0        0.0   0.117464   0.655804   \n",
       "12     6.183508   1.674540       39.0        0.0   0.877712   1.112496   \n",
       "13     6.805779   0.975116       14.0        0.0   0.088055   0.512298   \n",
       "14     6.830111   0.996086       26.0        0.0   0.355070   0.724511   \n",
       "15     6.996919   0.919613       19.0        1.0   0.094717   0.527014   \n",
       "16     4.828197   2.928585       84.0        0.0   0.329133   0.581963   \n",
       "17     5.233918   2.668338        3.0        0.0   0.213073   0.663138   \n",
       "18     5.212274   2.503750       20.0        0.0   0.168086   0.513006   \n",
       "19     5.371217   2.408193       36.0        0.0   0.354663   0.836047   \n",
       "20     5.756032   2.095509       54.0        0.0   0.131777   0.514850   \n",
       "21     5.921531   1.998585       66.0        0.0   0.120180   0.486677   \n",
       "22     6.030787   1.902442       49.0        0.0   0.108008   0.514865   \n",
       "23     6.116895   1.806662       13.0        0.0   0.137727   0.553914   \n",
       "24     6.131230   1.697618        7.0        0.0   0.063000   0.455951   \n",
       "25     6.108650   1.659590       42.0        0.0   0.119744   0.520411   \n",
       "26     6.279524   1.563077       17.0        1.0   0.083319   0.596526   \n",
       "27     4.440287   3.308304       45.0        0.0   0.223720   0.655991   \n",
       "28     4.857335   3.014893       35.0        0.0   0.100534   0.518767   \n",
       "29     5.004772   2.866300        8.0        0.0   0.225168   0.742067   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1594   5.087153   2.849363        7.0        0.0   0.068506   0.455951   \n",
       "1595   4.947373   2.765316       59.0        0.0   0.251725   0.739731   \n",
       "1596   5.345390   2.543323       71.0        0.0   0.107215   0.710326   \n",
       "1597   5.525512   2.423163       40.0        0.0   0.254963   0.580527   \n",
       "1598   5.698642   2.233186       31.0        0.0   0.231971   0.590622   \n",
       "1599   5.836664   2.065109       16.0        0.0   0.219733   0.586324   \n",
       "1600   5.923264   1.914465       48.0        0.0   0.099099   0.468081   \n",
       "1601   6.059620   1.842164       30.0        0.0   0.233825   0.581574   \n",
       "1602   6.200185   1.665501        0.0        0.0   0.190747   0.696677   \n",
       "1603   6.227022   1.510008       72.0        0.0   0.141028   0.526436   \n",
       "1604   6.398765   1.405443       79.0        0.0   0.221535   0.515221   \n",
       "1605   6.519286   1.267406        9.0        0.0   0.174257   0.668248   \n",
       "1606   6.612866   1.155866       52.0        0.0   0.078527   0.521422   \n",
       "1607   6.701516   1.122930       51.0        1.0   0.195269   0.609855   \n",
       "1608   4.888028   2.983419       86.0        0.0   0.181139   0.674019   \n",
       "1609   5.168266   2.767468       80.0        0.0   0.134919   0.629907   \n",
       "1610   5.352355   2.610207       76.0        0.0   0.115468   0.532430   \n",
       "1611   5.486479   2.491453       89.0        0.0   0.136218   0.552585   \n",
       "1612   5.593998   2.368134       34.0        0.0   0.088760   0.543223   \n",
       "1613   5.638154   2.286603        6.0        0.0   0.268915   0.628202   \n",
       "1614   5.689187   2.101754        5.0        0.0   0.221899   0.548274   \n",
       "1615   5.762863   1.976145       41.0        0.0   0.126035   0.508217   \n",
       "1616   5.967731   1.895549       13.0        0.0   0.148782   0.553914   \n",
       "1617   6.015730   1.793900       78.0        0.0   0.125190   0.655804   \n",
       "1618   6.169643   1.677797       64.0        0.0   0.107789   0.627657   \n",
       "1619   6.291245   1.568410       47.0        1.0   0.251481   0.535789   \n",
       "1620   4.664681   3.224655       21.0        0.0   0.118954   0.496095   \n",
       "1621   4.747522   3.037783       33.0        0.0   0.122900   0.513401   \n",
       "1622   4.950950   2.884768       77.0        0.0   0.130116   0.755169   \n",
       "1623   5.223221   2.708781       55.0        0.0   0.148145   0.725251   \n",
       "\n",
       "      var7(t-1)   var1(t)  \n",
       "0      0.098823  3.583615  \n",
       "1      0.044418  4.479771  \n",
       "2      0.047545  4.809662  \n",
       "3      0.125974  5.096562  \n",
       "4      0.240021  5.401882  \n",
       "5      0.013522  5.328630  \n",
       "6      0.066184  5.466595  \n",
       "7      0.150208  5.680602  \n",
       "8      0.077532  5.820526  \n",
       "9      0.095986  5.878485  \n",
       "10     0.191045  6.057662  \n",
       "11     0.083546  6.183508  \n",
       "12     0.950459  6.805779  \n",
       "13     0.049750  6.830111  \n",
       "14     0.271670  6.996919  \n",
       "15     0.053245  4.828197  \n",
       "16     0.194431  5.233918  \n",
       "17     0.139480  5.212274  \n",
       "18     0.087936  5.371217  \n",
       "19     0.309898  5.756032  \n",
       "20     0.073842  5.921531  \n",
       "21     0.066470  6.030787  \n",
       "22     0.061840  6.116895  \n",
       "23     0.085025  6.131230  \n",
       "24     0.032086  6.108650  \n",
       "25     0.066828  6.279524  \n",
       "26     0.052575  4.440287  \n",
       "27     0.158389  4.857335  \n",
       "28     0.055362  5.004772  \n",
       "29     0.182763  5.090256  \n",
       "...         ...       ...  \n",
       "1594   0.032086  4.947373  \n",
       "1595   0.183607  5.345390  \n",
       "1596   0.075301  5.525512  \n",
       "1597   0.153574  5.698642  \n",
       "1598   0.139106  5.836664  \n",
       "1599   0.129217  5.923264  \n",
       "1600   0.047545  6.059620  \n",
       "1601   0.137589  6.200185  \n",
       "1602   0.136833  6.227022  \n",
       "1603   0.077532  6.398765  \n",
       "1604   0.116079  6.519286  \n",
       "1605   0.117840  6.612866  \n",
       "1606   0.042307  6.701516  \n",
       "1607   0.121039  4.888028  \n",
       "1608   0.125974  5.168266  \n",
       "1609   0.087853  5.352355  \n",
       "1610   0.063177  5.486479  \n",
       "1611   0.079445  5.593998  \n",
       "1612   0.049324  5.638154  \n",
       "1613   0.171790  5.689187  \n",
       "1614   0.128292  5.762863  \n",
       "1615   0.065990  5.967731  \n",
       "1616   0.085025  6.015730  \n",
       "1617   0.083546  6.169643  \n",
       "1618   0.069538  6.291245  \n",
       "1619   0.138739  4.664681  \n",
       "1620   0.061535  4.747522  \n",
       "1621   0.066184  4.950950  \n",
       "1622   0.098450  5.223221  \n",
       "1623   0.106769  5.407983  \n",
       "\n",
       "[1624 rows x 8 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initialFreeMemory = test['var2(t-1)'].copy()\n",
    "gcRun = test['var4(t-1)'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcRun[13] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1624):\n",
    "    if gcRun[i] == 1:\n",
    "        gcRun[i] = 'True'\n",
    "    else:\n",
    "        gcRun[i] = 'False'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.DataFrame({\n",
    "        \"serialNum\": range(1,1625),\n",
    "        \"initialFreeMemory\": initialFreeMemory,\n",
    "        \"gcRun\": gcRun\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serialNum</th>\n",
       "      <th>initialFreeMemory</th>\n",
       "      <th>gcRun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.774299</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.488454</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.293406</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.074713</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.843139</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2.546555</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2.502242</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2.411124</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2.233593</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2.127847</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2.008466</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.791946</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1.674540</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.975116</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.996086</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.919613</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2.928585</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2.668338</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2.503750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2.408193</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>2.095509</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1.998585</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1.902442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1.806662</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1.697618</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1.659590</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1.563077</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>3.308304</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>3.014893</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>2.866300</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1595</td>\n",
       "      <td>2.849363</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1596</td>\n",
       "      <td>2.765316</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1597</td>\n",
       "      <td>2.543323</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1598</td>\n",
       "      <td>2.423163</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1599</td>\n",
       "      <td>2.233186</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1600</td>\n",
       "      <td>2.065109</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1601</td>\n",
       "      <td>1.914465</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1602</td>\n",
       "      <td>1.842164</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1603</td>\n",
       "      <td>1.665501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>1604</td>\n",
       "      <td>1.510008</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>1605</td>\n",
       "      <td>1.405443</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>1606</td>\n",
       "      <td>1.267406</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1607</td>\n",
       "      <td>1.155866</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>1608</td>\n",
       "      <td>1.122930</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>1609</td>\n",
       "      <td>2.983419</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>1610</td>\n",
       "      <td>2.767468</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>1611</td>\n",
       "      <td>2.610207</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>1612</td>\n",
       "      <td>2.491453</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>1613</td>\n",
       "      <td>2.368134</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>1614</td>\n",
       "      <td>2.286603</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>1615</td>\n",
       "      <td>2.101754</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>1616</td>\n",
       "      <td>1.976145</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>1617</td>\n",
       "      <td>1.895549</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>1618</td>\n",
       "      <td>1.793900</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>1619</td>\n",
       "      <td>1.677797</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>1620</td>\n",
       "      <td>1.568410</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>1621</td>\n",
       "      <td>3.224655</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>1622</td>\n",
       "      <td>3.037783</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>1623</td>\n",
       "      <td>2.884768</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>1624</td>\n",
       "      <td>2.708781</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1624 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      serialNum  initialFreeMemory  gcRun\n",
       "0             1           2.774299   True\n",
       "1             2           3.488454  False\n",
       "2             3           3.293406  False\n",
       "3             4           3.074713  False\n",
       "4             5           2.843139  False\n",
       "5             6           2.546555  False\n",
       "6             7           2.502242  False\n",
       "7             8           2.411124  False\n",
       "8             9           2.233593  False\n",
       "9            10           2.127847  False\n",
       "10           11           2.008466  False\n",
       "11           12           1.791946  False\n",
       "12           13           1.674540  False\n",
       "13           14           0.975116  False\n",
       "14           15           0.996086  False\n",
       "15           16           0.919613   True\n",
       "16           17           2.928585  False\n",
       "17           18           2.668338  False\n",
       "18           19           2.503750  False\n",
       "19           20           2.408193  False\n",
       "20           21           2.095509  False\n",
       "21           22           1.998585  False\n",
       "22           23           1.902442  False\n",
       "23           24           1.806662  False\n",
       "24           25           1.697618  False\n",
       "25           26           1.659590  False\n",
       "26           27           1.563077   True\n",
       "27           28           3.308304  False\n",
       "28           29           3.014893  False\n",
       "29           30           2.866300  False\n",
       "...         ...                ...    ...\n",
       "1594       1595           2.849363  False\n",
       "1595       1596           2.765316  False\n",
       "1596       1597           2.543323  False\n",
       "1597       1598           2.423163  False\n",
       "1598       1599           2.233186  False\n",
       "1599       1600           2.065109  False\n",
       "1600       1601           1.914465  False\n",
       "1601       1602           1.842164  False\n",
       "1602       1603           1.665501  False\n",
       "1603       1604           1.510008  False\n",
       "1604       1605           1.405443  False\n",
       "1605       1606           1.267406  False\n",
       "1606       1607           1.155866  False\n",
       "1607       1608           1.122930   True\n",
       "1608       1609           2.983419  False\n",
       "1609       1610           2.767468  False\n",
       "1610       1611           2.610207  False\n",
       "1611       1612           2.491453  False\n",
       "1612       1613           2.368134  False\n",
       "1613       1614           2.286603  False\n",
       "1614       1615           2.101754  False\n",
       "1615       1616           1.976145  False\n",
       "1616       1617           1.895549  False\n",
       "1617       1618           1.793900  False\n",
       "1618       1619           1.677797  False\n",
       "1619       1620           1.568410   True\n",
       "1620       1621           3.224655  False\n",
       "1621       1622           3.037783  False\n",
       "1622       1623           2.884768  False\n",
       "1623       1624           2.708781  False\n",
       "\n",
       "[1624 rows x 3 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = sample_submission[['serialNum', 'initialFreeMemory', 'gcRun']]\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serialNum</th>\n",
       "      <th>initialFreeMemory</th>\n",
       "      <th>gcRun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>1625</td>\n",
       "      <td>0.952542</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     serialNum  initialFreeMemory  gcRun\n",
       "1624      1625           0.952542  False"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame(columns=('serialNum', 'initialFreeMemory', 'gcRun'))\n",
    "df.loc[1624] = [1625, 0.9525423, False]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serialNum</th>\n",
       "      <th>initialFreeMemory</th>\n",
       "      <th>gcRun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.774299</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.488454</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.293406</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.074713</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.843139</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2.546555</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2.502242</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2.411124</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2.233593</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2.127847</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2.008466</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.791946</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1.674540</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.975116</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.996086</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.919613</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2.928585</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2.668338</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2.503750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2.408193</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>2.095509</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1.998585</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1.902442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1.806662</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1.697618</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1.659590</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1.563077</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>3.308304</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>3.014893</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>2.866300</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1596</td>\n",
       "      <td>2.765316</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1597</td>\n",
       "      <td>2.543323</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1598</td>\n",
       "      <td>2.423163</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1599</td>\n",
       "      <td>2.233186</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1600</td>\n",
       "      <td>2.065109</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1601</td>\n",
       "      <td>1.914465</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1602</td>\n",
       "      <td>1.842164</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1603</td>\n",
       "      <td>1.665501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>1604</td>\n",
       "      <td>1.510008</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>1605</td>\n",
       "      <td>1.405443</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>1606</td>\n",
       "      <td>1.267406</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1607</td>\n",
       "      <td>1.155866</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>1608</td>\n",
       "      <td>1.122930</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>1609</td>\n",
       "      <td>2.983419</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>1610</td>\n",
       "      <td>2.767468</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>1611</td>\n",
       "      <td>2.610207</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>1612</td>\n",
       "      <td>2.491453</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>1613</td>\n",
       "      <td>2.368134</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>1614</td>\n",
       "      <td>2.286603</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>1615</td>\n",
       "      <td>2.101754</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>1616</td>\n",
       "      <td>1.976145</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>1617</td>\n",
       "      <td>1.895549</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>1618</td>\n",
       "      <td>1.793900</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>1619</td>\n",
       "      <td>1.677797</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>1620</td>\n",
       "      <td>1.568410</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>1621</td>\n",
       "      <td>3.224655</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>1622</td>\n",
       "      <td>3.037783</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>1623</td>\n",
       "      <td>2.884768</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>1624</td>\n",
       "      <td>2.708781</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>1625</td>\n",
       "      <td>0.952542</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1625 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     serialNum  initialFreeMemory  gcRun\n",
       "0            1           2.774299   True\n",
       "1            2           3.488454  False\n",
       "2            3           3.293406  False\n",
       "3            4           3.074713  False\n",
       "4            5           2.843139  False\n",
       "5            6           2.546555  False\n",
       "6            7           2.502242  False\n",
       "7            8           2.411124  False\n",
       "8            9           2.233593  False\n",
       "9           10           2.127847  False\n",
       "10          11           2.008466  False\n",
       "11          12           1.791946  False\n",
       "12          13           1.674540  False\n",
       "13          14           0.975116  False\n",
       "14          15           0.996086  False\n",
       "15          16           0.919613   True\n",
       "16          17           2.928585  False\n",
       "17          18           2.668338  False\n",
       "18          19           2.503750  False\n",
       "19          20           2.408193  False\n",
       "20          21           2.095509  False\n",
       "21          22           1.998585  False\n",
       "22          23           1.902442  False\n",
       "23          24           1.806662  False\n",
       "24          25           1.697618  False\n",
       "25          26           1.659590  False\n",
       "26          27           1.563077   True\n",
       "27          28           3.308304  False\n",
       "28          29           3.014893  False\n",
       "29          30           2.866300  False\n",
       "...        ...                ...    ...\n",
       "1595      1596           2.765316  False\n",
       "1596      1597           2.543323  False\n",
       "1597      1598           2.423163  False\n",
       "1598      1599           2.233186  False\n",
       "1599      1600           2.065109  False\n",
       "1600      1601           1.914465  False\n",
       "1601      1602           1.842164  False\n",
       "1602      1603           1.665501  False\n",
       "1603      1604           1.510008  False\n",
       "1604      1605           1.405443  False\n",
       "1605      1606           1.267406  False\n",
       "1606      1607           1.155866  False\n",
       "1607      1608           1.122930   True\n",
       "1608      1609           2.983419  False\n",
       "1609      1610           2.767468  False\n",
       "1610      1611           2.610207  False\n",
       "1611      1612           2.491453  False\n",
       "1612      1613           2.368134  False\n",
       "1613      1614           2.286603  False\n",
       "1614      1615           2.101754  False\n",
       "1615      1616           1.976145  False\n",
       "1616      1617           1.895549  False\n",
       "1617      1618           1.793900  False\n",
       "1618      1619           1.677797  False\n",
       "1619      1620           1.568410   True\n",
       "1620      1621           3.224655  False\n",
       "1621      1622           3.037783  False\n",
       "1622      1623           2.884768  False\n",
       "1623      1624           2.708781  False\n",
       "1624      1625           0.952542  False\n",
       "\n",
       "[1625 rows x 3 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.concat([sample_submission,df], axis=0)\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv('sample_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
